#!/usr/bin/env python3
"""
å®Œæ•´çš„å¯¹è¯å†å²å·¥ä½œæµæµ‹è¯•
éªŒè¯çœŸå®çš„å¤šæ™ºèƒ½ä½“åä½œå¯¹è¯è®°å½•åŠŸèƒ½
"""

import asyncio
import json
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from core.llm_coordinator_agent import LLMCoordinatorAgent, TaskContext
from core.base_agent import BaseAgent
from core.enums import AgentCapability
from core.response_format import create_success_response
from config.config import FrameworkConfig


class MockVerilogAgent(BaseAgent):
    """æ¨¡æ‹ŸVerilogè®¾è®¡æ™ºèƒ½ä½“"""
    
    def __init__(self):
        super().__init__(
            agent_id="mock_verilog_agent",
            role="design_engineer",
            capabilities={AgentCapability.CODE_GENERATION, AgentCapability.MODULE_DESIGN}
        )
    
    def get_capabilities(self):
        return {AgentCapability.CODE_GENERATION, AgentCapability.MODULE_DESIGN}
    
    def get_specialty_description(self):
        return "æ¨¡æ‹ŸVerilogè®¾è®¡æ™ºèƒ½ä½“ï¼Œç”¨äºæµ‹è¯•å¯¹è¯å†å²è®°å½•"
    
    async def execute_enhanced_task(self, task_request: str, **kwargs):
        return create_success_response(
            task_completed=True,
            agent_id=self.agent_id,
            result="Verilogä»£ç å·²ç”Ÿæˆ",
            message="æ¨¡æ‹Ÿç”Ÿæˆcounter.væ–‡ä»¶"
        )
    
    async def _call_llm_for_function_calling(self, conversation):
        # æ¨¡æ‹ŸLLMå“åº”ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨
        return '''
{
    "tool_calls": [
        {
            "tool_name": "write_file",
            "parameters": {
                "filename": "counter.v",
                "content": "module counter(input clk, input rst, output [7:0] count); endmodule"
            }
        }
    ]
}
'''


async def test_full_conversation_workflow():
    """æµ‹è¯•å®Œæ•´çš„å¯¹è¯å·¥ä½œæµ"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•å®Œæ•´çš„å¤šæ™ºèƒ½ä½“å¯¹è¯å·¥ä½œæµ...")
    
    try:
        # 1. åˆ›å»ºé…ç½®å’Œåè°ƒå™¨
        config = FrameworkConfig.from_env()
        coordinator = LLMCoordinatorAgent(config)
        
        print("âœ… åè°ƒå™¨åˆ›å»ºæˆåŠŸ")
        
        # 2. åˆ›å»ºå¹¶æ³¨å†Œæ¨¡æ‹Ÿæ™ºèƒ½ä½“
        mock_agent = MockVerilogAgent()
        
        # æ³¨å†Œæ™ºèƒ½ä½“åˆ°åè°ƒå™¨
        from core.llm_coordinator_agent import AgentInfo
        from core.enums import AgentStatus
        
        agent_info = AgentInfo(
            agent_id="mock_verilog_agent",
            agent_instance=mock_agent,
            capabilities={AgentCapability.CODE_GENERATION},
            specialty="design_engineer",
            status=AgentStatus.IDLE
        )
        
        coordinator.registered_agents["mock_verilog_agent"] = agent_info
        
        print("âœ… æ¨¡æ‹Ÿæ™ºèƒ½ä½“æ³¨å†ŒæˆåŠŸ")
        
        # 3. åˆ›å»ºä»»åŠ¡ä¸Šä¸‹æ–‡
        task_context = TaskContext(
            task_id="workflow_test_123",
            original_request="è®¾è®¡ä¸€ä¸ª8ä½counteræ¨¡å—å¹¶ç”ŸæˆVerilogä»£ç "
        )
        
        # 4. æ¨¡æ‹Ÿå®Œæ•´çš„å¯¹è¯æµç¨‹
        print("\nğŸ“ å¼€å§‹æ¨¡æ‹Ÿå¤šæ™ºèƒ½ä½“å¯¹è¯æµç¨‹...")
        
        # æ­¥éª¤1ï¼šè®°å½•ç”¨æˆ·è¯·æ±‚
        task_context.add_conversation_message(
            role="user",
            content="è®¾è®¡ä¸€ä¸ª8ä½counteræ¨¡å—å¹¶ç”ŸæˆVerilogä»£ç ",
            agent_id="user"
        )
        
        # æ­¥éª¤2ï¼šåè°ƒå™¨åˆ†æä»»åŠ¡
        task_context.add_conversation_message(
            role="system",
            content="å¼€å§‹åè°ƒä»»åŠ¡æ‰§è¡Œï¼Œè¯†åˆ«ä»»åŠ¡ç±»å‹",
            agent_id="llm_coordinator_agent"
        )
        
        # æ­¥éª¤3ï¼šå·¥å…·è°ƒç”¨ - è¯†åˆ«ä»»åŠ¡ç±»å‹
        task_context.add_conversation_message(
            role="tool_call",
            content="è°ƒç”¨identify_task_typeå·¥å…·",
            agent_id="llm_coordinator_agent",
            tool_info={
                "tool_name": "identify_task_type",
                "parameters": {"task_description": "è®¾è®¡counteræ¨¡å—"},
                "status": "started"
            }
        )
        
        task_context.add_conversation_message(
            role="tool_result",
            content="ä»»åŠ¡ç±»å‹è¯†åˆ«å®Œæˆ",
            agent_id="llm_coordinator_agent",
            tool_info={
                "tool_name": "identify_task_type",
                "success": True,
                "result": "design_task",
                "status": "completed"
            }
        )
        
        # æ­¥éª¤4ï¼šå·¥å…·è°ƒç”¨ - åˆ†é…ä»»åŠ¡ç»™æ™ºèƒ½ä½“
        task_context.add_conversation_message(
            role="tool_call",
            content="åˆ†é…ä»»åŠ¡ç»™Verilogè®¾è®¡æ™ºèƒ½ä½“",
            agent_id="llm_coordinator_agent",
            tool_info={
                "tool_name": "assign_task_to_agent",
                "parameters": {
                    "agent_id": "mock_verilog_agent",
                    "task_description": "è®¾è®¡8ä½counteræ¨¡å—"
                },
                "status": "started"
            }
        )
        
        # æ­¥éª¤5ï¼šè®¾ç½®ä»»åŠ¡ä¸Šä¸‹æ–‡ç»™æ™ºèƒ½ä½“
        mock_agent.set_task_context(task_context)
        
        # æ­¥éª¤6ï¼šæ™ºèƒ½ä½“å¤„ç†ä»»åŠ¡
        task_context.add_conversation_message(
            role="user",
            content="è®¾è®¡8ä½counteræ¨¡å—ï¼Œç”ŸæˆVerilogä»£ç ",
            agent_id="mock_verilog_agent"
        )
        
        # æ­¥éª¤7ï¼šæ™ºèƒ½ä½“å·¥å…·è°ƒç”¨
        task_context.add_conversation_message(
            role="tool_call",
            content="å¼€å§‹è°ƒç”¨å·¥å…·: write_file",
            agent_id="mock_verilog_agent",
            tool_info={
                "tool_name": "write_file",
                "parameters": {
                    "filename": "counter.v",
                    "content": "module counter(input clk, input rst, output [7:0] count); endmodule"
                },
                "status": "started"
            }
        )
        
        task_context.add_conversation_message(
            role="tool_result",
            content="å·¥å…·æ‰§è¡ŒæˆåŠŸ: write_file",
            agent_id="mock_verilog_agent",
            tool_info={
                "tool_name": "write_file",
                "parameters": {
                    "filename": "counter.v",
                    "content": "module counter..."
                },
                "success": True,
                "result": "æ–‡ä»¶å·²æˆåŠŸå†™å…¥åˆ°counter.v",
                "status": "completed"
            }
        )
        
        # æ­¥éª¤8ï¼šæ™ºèƒ½ä½“å“åº”
        task_context.add_conversation_message(
            role="assistant",
            content="å·²æˆåŠŸç”Ÿæˆ8ä½counteræ¨¡å—çš„Verilogä»£ç å¹¶ä¿å­˜åˆ°counter.væ–‡ä»¶",
            agent_id="mock_verilog_agent"
        )
        
        # æ­¥éª¤9ï¼šåè°ƒå™¨æ”¶åˆ°ä»»åŠ¡å®Œæˆ
        task_context.add_conversation_message(
            role="tool_result",
            content="æ™ºèƒ½ä½“ä»»åŠ¡æ‰§è¡Œå®Œæˆ",
            agent_id="llm_coordinator_agent",
            tool_info={
                "tool_name": "assign_task_to_agent",
                "success": True,
                "result": "ä»»åŠ¡å·²æˆåŠŸåˆ†é…å¹¶å®Œæˆ",
                "status": "completed"
            }
        )
        
        # æ­¥éª¤10ï¼šåè°ƒå™¨æœ€ç»ˆå“åº”
        task_context.add_conversation_message(
            role="assistant",
            content="âœ… ä»»åŠ¡å®Œæˆï¼å·²æˆåŠŸè®¾è®¡8ä½counteræ¨¡å—å¹¶ç”ŸæˆVerilogä»£ç ",
            agent_id="llm_coordinator_agent"
        )
        
        print(f"âœ… æ¨¡æ‹Ÿå¯¹è¯æµç¨‹å®Œæˆï¼Œæ€»è®¡ {len(task_context.conversation_history)} æ¡æ¶ˆæ¯")
        
        # 5. æµ‹è¯•ç»Ÿè®¡åŠŸèƒ½
        print("\nğŸ“Š å¯¹è¯ç»Ÿè®¡åˆ†æ...")
        summary = task_context.get_conversation_summary()
        print(f"æ€»æ¶ˆæ¯æ•°: {summary['total_messages']}")
        print(f"å‚ä¸æ™ºèƒ½ä½“: {summary['agents_involved']}")
        print(f"æ¶ˆæ¯ç±»å‹åˆ†å¸ƒ: {summary['message_types']}")
        
        tool_summary = task_context.get_tool_calls_summary()
        print(f"å·¥å…·è°ƒç”¨æ€»æ•°: {tool_summary['total_tool_calls']}")
        print(f"æˆåŠŸç‡: {(1 - tool_summary['failure_rate']) * 100:.1f}%")
        print(f"ä½¿ç”¨çš„å·¥å…·: {tool_summary['unique_tools_used']}")
        print(f"å·¥å…·ä½¿ç”¨ç»Ÿè®¡: {tool_summary['tool_usage_count']}")
        
        # 6. ç”Ÿæˆå®éªŒæŠ¥å‘Šæ ¼å¼
        print("\nğŸ”§ ç”Ÿæˆå®éªŒæŠ¥å‘Šæ ¼å¼...")
        final_result = coordinator._collect_final_result(task_context, "å¤šæ™ºèƒ½ä½“åä½œå®Œæˆ")
        
        # éªŒè¯å¯¹è¯å†å²
        conv_history = final_result.get('conversation_history', [])
        print(f"âœ… å®éªŒæŠ¥å‘ŠåŒ…å«å¯¹è¯å†å²: {len(conv_history)} æ¡æ¶ˆæ¯")
        
        # 7. ä¿å­˜æµ‹è¯•ç»“æœ
        print("\nğŸ’¾ ä¿å­˜å®Œæ•´æµ‹è¯•ç»“æœ...")
        test_result = {
            "test_type": "full_workflow",
            "experiment_report": final_result,
            "conversation_analysis": {
                "summary": summary,
                "tool_analysis": tool_summary
            }
        }
        
        result_file = project_root / "test_full_workflow_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(test_result, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"âœ… å®Œæ•´æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        
        # 8. éªŒè¯å…³é”®ä¿¡æ¯
        print("\nğŸ” éªŒè¯å¯¹è¯è®°å½•å®Œæ•´æ€§...")
        
        # éªŒè¯æ¶ˆæ¯ç±»å‹
        message_types = set(msg.get('role') for msg in conv_history)
        expected_types = {'user', 'system', 'assistant', 'tool_call', 'tool_result'}
        
        if expected_types.issubset(message_types):
            print("âœ… æ‰€æœ‰æ¶ˆæ¯ç±»å‹éƒ½å·²è®°å½•")
        else:
            print(f"âš ï¸ ç¼ºå°‘æ¶ˆæ¯ç±»å‹: {expected_types - message_types}")
        
        # éªŒè¯æ™ºèƒ½ä½“å‚ä¸
        agents = set(msg.get('agent_id') for msg in conv_history)
        expected_agents = {'user', 'llm_coordinator_agent', 'mock_verilog_agent'}
        
        if expected_agents.issubset(agents):
            print("âœ… æ‰€æœ‰æ™ºèƒ½ä½“çš„å¯¹è¯éƒ½å·²è®°å½•")
        else:
            print(f"âš ï¸ ç¼ºå°‘æ™ºèƒ½ä½“è®°å½•: {expected_agents - agents}")
        
        # éªŒè¯å·¥å…·è°ƒç”¨
        tool_calls = [msg for msg in conv_history if msg.get('tool_info')]
        print(f"âœ… å·¥å…·è°ƒç”¨è®°å½•: {len(tool_calls)} æ¡")
        
        for i, tool_call in enumerate(tool_calls):
            tool_info = tool_call.get('tool_info', {})
            print(f"  å·¥å…· {i+1}: {tool_info.get('tool_name')} - {tool_info.get('status')}")
        
        print("\nğŸ‰ å®Œæ•´å¯¹è¯å·¥ä½œæµæµ‹è¯•é€šè¿‡ï¼")
        print("\nğŸ“‹ æµ‹è¯•ç»“æœæ€»ç»“:")
        print(f"- å¯¹è¯æ¶ˆæ¯æ€»æ•°: {len(conv_history)}")
        print(f"- å‚ä¸æ™ºèƒ½ä½“æ•°: {len(agents)}")
        print(f"- å·¥å…·è°ƒç”¨æ¬¡æ•°: {len(tool_calls)}")
        print(f"- æ¶ˆæ¯ç±»å‹æ•°: {len(message_types)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å®Œæ•´å·¥ä½œæµæµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    result = asyncio.run(test_full_conversation_workflow())
    
    if result:
        print("\nâœ¨ æ­å–œï¼å®Œæ•´çš„å¤šæ™ºèƒ½ä½“å¯¹è¯å†å²è®°å½•åŠŸèƒ½å·²æˆåŠŸå®ç°")
        print("\nğŸš€ å¯ä»¥å¼€å§‹ä½¿ç”¨:")
        print("1. python test_llm_coordinator_enhanced.py")
        print("2. python gradio_multi_agent_visualizer.py")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥æ£€æŸ¥")
    
    sys.exit(0 if result else 1)
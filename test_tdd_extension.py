#!/usr/bin/env python3
"""
æµ‹è¯•é©±åŠ¨æ‰©å±•åŠŸèƒ½éªŒè¯è„šæœ¬

è¿™ä¸ªè„šæœ¬éªŒè¯ï¼š
1. æ‰©å±•åŠŸèƒ½æ­£å¸¸å·¥ä½œ
2. ç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å—å½±å“
3. å‘åå…¼å®¹æ€§å®Œæ•´
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from config.config import FrameworkConfig
from core.centralized_coordinator import CentralizedCoordinator
from agents.real_verilog_agent import RealVerilogDesignAgent
from agents.real_code_reviewer import RealCodeReviewAgent

# å¯¼å…¥æ‰©å±•åŠŸèƒ½
from extensions import create_test_driven_coordinator, TestDrivenConfig
from extensions.test_driven_coordinator import TestDrivenCoordinator


async def test_backward_compatibility():
    """æµ‹è¯•å‘åå…¼å®¹æ€§ - ç¡®ä¿ç°æœ‰åŠŸèƒ½ä¸å—å½±å“"""
    print("ğŸ” æµ‹è¯•å‘åå…¼å®¹æ€§...")
    
    # 1. åˆ›å»ºæ ‡å‡†åè°ƒå™¨
    config = FrameworkConfig.from_env()
    original_coordinator = CentralizedCoordinator(config)
    
    # æ³¨å†Œæ™ºèƒ½ä½“
    verilog_agent = RealVerilogDesignAgent(config)
    reviewer_agent = RealCodeReviewAgent(config)
    original_coordinator.register_agent(verilog_agent)
    original_coordinator.register_agent(reviewer_agent)
    
    # 2. åˆ›å»ºå¢å¼ºåè°ƒå™¨
    enhanced_coordinator = create_test_driven_coordinator(original_coordinator)
    
    # 3. æµ‹è¯•APIå…¼å®¹æ€§
    print("   æ£€æŸ¥APIå…¼å®¹æ€§...")
    
    # æ£€æŸ¥æ–¹æ³•æ˜¯å¦å­˜åœ¨
    assert hasattr(enhanced_coordinator, 'coordinate_task_execution')
    assert hasattr(enhanced_coordinator, 'register_agent')
    assert hasattr(enhanced_coordinator, 'get_registered_agents')
    
    # æ£€æŸ¥æ™ºèƒ½ä½“æ³¨å†Œ
    agents_original = original_coordinator.get_registered_agents()
    agents_enhanced = enhanced_coordinator.get_registered_agents()
    
    assert len(agents_original) == len(agents_enhanced)
    print("   âœ… æ™ºèƒ½ä½“æ³¨å†Œå…¼å®¹")
    
    # 4. æµ‹è¯•æ ‡å‡†ä»»åŠ¡æ‰§è¡Œï¼ˆåº”è¯¥ä¸åŸæœ‰è¡Œä¸ºå®Œå…¨ç›¸åŒï¼‰
    standard_task = """
    è®¾è®¡ä¸€ä¸ªç®€å•çš„8ä½è®¡æ•°å™¨ï¼ŒåŒ…æ‹¬ï¼š
    - åŒæ­¥å¤ä½
    - ä½¿èƒ½æ§åˆ¶
    - è®¡æ•°è¾“å‡º
    """
    
    print("   æµ‹è¯•æ ‡å‡†ä»»åŠ¡æ‰§è¡Œ...")
    
    # æ³¨æ„ï¼šè¿™é‡Œåªæµ‹è¯•è°ƒç”¨æ¥å£ï¼Œä¸æ‰§è¡Œå®é™…LLMè°ƒç”¨ä»¥é¿å…æ¶ˆè€—
    try:
        # æµ‹è¯•æ–¹æ³•è°ƒç”¨ä¸ä¼šå‡ºé”™
        print("   âœ… æ ‡å‡†ä»»åŠ¡æ¥å£å…¼å®¹")
    except Exception as e:
        print(f"   âŒ å…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False
    
    print("âœ… å‘åå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
    return True


async def test_extension_features():
    """æµ‹è¯•æ‰©å±•åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æ‰©å±•åŠŸèƒ½...")
    
    # 1. åˆ›å»ºæµ‹è¯•é©±åŠ¨åè°ƒå™¨
    config = FrameworkConfig.from_env()
    original_coordinator = CentralizedCoordinator(config)
    
    # ä½¿ç”¨è‡ªå®šä¹‰é…ç½®
    tdd_config = TestDrivenConfig(
        max_iterations=3,
        enable_deep_analysis=True,
        timeout_per_iteration=60
    )
    
    tdd_coordinator = TestDrivenCoordinator(original_coordinator, tdd_config)
    
    # 2. æµ‹è¯•ä»»åŠ¡è§£æåŠŸèƒ½
    print("   æµ‹è¯•ä»»åŠ¡è§£æ...")
    
    test_task_with_tb = """
    è®¾è®¡ä¸€ä¸ª32ä½ALUæ¨¡å—ï¼Œæ”¯æŒåŠ å‡æ³•è¿ç®—ã€‚
    
    æµ‹è¯•è¦æ±‚ï¼š
    - æµ‹è¯•å°è·¯å¾„: /home/user/alu_testbench.v
    - å¿…é¡»é€šè¿‡æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹
    - å¦‚æœæµ‹è¯•å¤±è´¥è¯·è¿­ä»£æ”¹è¿›
    """
    
    # æµ‹è¯•ä»»åŠ¡è§£æå™¨
    from extensions.enhanced_task_parser import EnhancedTaskParser
    parser = EnhancedTaskParser()
    
    analysis = await parser.parse_enhanced_task(test_task_with_tb)
    
    # éªŒè¯è§£æç»“æœ
    assert analysis["is_test_driven"] == True
    assert "/home/user/alu_testbench.v" in str(analysis.get("testbench_path", ""))
    assert analysis["iteration_required"] == True
    
    print("   âœ… ä»»åŠ¡è§£æåŠŸèƒ½æ­£å¸¸")
    
    # 3. æµ‹è¯•æµ‹è¯•å°éªŒè¯åŠŸèƒ½
    print("   æµ‹è¯•æµ‹è¯•å°éªŒè¯...")
    
    from extensions.test_analyzer import TestAnalyzer
    analyzer = TestAnalyzer()
    
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿæµ‹è¯•å°å†…å®¹
    mock_testbench_content = """
module alu_tb;
    reg [31:0] a, b;
    reg [3:0] op;
    wire [31:0] result;
    wire zero;
    
    alu_32bit dut (
        .a(a),
        .b(b),
        .op(op),
        .result(result),
        .zero(zero)
    );
    
    initial begin
        $monitor("Time=%0t a=%h b=%h op=%b result=%h zero=%b", 
                 $time, a, b, op, result, zero);
        
        // Test cases
        a = 32'h12345678; b = 32'h87654321; op = 4'b0000; #10;
        a = 32'hFFFFFFFF; b = 32'h00000001; op = 4'b0001; #10;
        
        $finish;
    end
endmodule
"""
    
    # éªŒè¯æµ‹è¯•å°å†…å®¹ï¼ˆä¸ä¾èµ–å®é™…æ–‡ä»¶ï¼‰
    validations = analyzer._validate_testbench_content(mock_testbench_content)
    assert validations["is_valid"] == True
    assert validations["has_module"] == True
    assert validations["has_initial_block"] == True
    
    print("   âœ… æµ‹è¯•å°éªŒè¯åŠŸèƒ½æ­£å¸¸")
    
    # 4. æµ‹è¯•ä¼šè¯ç®¡ç†
    print("   æµ‹è¯•ä¼šè¯ç®¡ç†...")
    
    # æ£€æŸ¥åˆå§‹çŠ¶æ€
    active_sessions = tdd_coordinator.list_active_sessions()
    assert len(active_sessions) == 0
    
    # æ¨¡æ‹Ÿæ·»åŠ ä¼šè¯
    session_id = "test_session_123"
    tdd_coordinator.test_driven_sessions[session_id] = {
        "status": "running",
        "start_time": 1234567890,
        "iterations": []
    }
    
    active_sessions = tdd_coordinator.list_active_sessions()
    assert session_id in active_sessions
    
    session_info = tdd_coordinator.get_session_info(session_id)
    assert session_info is not None
    assert session_info["status"] == "running"
    
    print("   âœ… ä¼šè¯ç®¡ç†åŠŸèƒ½æ­£å¸¸")
    
    print("âœ… æ‰©å±•åŠŸèƒ½æµ‹è¯•é€šè¿‡")
    return True


async def test_task_type_detection():
    """æµ‹è¯•ä»»åŠ¡ç±»å‹è‡ªåŠ¨æ£€æµ‹"""
    print("ğŸ¯ æµ‹è¯•ä»»åŠ¡ç±»å‹è‡ªåŠ¨æ£€æµ‹...")
    
    from extensions.enhanced_task_parser import EnhancedTaskParser
    parser = EnhancedTaskParser()
    
    # æµ‹è¯•ç”¨ä¾‹
    test_cases = [
        {
            "description": "æ ‡å‡†è®¾è®¡ä»»åŠ¡",
            "task": "è®¾è®¡ä¸€ä¸ª8ä½è®¡æ•°å™¨ï¼Œæ”¯æŒåŒæ­¥å¤ä½å’Œä½¿èƒ½æ§åˆ¶",
            "expected_tdd": False
        },
        {
            "description": "å¸¦æµ‹è¯•å°è·¯å¾„çš„ä»»åŠ¡",
            "task": "è®¾è®¡ALUæ¨¡å—ï¼Œæµ‹è¯•å°: /path/to/tb.v",
            "expected_tdd": True
        },
        {
            "description": "åŒ…å«è¿­ä»£å…³é”®è¯çš„ä»»åŠ¡",
            "task": "è®¾è®¡è®¡æ•°å™¨ï¼Œå¦‚æœæµ‹è¯•å¤±è´¥è¯·è¿­ä»£æ”¹è¿›ç›´åˆ°é€šè¿‡",
            "expected_tdd": True
        },
        {
            "description": "åŒ…å«å¤šä¸ªTDDå…³é”®è¯",
            "task": "è®¾è®¡æ¨¡å—å¹¶éªŒè¯ï¼Œéœ€è¦æµ‹è¯•å’Œè°ƒè¯•ä¼˜åŒ–",
            "expected_tdd": True
        }
    ]
    
    for test_case in test_cases:
        analysis = await parser.parse_enhanced_task(test_case["task"])
        actual_tdd = analysis["is_test_driven"]
        expected_tdd = test_case["expected_tdd"]
        
        if actual_tdd == expected_tdd:
            print(f"   âœ… {test_case['description']}: {actual_tdd}")
        else:
            print(f"   âŒ {test_case['description']}: æœŸæœ› {expected_tdd}, å®é™… {actual_tdd}")
            return False
    
    print("âœ… ä»»åŠ¡ç±»å‹æ£€æµ‹æµ‹è¯•é€šè¿‡")
    return True


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•é©±åŠ¨æ‰©å±•åŠŸèƒ½éªŒè¯")
    print("=" * 60)
    
    tests = [
        ("å‘åå…¼å®¹æ€§", test_backward_compatibility),
        ("æ‰©å±•åŠŸèƒ½", test_extension_features),
        ("ä»»åŠ¡ç±»å‹æ£€æµ‹", test_task_type_detection)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ æ‰§è¡Œæµ‹è¯•: {test_name}")
        try:
            result = await test_func()
            if result:
                passed += 1
                print(f"âœ… {test_name} æµ‹è¯•é€šè¿‡")
            else:
                print(f"âŒ {test_name} æµ‹è¯•å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} æµ‹è¯•å¼‚å¸¸: {str(e)}")
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ‰©å±•åŠŸèƒ½å¯ä»¥å®‰å…¨ä½¿ç”¨ã€‚")
        print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print("from extensions import create_test_driven_coordinator")
        print("enhanced_coordinator = create_test_driven_coordinator(your_coordinator)")
        print("result = await enhanced_coordinator.execute_test_driven_task(task, testbench_path)")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
    
    return passed == total


if __name__ == "__main__":
    success = asyncio.run(main())
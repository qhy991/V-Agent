#!/usr/bin/env python3
"""
æ•°æ®æ”¶é›†åŠŸèƒ½æµ‹è¯•è„šæœ¬
====================

æµ‹è¯•æ”¹è¿›åçš„å®éªŒæŠ¥å‘Šç³»ç»Ÿï¼ŒéªŒè¯æ•°æ®æ”¶é›†åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

import asyncio
import json
import time
from pathlib import Path
from datetime import datetime

from core.llm_coordinator_agent import LLMCoordinatorAgent, TaskContext
from config.config import FrameworkConfig
from agents.enhanced_real_verilog_agent import EnhancedRealVerilogAgent
from agents.enhanced_real_code_reviewer import EnhancedRealCodeReviewAgent


async def test_data_collection():
    """æµ‹è¯•æ•°æ®æ”¶é›†åŠŸèƒ½"""
    print("ğŸ§ª å¼€å§‹æµ‹è¯•æ•°æ®æ”¶é›†åŠŸèƒ½...")
    
    # åˆ›å»ºé…ç½®
    config = FrameworkConfig()
    config.enable_detailed_logging = True
    
    # åˆ›å»ºåè°ƒæ™ºèƒ½ä½“
    coordinator = LLMCoordinatorAgent(config)
    
    # æ³¨å†Œæ™ºèƒ½ä½“
    verilog_agent = EnhancedRealVerilogAgent()
    reviewer_agent = EnhancedRealCodeReviewAgent()
    
    await coordinator.register_agent(verilog_agent)
    await coordinator.register_agent(reviewer_agent)
    
    # åˆ›å»ºä»»åŠ¡ä¸Šä¸‹æ–‡
    task_context = TaskContext(
        task_id="test_task_001",
        original_request="è®¾è®¡ä¸€ä¸ªç®€å•çš„4ä½è®¡æ•°å™¨",
        experiment_path="/tmp/test_experiment"
    )
    
    # è®¾ç½®ä»»åŠ¡ä¸Šä¸‹æ–‡
    coordinator.current_task_context = task_context
    
    # æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨
    print("ğŸ”§ æ¨¡æ‹Ÿå·¥å…·è°ƒç”¨...")
    task_context.add_tool_execution(
        tool_name="identify_task_type",
        parameters={"user_request": "è®¾è®¡ä¸€ä¸ª4ä½è®¡æ•°å™¨"},
        agent_id="llm_coordinator_agent",
        success=True,
        result={"task_type": "design", "complexity": "medium"},
        execution_time=2.5
    )
    
    task_context.add_tool_execution(
        tool_name="recommend_agent",
        parameters={"task_type": "design", "complexity": "medium"},
        agent_id="llm_coordinator_agent",
        success=True,
        result={"recommended_agent": "enhanced_real_verilog_agent"},
        execution_time=1.8
    )
    
    # æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œ
    print("ğŸ“ æ¨¡æ‹Ÿæ–‡ä»¶æ“ä½œ...")
    task_context.add_file_operation(
        operation_type="create",
        file_path="/tmp/test_experiment/designs/counter.v",
        agent_id="enhanced_real_verilog_agent",
        success=True,
        file_size=1024
    )
    
    task_context.add_file_operation(
        operation_type="create",
        file_path="/tmp/test_experiment/testbenches/counter_tb.v",
        agent_id="enhanced_real_code_reviewer",
        success=True,
        file_size=2048
    )
    
    # æ¨¡æ‹Ÿå·¥ä½œæµé˜¶æ®µ
    print("ğŸ”„ æ¨¡æ‹Ÿå·¥ä½œæµé˜¶æ®µ...")
    task_context.add_workflow_stage(
        stage_name="task_analysis",
        description="åˆ†æä»»åŠ¡éœ€æ±‚",
        agent_id="llm_coordinator_agent",
        duration=3.2,
        success=True
    )
    
    task_context.add_workflow_stage(
        stage_name="agent_execution_enhanced_real_verilog_agent",
        description="Verilogè®¾è®¡æ™ºèƒ½ä½“æ‰§è¡Œä»»åŠ¡",
        agent_id="enhanced_real_verilog_agent",
        duration=45.6,
        success=True,
        metadata={"task_type": "design", "priority": "medium"}
    )
    
    # æ¨¡æ‹Ÿæ™ºèƒ½ä½“äº¤äº’
    print("ğŸ¤– æ¨¡æ‹Ÿæ™ºèƒ½ä½“äº¤äº’...")
    task_context.agent_interactions.append({
        "timestamp": time.time(),
        "coordinator_id": "llm_coordinator_agent",
        "target_agent_id": "enhanced_real_verilog_agent",
        "task_description": "è®¾è®¡ä¸€ä¸ª4ä½è®¡æ•°å™¨æ¨¡å—...",
        "success": True,
        "execution_time": 45.6,
        "response_length": 1500
    })
    
    # ğŸ†• æ¨¡æ‹ŸLLMå¯¹è¯è®°å½•
    print("ğŸ§  æ¨¡æ‹ŸLLMå¯¹è¯è®°å½•...")
    task_context.add_llm_conversation(
        agent_id="llm_coordinator_agent",
        conversation_id="coordinator_agent_test_task_001",
        system_prompt="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åè°ƒè€…ï¼Œè´Ÿè´£åˆ†æä»»åŠ¡å¹¶åˆ†é…ç»™åˆé€‚çš„æ™ºèƒ½ä½“...",
        user_message="è¯·è®¾è®¡ä¸€ä¸ª4ä½è®¡æ•°å™¨æ¨¡å—ï¼ŒåŒ…å«æ—¶é’Ÿã€å¤ä½ã€ä½¿èƒ½è¾“å…¥ï¼Œæ”¯æŒå‘ä¸Šè®¡æ•°åŠŸèƒ½ã€‚",
        assistant_response="æˆ‘å°†åˆ†æè¿™ä¸ªä»»åŠ¡å¹¶åˆ†é…ç»™åˆé€‚çš„æ™ºèƒ½ä½“ã€‚è¿™æ˜¯ä¸€ä¸ªVerilogè®¾è®¡ä»»åŠ¡ï¼Œå¤æ‚åº¦ä¸ºä¸­ç­‰ï¼Œå»ºè®®åˆ†é…ç»™enhanced_real_verilog_agentã€‚",
        model_name="claude-3.5-sonnet",
        duration=2.5,
        success=True,
        is_first_call=True,
        temperature=0.3,
        max_tokens=4000,
        prompt_tokens=150,
        completion_tokens=80,
        total_tokens=230
    )
    
    task_context.add_llm_conversation(
        agent_id="enhanced_real_verilog_agent",
        conversation_id="verilog_agent_test_task_001",
        system_prompt="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„Verilogè®¾è®¡æ™ºèƒ½ä½“ï¼Œè´Ÿè´£ç”Ÿæˆé«˜è´¨é‡çš„Verilogä»£ç ...",
        user_message="è®¾è®¡ä¸€ä¸ª4ä½è®¡æ•°å™¨æ¨¡å—ï¼ŒåŒ…å«æ—¶é’Ÿã€å¤ä½ã€ä½¿èƒ½è¾“å…¥ï¼Œæ”¯æŒå‘ä¸Šè®¡æ•°åŠŸèƒ½ã€‚",
        assistant_response="æˆ‘å°†ä¸ºæ‚¨è®¾è®¡ä¸€ä¸ª4ä½è®¡æ•°å™¨æ¨¡å—ã€‚è¿™ä¸ªæ¨¡å—å°†åŒ…å«æ—¶é’Ÿ(clk)ã€å¤ä½(rst)ã€ä½¿èƒ½(en)è¾“å…¥ï¼Œä»¥åŠ4ä½è®¡æ•°è¾“å‡º(count)ã€‚",
        model_name="claude-3.5-sonnet",
        duration=3.8,
        success=True,
        is_first_call=True,
        temperature=0.2,
        max_tokens=4000,
        prompt_tokens=200,
        completion_tokens=120,
        total_tokens=320
    )
    
    # è·å–æ•°æ®æ”¶é›†æ‘˜è¦
    print("ğŸ“Š è·å–æ•°æ®æ”¶é›†æ‘˜è¦...")
    summary = task_context.get_data_collection_summary()
    
    # æ‰“å°æ‘˜è¦
    print("\n" + "="*60)
    print("ğŸ“Š æ•°æ®æ”¶é›†æ‘˜è¦")
    print("="*60)
    
    print(f"å·¥å…·è°ƒç”¨ç»Ÿè®¡:")
    print(f"  æ€»æ•°: {summary['tool_executions']['total']}")
    print(f"  æˆåŠŸ: {summary['tool_executions']['successful']}")
    print(f"  å¤±è´¥: {summary['tool_executions']['failed']}")
    print(f"  ä½¿ç”¨å·¥å…·: {', '.join(summary['tool_executions']['unique_tools'])}")
    print(f"  æ€»æ‰§è¡Œæ—¶é—´: {summary['tool_executions']['total_execution_time']:.2f}ç§’")
    
    print(f"\næ–‡ä»¶æ“ä½œç»Ÿè®¡:")
    print(f"  æ€»æ•°: {summary['file_operations']['total']}")
    print(f"  æˆåŠŸ: {summary['file_operations']['successful']}")
    print(f"  å¤±è´¥: {summary['file_operations']['failed']}")
    print(f"  æ“ä½œç±»å‹: {', '.join(summary['file_operations']['operation_types'])}")
    print(f"  æ€»æ–‡ä»¶å¤§å°: {summary['file_operations']['total_file_size']} å­—èŠ‚")
    
    print(f"\nå·¥ä½œæµé˜¶æ®µç»Ÿè®¡:")
    print(f"  æ€»æ•°: {summary['workflow_stages']['total']}")
    print(f"  æˆåŠŸ: {summary['workflow_stages']['successful']}")
    print(f"  å¤±è´¥: {summary['workflow_stages']['failed']}")
    print(f"  æ€»æ—¶é—´: {summary['workflow_stages']['total_duration']:.2f}ç§’")
    
    print(f"\næ™ºèƒ½ä½“äº¤äº’ç»Ÿè®¡:")
    print(f"  æ€»æ•°: {summary['agent_interactions']['total']}")
    print(f"  æˆåŠŸ: {summary['agent_interactions']['successful']}")
    print(f"  å¤±è´¥: {summary['agent_interactions']['failed']}")
    print(f"  å‚ä¸æ™ºèƒ½ä½“: {', '.join(summary['agent_interactions']['unique_agents'])}")
    
    print(f"\næ‰§è¡Œæ—¶é—´çº¿ç»Ÿè®¡:")
    print(f"  æ€»äº‹ä»¶: {summary['execution_timeline']['total_events']}")
    print(f"  äº‹ä»¶ç±»å‹: {', '.join(summary['execution_timeline']['event_types'])}")
    
    print(f"\nLLMå¯¹è¯ç»Ÿè®¡:")
    print(f"  æ€»æ•°: {summary['llm_conversations']['total']}")
    print(f"  æˆåŠŸ: {summary['llm_conversations']['successful']}")
    print(f"  å¤±è´¥: {summary['llm_conversations']['failed']}")
    print(f"  å‚ä¸æ™ºèƒ½ä½“: {', '.join(summary['llm_conversations']['unique_agents'])}")
    print(f"  ä½¿ç”¨æ¨¡å‹: {', '.join(summary['llm_conversations']['unique_models'])}")
    print(f"  é¦–æ¬¡è°ƒç”¨: {summary['llm_conversations']['first_calls']} æ¬¡")
    print(f"  æ€»å¯¹è¯æ—¶é—´: {summary['llm_conversations']['total_duration']:.2f}ç§’")
    print(f"  æ€»Tokenæ•°: {summary['llm_conversations']['total_tokens']} ä¸ª")
    
    # æµ‹è¯•æœ€ç»ˆç»“æœæ”¶é›†
    print("\nğŸ” æµ‹è¯•æœ€ç»ˆç»“æœæ”¶é›†...")
    final_result = coordinator._collect_final_result(task_context, "ä»»åŠ¡å®Œæˆ")
    
    # ä¿å­˜æµ‹è¯•ç»“æœ
    output_dir = Path("test_output")
    output_dir.mkdir(exist_ok=True)
    
    result_file = output_dir / "data_collection_test_result.json"
    with open(result_file, 'w', encoding='utf-8') as f:
        json.dump(final_result, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"âœ… æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    
    # éªŒè¯æ•°æ®å®Œæ•´æ€§
    print("\nğŸ” éªŒè¯æ•°æ®å®Œæ•´æ€§...")
    task_context_data = final_result.get('task_context', {})
    
    assert len(task_context_data.get('tool_executions', [])) > 0, "å·¥å…·è°ƒç”¨è®°å½•ä¸ºç©º"
    assert len(task_context_data.get('file_operations', [])) > 0, "æ–‡ä»¶æ“ä½œè®°å½•ä¸ºç©º"
    assert len(task_context_data.get('workflow_stages', [])) > 0, "å·¥ä½œæµé˜¶æ®µè®°å½•ä¸ºç©º"
    assert len(task_context_data.get('agent_interactions', [])) > 0, "æ™ºèƒ½ä½“äº¤äº’è®°å½•ä¸ºç©º"
    assert len(task_context_data.get('execution_timeline', [])) > 0, "æ‰§è¡Œæ—¶é—´çº¿è®°å½•ä¸ºç©º"
    assert len(task_context_data.get('llm_conversations', [])) > 0, "LLMå¯¹è¯è®°å½•ä¸ºç©º"
    assert task_context_data.get('data_collection_summary'), "æ•°æ®æ”¶é›†æ‘˜è¦ä¸ºç©º"
    
    print("âœ… æ‰€æœ‰æ•°æ®æ”¶é›†åŠŸèƒ½éªŒè¯é€šè¿‡ï¼")
    
    return final_result


async def main():
    """ä¸»å‡½æ•°"""
    try:
        result = await test_data_collection()
        print("\nğŸ‰ æ•°æ®æ”¶é›†åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        
        # æ˜¾ç¤ºæœ€ç»ˆç»“æœæ‘˜è¦
        task_context = result.get('task_context', {})
        summary = task_context.get('data_collection_summary', {})
        
        print(f"\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡:")
        print(f"  å·¥å…·è°ƒç”¨: {summary.get('tool_executions', {}).get('total', 0)} æ¬¡")
        print(f"  æ–‡ä»¶æ“ä½œ: {summary.get('file_operations', {}).get('total', 0)} æ¬¡")
        print(f"  å·¥ä½œæµé˜¶æ®µ: {summary.get('workflow_stages', {}).get('total', 0)} ä¸ª")
        print(f"  æ™ºèƒ½ä½“äº¤äº’: {summary.get('agent_interactions', {}).get('total', 0)} æ¬¡")
        print(f"  æ‰§è¡Œäº‹ä»¶: {summary.get('execution_timeline', {}).get('total_events', 0)} ä¸ª")
        print(f"  LLMå¯¹è¯: {summary.get('llm_conversations', {}).get('total', 0)} æ¬¡")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main()) 
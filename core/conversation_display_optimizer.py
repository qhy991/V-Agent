#!/usr/bin/env python3
"""
å¯¹è¯æ˜¾ç¤ºä¼˜åŒ–å™¨
è§£å†³å¯¹è¯å†å²æ‹¼æ¥å¯¼è‡´è¾“å‡ºè¶Šæ¥è¶Šé•¿çš„é—®é¢˜
"""

import logging
from typing import List, Dict, Any, Optional
from datetime import datetime


class ConversationDisplayOptimizer:
    """å¯¹è¯æ˜¾ç¤ºä¼˜åŒ–å™¨ - åªæ˜¾ç¤ºæœ€æ–°ä¸€è½®å¯¹è¯ï¼Œé¿å…è¾“å‡ºå†—ä½™"""
    
    def __init__(self, max_display_rounds: int = 1, enable_compact_mode: bool = True):
        """
        åˆå§‹åŒ–å¯¹è¯æ˜¾ç¤ºä¼˜åŒ–å™¨
        
        Args:
            max_display_rounds: æœ€å¤§æ˜¾ç¤ºè½®æ•°ï¼Œé»˜è®¤åªæ˜¾ç¤ºå½“å‰è½®
            enable_compact_mode: æ˜¯å¦å¯ç”¨ç´§å‡‘æ¨¡å¼
        """
        self.max_display_rounds = max_display_rounds
        self.enable_compact_mode = enable_compact_mode
        self.logger = logging.getLogger(self.__class__.__name__)
    
    def display_current_round_only(self, 
                                 user_request: str, 
                                 ai_response: str, 
                                 iteration_count: int = 1,
                                 agent_id: str = "unknown",
                                 additional_info: Optional[Dict[str, Any]] = None) -> str:
        """
        åªæ˜¾ç¤ºå½“å‰è½®æ¬¡çš„å¯¹è¯ï¼Œé¿å…å†å²ç´¯ç§¯
        
        Args:
            user_request: ç”¨æˆ·è¯·æ±‚
            ai_response: AIå“åº” 
            iteration_count: è¿­ä»£æ¬¡æ•°
            agent_id: æ™ºèƒ½ä½“ID
            additional_info: é¢å¤–ä¿¡æ¯
            
        Returns:
            æ ¼å¼åŒ–çš„å½“å‰è½®æ¬¡æ˜¾ç¤ºå†…å®¹
        """
        timestamp = datetime.now().strftime("%H:%M:%S")
        
        # æ„å»ºæ˜¾ç¤ºå†…å®¹
        display_parts = []
        
        # æ ‡é¢˜
        display_parts.append(f"\n{'='*60}")
        display_parts.append(f"ğŸ”„ ç¬¬ {iteration_count} è½®å¯¹è¯ | {agent_id} | {timestamp}")
        display_parts.append(f"{'='*60}")
        
        # ç”¨æˆ·è¯·æ±‚ï¼ˆå¦‚æœå¯ç”¨ç´§å‡‘æ¨¡å¼ï¼Œåˆ™æˆªæ–­é•¿å†…å®¹ï¼‰
        if self.enable_compact_mode and len(user_request) > 200:
            truncated_request = user_request[:200] + "...[æˆªæ–­]"
            display_parts.append(f"ğŸ“¤ ç”¨æˆ·è¯·æ±‚: {truncated_request}")
        else:
            display_parts.append(f"ğŸ“¤ ç”¨æˆ·è¯·æ±‚: {user_request}")
        
        # AIå“åº”ï¼ˆå¦‚æœå¯ç”¨ç´§å‡‘æ¨¡å¼ï¼Œåˆ™æˆªæ–­é•¿å†…å®¹ï¼‰
        if self.enable_compact_mode and len(ai_response) > 500:
            truncated_response = ai_response[:500] + "...[æˆªæ–­]"
            display_parts.append(f"ğŸ“¥ AIå“åº”: {truncated_response}")
        else:
            display_parts.append(f"ğŸ“¥ AIå“åº”: {ai_response}")
        
        # é¢å¤–ä¿¡æ¯
        if additional_info:
            display_parts.append(f"ğŸ“Š é¢å¤–ä¿¡æ¯:")
            for key, value in additional_info.items():
                display_parts.append(f"   - {key}: {value}")
        
        display_parts.append(f"ğŸ”š ç¬¬ {iteration_count} è½®å®Œæˆ")
        display_parts.append(f"{'='*60}\n")
        
        return "\n".join(display_parts)
    
    def optimize_conversation_history(self, 
                                    conversation_history: List[Dict[str, str]], 
                                    keep_last_n_turns: int = 2) -> List[Dict[str, str]]:
        """
        ä¼˜åŒ–å¯¹è¯å†å²ï¼Œåªä¿ç•™æœ€è¿‘Nè½®å¯¹è¯
        
        Args:
            conversation_history: å®Œæ•´å¯¹è¯å†å²
            keep_last_n_turns: ä¿ç•™æœ€è¿‘Nè½®å¯¹è¯
            
        Returns:
            ä¼˜åŒ–åçš„å¯¹è¯å†å²
        """
        if not conversation_history:
            return conversation_history
        
        # æ‰¾åˆ°system prompt
        system_messages = [msg for msg in conversation_history if msg.get("role") == "system"]
        non_system_messages = [msg for msg in conversation_history if msg.get("role") != "system"]
        
        # åªä¿ç•™æœ€è¿‘çš„Nè½®å¯¹è¯ï¼ˆæ¯è½®åŒ…å«userå’Œassistantæ¶ˆæ¯ï¼‰
        if len(non_system_messages) > keep_last_n_turns * 2:
            recent_messages = non_system_messages[-(keep_last_n_turns * 2):]
        else:
            recent_messages = non_system_messages
        
        # é‡æ–°ç»„åˆï¼šsystem messages + æœ€è¿‘çš„å¯¹è¯
        optimized_history = system_messages + recent_messages
        
        self.logger.info(f"ğŸ”§ å¯¹è¯å†å²ä¼˜åŒ–: {len(conversation_history)} -> {len(optimized_history)} æ¡æ¶ˆæ¯")
        
        return optimized_history
    
    def create_conversation_summary(self, 
                                  conversation_history: List[Dict[str, str]]) -> str:
        """
        åˆ›å»ºå¯¹è¯å†å²æ‘˜è¦ï¼Œç”¨äºæ›¿ä»£å®Œæ•´å†å²
        
        Args:
            conversation_history: å¯¹è¯å†å²
            
        Returns:
            å¯¹è¯æ‘˜è¦
        """
        if not conversation_history:
            return "æ— å¯¹è¯å†å²"
        
        non_system_messages = [msg for msg in conversation_history if msg.get("role") != "system"]
        
        if len(non_system_messages) <= 4:  # 2è½®å¯¹è¯ä»¥å†…
            return "å¯¹è¯è¾ƒçŸ­ï¼Œä¿ç•™å®Œæ•´å†å²"
        
        # ç»Ÿè®¡ä¿¡æ¯
        user_messages = len([msg for msg in non_system_messages if msg.get("role") == "user"])
        assistant_messages = len([msg for msg in non_system_messages if msg.get("role") == "assistant"])
        
        # è·å–ç¬¬ä¸€è½®å’Œæœ€åä¸€è½®çš„ä¸»é¢˜
        first_user_msg = next((msg for msg in non_system_messages if msg.get("role") == "user"), {})
        last_user_msg = next((msg for msg in reversed(non_system_messages) if msg.get("role") == "user"), {})
        
        first_topic = first_user_msg.get("content", "")[:50] + "..." if len(first_user_msg.get("content", "")) > 50 else first_user_msg.get("content", "")
        last_topic = last_user_msg.get("content", "")[:50] + "..." if len(last_user_msg.get("content", "")) > 50 else last_user_msg.get("content", "")
        
        summary = f"""
ğŸ“‹ å¯¹è¯å†å²æ‘˜è¦:
- æ€»è½®æ•°: {user_messages} è½®
- ç”¨æˆ·æ¶ˆæ¯: {user_messages} æ¡
- AIå“åº”: {assistant_messages} æ¡
- é¦–è½®ä¸»é¢˜: {first_topic}
- æœ«è½®ä¸»é¢˜: {last_topic}
- çŠ¶æ€: ä¿ç•™æœ€è¿‘2è½®å®Œæ•´å¯¹è¯ï¼Œå…¶ä½™å·²å‹ç¼©
        """.strip()
        
        return summary
    
    def apply_display_optimization(self, 
                                 original_output: str, 
                                 current_round_info: Dict[str, Any]) -> str:
        """
        åº”ç”¨æ˜¾ç¤ºä¼˜åŒ–ï¼Œæ›¿æ¢åŸå§‹è¾“å‡ºä¸­çš„å†—ä½™å†…å®¹
        
        Args:
            original_output: åŸå§‹è¾“å‡ºå†…å®¹
            current_round_info: å½“å‰è½®æ¬¡ä¿¡æ¯
            
        Returns:
            ä¼˜åŒ–åçš„è¾“å‡ºå†…å®¹
        """
        # å¦‚æœåŸå§‹è¾“å‡ºè¿‡é•¿ï¼Œä½¿ç”¨ä¼˜åŒ–æ˜¾ç¤º
        if len(original_output) > 2000:
            self.logger.info("ğŸ”§ æ£€æµ‹åˆ°è¾“å‡ºè¿‡é•¿ï¼Œåº”ç”¨æ˜¾ç¤ºä¼˜åŒ–")
            return self.display_current_round_only(
                user_request=current_round_info.get("user_request", ""),
                ai_response=current_round_info.get("ai_response", "")[:500] + "...[å·²ä¼˜åŒ–æ˜¾ç¤º]",
                iteration_count=current_round_info.get("iteration_count", 1),
                agent_id=current_round_info.get("agent_id", "unknown"),
                additional_info={
                    "åŸå§‹é•¿åº¦": f"{len(original_output)} å­—ç¬¦",
                    "ä¼˜åŒ–çŠ¶æ€": "å·²åº”ç”¨æ˜¾ç¤ºä¼˜åŒ–"
                }
            )
        
        return original_output


# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
conversation_optimizer = ConversationDisplayOptimizer(
    max_display_rounds=1,
    enable_compact_mode=True
)


def optimize_agent_output(agent_id: str, 
                         user_request: str, 
                         ai_response: str, 
                         iteration_count: int = 1) -> str:
    """
    ä¾¿æ·å‡½æ•°ï¼šä¼˜åŒ–æ™ºèƒ½ä½“è¾“å‡ºæ˜¾ç¤º
    
    Args:
        agent_id: æ™ºèƒ½ä½“ID
        user_request: ç”¨æˆ·è¯·æ±‚
        ai_response: AIå“åº”
        iteration_count: è¿­ä»£æ¬¡æ•°
        
    Returns:
        ä¼˜åŒ–åçš„æ˜¾ç¤ºå†…å®¹
    """
    return conversation_optimizer.display_current_round_only(
        user_request=user_request,
        ai_response=ai_response,
        iteration_count=iteration_count,
        agent_id=agent_id
    )


def optimize_conversation_for_ollama(conversation_history: List[Dict[str, str]]) -> List[Dict[str, str]]:
    """
    ä¾¿æ·å‡½æ•°ï¼šä¸ºOllamaä¼˜åŒ–å¯¹è¯å†å²æ ¼å¼
    
    Args:
        conversation_history: åŸå§‹å¯¹è¯å†å²
        
    Returns:
        ä¼˜åŒ–åçš„å¯¹è¯å†å²
    """
    return conversation_optimizer.optimize_conversation_history(
        conversation_history=conversation_history,
        keep_last_n_turns=2  # Ollamaé€šå¸¸ä¸éœ€è¦å¤ªé•¿çš„å†å²
    )


if __name__ == "__main__":
    # æµ‹è¯•æ˜¾ç¤ºä¼˜åŒ–å™¨
    optimizer = ConversationDisplayOptimizer()
    
    # æµ‹è¯•å½“å‰è½®æ˜¾ç¤º
    display_content = optimizer.display_current_round_only(
        user_request="è®¾è®¡ä¸€ä¸ªè®¡æ•°å™¨æ¨¡å—",
        ai_response="æˆ‘å°†ä¸ºæ‚¨è®¾è®¡ä¸€ä¸ª8ä½è®¡æ•°å™¨æ¨¡å—...",
        iteration_count=1,
        agent_id="verilog_agent",
        additional_info={"æ‰§è¡Œæ—¶é—´": "1.5ç§’", "å·¥å…·è°ƒç”¨": "write_file"}
    )
    
    print(display_content)
    
    # æµ‹è¯•å¯¹è¯å†å²ä¼˜åŒ–
    sample_history = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªVerilogè®¾è®¡åŠ©æ‰‹"},
        {"role": "user", "content": "è®¾è®¡ALU"},
        {"role": "assistant", "content": "å¥½çš„ï¼Œæˆ‘å°†è®¾è®¡ALU..."},
        {"role": "user", "content": "æ·»åŠ æµ‹è¯•å°"},
        {"role": "assistant", "content": "æˆ‘å°†æ·»åŠ æµ‹è¯•å°..."},
        {"role": "user", "content": "ä¿®å¤é”™è¯¯"},
        {"role": "assistant", "content": "æˆ‘å°†ä¿®å¤é”™è¯¯..."}
    ]
    
    optimized_history = optimizer.optimize_conversation_history(sample_history)
    print(f"\nå†å²ä¼˜åŒ–: {len(sample_history)} -> {len(optimized_history)} æ¡æ¶ˆæ¯")
    
    summary = optimizer.create_conversation_summary(sample_history)
    print(f"\n{summary}")
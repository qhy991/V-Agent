"""
ğŸ§  å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ
==================================================

è¯¥ç³»ç»Ÿè´Ÿè´£ç®¡ç†TDDè¿­ä»£è¿‡ç¨‹ä¸­çš„å®Œæ•´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œç¡®ä¿æ¯ä¸ªagentéƒ½èƒ½è®¿é—®ï¼š
- å®Œæ•´çš„ä»£ç å†…å®¹ï¼ˆåŒ…æ‹¬å…·ä½“å‡ºé”™è¡Œï¼‰
- å®Œæ•´çš„å¯¹è¯å†å²ï¼ˆåŒ…æ‹¬AIæ¨ç†è¿‡ç¨‹ï¼‰
- å¤šagentåä½œçš„å…¨é‡ä¸Šä¸‹æ–‡
- å…³é”®å­—æ®µçš„å®Œæ•´ä¿å­˜å’Œä¼ é€’
"""

import json
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from pathlib import Path


@dataclass
class CodeContext:
    """ä»£ç ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    file_path: str
    content: str
    content_with_line_numbers: str
    module_name: str
    last_modified: float
    syntax_errors: List[Dict[str, Any]] = None
    error_lines: Dict[int, str] = None  # é”™è¯¯è¡Œå· -> å…·ä½“å†…å®¹
    
    def get_error_context(self, error_line: int, context_lines: int = 5) -> str:
        """è·å–é”™è¯¯è¡Œçš„ä¸Šä¸‹æ–‡"""
        lines = self.content.split('\n')
        start = max(0, error_line - context_lines - 1)
        end = min(len(lines), error_line + context_lines)
        
        context = []
        for i in range(start, end):
            marker = ">>> " if i == error_line - 1 else "    "
            context.append(f"{marker}{i+1:3d}: {lines[i]}")
        
        return "\n".join(context)


@dataclass
class ConversationTurn:
    """å¯¹è¯è½®æ¬¡ä¿¡æ¯"""
    turn_id: str
    agent_id: str
    timestamp: float
    user_prompt: str
    system_prompt: str
    ai_response: str
    tool_calls: List[Dict[str, Any]] = None
    tool_results: List[Dict[str, Any]] = None
    reasoning_notes: str = ""
    success: bool = False
    error_info: Dict[str, Any] = None


@dataclass
class IterationContext:
    """è¿­ä»£ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    iteration_id: str
    iteration_number: int
    timestamp: float
    code_files: Dict[str, CodeContext]
    testbench_files: Dict[str, CodeContext]
    conversation_turns: List[ConversationTurn]
    # ğŸ¯ æ–°å¢ï¼šç«¯å£ä¿¡æ¯ç®¡ç†
    port_info: Dict[str, Dict[str, Any]] = None  # module_name -> port_info
    agent_assignments: Dict[str, str] = None  # role -> agent_id
    # ğŸ¯ ä¿®å¤ï¼šæ·»åŠ ç¼ºå¤±çš„compilation_errorså±æ€§
    compilation_errors: List[Dict[str, Any]] = None
    simulation_errors: List[Dict[str, Any]] = None
    
    def __post_init__(self):
        if self.port_info is None:
            self.port_info = {}
        if self.agent_assignments is None:
            self.agent_assignments = {}
        if self.compilation_errors is None:
            self.compilation_errors = []
        if self.simulation_errors is None:
            self.simulation_errors = []


class FullContextManager:
    """å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, session_id: str):
        self.session_id = session_id
        self.iterations: Dict[str, IterationContext] = {}
        self.current_iteration: Optional[IterationContext] = None
        self.global_context: Dict[str, Any] = {
            "session_start_time": time.time(),
            "task_description": "",
            "testbench_path": "",
            "design_requirements": "",
            "persistent_conversation_id": None,
            "agent_selections": {},  # è®°å½•æ¯ä¸ªé˜¶æ®µé€‰æ‹©çš„agent
            
            # ğŸ¯ æ–°å¢ï¼šå…¨å±€æˆåŠŸç»éªŒç´¯ç§¯
            "success_patterns": {
                "verilog_syntax": {
                    "correct_patterns": [],
                    "avoid_patterns": []
                },
                "interface_compliance": {
                    "correct_patterns": [],
                    "avoid_patterns": []
                },
                "overflow_detection": {
                    "correct_patterns": [],
                    "avoid_patterns": []
                }
            },
            "error_lessons": [],
            "successful_code_snippets": [],
            "failure_patterns": [],
            # ğŸ¯ æ–°å¢ï¼šç«¯å£ä¿¡æ¯å…¨å±€ç¼“å­˜
            "global_port_info": {}  # module_name -> port_info
        }
    
    def add_port_info(self, module_name: str, port_info: Dict[str, Any]) -> None:
        """æ·»åŠ ç«¯å£ä¿¡æ¯åˆ°å½“å‰è¿­ä»£å’Œå…¨å±€ç¼“å­˜"""
        if self.current_iteration:
            self.current_iteration.port_info[module_name] = port_info
        
        # åŒæ—¶æ›´æ–°å…¨å±€ç¼“å­˜
        self.global_context["global_port_info"][module_name] = port_info
    
    def get_port_info(self, module_name: str) -> Optional[Dict[str, Any]]:
        """è·å–æ¨¡å—çš„ç«¯å£ä¿¡æ¯"""
        # ä¼˜å…ˆä»å½“å‰è¿­ä»£è·å–
        if self.current_iteration and module_name in self.current_iteration.port_info:
            return self.current_iteration.port_info[module_name]
        
        # ä»å…¨å±€ç¼“å­˜è·å–
        return self.global_context["global_port_info"].get(module_name)
    
    def get_all_port_info(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰ç«¯å£ä¿¡æ¯"""
        all_ports = {}
        
        # åˆå¹¶å½“å‰è¿­ä»£å’Œå…¨å±€ç¼“å­˜çš„ç«¯å£ä¿¡æ¯
        if self.current_iteration:
            all_ports.update(self.current_iteration.port_info)
        
        all_ports.update(self.global_context["global_port_info"])
        
        return all_ports
    
    def validate_port_consistency(self, module_name: str, testbench_content: str) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•å°ç«¯å£ä¸è®¾è®¡ç«¯å£çš„ä¸€è‡´æ€§"""
        design_ports = self.get_port_info(module_name)
        if not design_ports:
            return {"valid": False, "error": f"æœªæ‰¾åˆ°æ¨¡å— {module_name} çš„ç«¯å£ä¿¡æ¯"}
        
        import re
        
        # æå–æµ‹è¯•å°ä¸­çš„æ¨¡å—å®ä¾‹åŒ–
        instance_pattern = rf'{module_name}\s+\w+\s*\(([^)]+)\);'
        match = re.search(instance_pattern, testbench_content, re.DOTALL)
        
        if not match:
            return {"valid": False, "error": f"æœªæ‰¾åˆ°æ¨¡å— {module_name} çš„å®ä¾‹åŒ–"}
        
        instance_ports = match.group(1)
        port_connections = []
        
        # è§£æç«¯å£è¿æ¥
        for line in instance_ports.split(','):
            line = line.strip()
            if not line:
                continue
            
            port_match = re.search(r'\.(\w+)\s*\(\s*(\w+)\s*\)', line)
            if port_match:
                port_name = port_match.group(1)
                signal_name = port_match.group(2)
                port_connections.append({"port": port_name, "signal": signal_name})
        
        # éªŒè¯ç«¯å£è¿æ¥
        design_port_names = {port["name"] for port in design_ports["ports"]}
        testbench_port_names = {conn["port"] for conn in port_connections}
        
        missing_ports = design_port_names - testbench_port_names
        extra_ports = testbench_port_names - design_port_names
        
        return {
            "valid": len(missing_ports) == 0 and len(extra_ports) == 0,
            "missing_ports": list(missing_ports),
            "extra_ports": list(extra_ports),
            "design_ports": design_ports,
            "testbench_connections": port_connections
        }
    
    def start_new_iteration(self, iteration_number: int) -> str:
        """å¼€å§‹æ–°çš„è¿­ä»£"""
        iteration_id = f"{self.session_id}_iter_{iteration_number}"
        
        self.current_iteration = IterationContext(
            iteration_id=iteration_id,
            iteration_number=iteration_number,
            timestamp=time.time(),
            code_files={},
            testbench_files={},
            conversation_turns=[]
        )
        
        self.iterations[iteration_id] = self.current_iteration
        return iteration_id
    
    def add_conversation_turn(self, agent_id: str, user_prompt: str, 
                            system_prompt: str, ai_response: str,
                            tool_calls: List[Dict] = None, 
                            tool_results: List[Dict] = None,
                            reasoning_notes: str = "") -> str:
        """æ·»åŠ å¯¹è¯è½®æ¬¡"""
        if not self.current_iteration:
            raise ValueError("æ²¡æœ‰æ´»è·ƒçš„è¿­ä»£")
        
        turn_id = f"{self.current_iteration.iteration_id}_turn_{len(self.current_iteration.conversation_turns) + 1}"
        
        turn = ConversationTurn(
            turn_id=turn_id,
            agent_id=agent_id,
            timestamp=time.time(),
            user_prompt=user_prompt,
            system_prompt=system_prompt,
            ai_response=ai_response,
            tool_calls=tool_calls or [],
            tool_results=tool_results or [],
            reasoning_notes=reasoning_notes
        )
        
        self.current_iteration.conversation_turns.append(turn)
        return turn_id
    
    def add_code_file(self, file_path: str, content: str, module_name: str, 
                     file_type: str = "design") -> None:
        """æ·»åŠ ä»£ç æ–‡ä»¶"""
        if not self.current_iteration:
            raise ValueError("æ²¡æœ‰æ´»è·ƒçš„è¿­ä»£")
        
        # ç”Ÿæˆå¸¦è¡Œå·çš„å†…å®¹
        lines = content.split('\n')
        content_with_line_numbers = "\n".join([
            f"{i+1:4d}â†’{line}" for i, line in enumerate(lines)
        ])
        
        code_context = CodeContext(
            file_path=file_path,
            content=content,
            content_with_line_numbers=content_with_line_numbers,
            module_name=module_name,
            last_modified=time.time()
        )
        
        if file_type == "design":
            self.current_iteration.code_files[file_path] = code_context
        else:
            self.current_iteration.testbench_files[file_path] = code_context
    
    def add_compilation_errors(self, errors: List[Dict[str, Any]]) -> None:
        """æ·»åŠ ç¼–è¯‘é”™è¯¯ä¿¡æ¯"""
        if not self.current_iteration:
            return
        
        self.current_iteration.compilation_errors = errors
        self.current_iteration.compilation_success = len(errors) == 0
        
        # ä¸ºæ¯ä¸ªä»£ç æ–‡ä»¶æ ‡è®°é”™è¯¯è¡Œ
        for error in errors:
            if 'file' in error and 'line' in error:
                file_path = error['file']
                line_number = int(error['line'])
                
                # æ‰¾åˆ°å¯¹åº”çš„ä»£ç æ–‡ä»¶
                code_context = None
                if file_path in self.current_iteration.code_files:
                    code_context = self.current_iteration.code_files[file_path]
                elif file_path in self.current_iteration.testbench_files:
                    code_context = self.current_iteration.testbench_files[file_path]
                
                if code_context:
                    if not code_context.error_lines:
                        code_context.error_lines = {}
                    
                    # è·å–é”™è¯¯è¡Œçš„å…·ä½“å†…å®¹
                    lines = code_context.content.split('\n')
                    if 0 <= line_number - 1 < len(lines):
                        code_context.error_lines[line_number] = lines[line_number - 1]
        
        # ğŸ¯ æ–°å¢ï¼šä»é”™è¯¯ä¸­å­¦ä¹ ç»éªŒæ•™è®­
        self._extract_error_lessons(errors)
    
    def get_full_context_for_agent(self, agent_id: str, current_task: str) -> Dict[str, Any]:
        """ä¸ºagentæ„å»ºå®Œæ•´ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = {
            "session_info": {
                "session_id": self.session_id,
                "total_iterations": len(self.iterations),
                "current_iteration_number": self.current_iteration.iteration_number if self.current_iteration else 0,
                "task_description": self.global_context["task_description"],
                "current_task": current_task
            },
            
            "complete_code_content": self._get_complete_code_content(),
            "complete_conversation_history": self._get_complete_conversation_history(),
            "detailed_error_context": self._get_detailed_error_context(),
            "previous_iterations_summary": self._get_previous_iterations_summary(),
            "agent_collaboration_history": self._get_agent_collaboration_history(),
            # ğŸ¯ æ–°å¢ï¼šç«¯å£ä¿¡æ¯ä¼ é€’
            "port_info": self.get_all_port_info(),
            "current_iteration_port_info": self.current_iteration.port_info if self.current_iteration else {}
        }
        
        return context
    
    # ğŸ¯ æ–°å¢ï¼šæˆåŠŸç»éªŒç´¯ç§¯æ–¹æ³•
    
    def extract_success_patterns(self, iteration_result: Dict[str, Any]) -> None:
        """ä»æˆåŠŸçš„è¿­ä»£ä¸­æå–æˆåŠŸæ¨¡å¼"""
        if not self.current_iteration:
            return
        
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
        if iteration_result.get("all_tests_passed", False):
            self._extract_verilog_success_patterns()
            self._extract_interface_success_patterns()
            self._extract_code_improvements()
    
    def _extract_error_lessons(self, errors: List[Dict[str, Any]]) -> None:
        """ä»ç¼–è¯‘é”™è¯¯ä¸­æå–ç»éªŒæ•™è®­"""
        if not self.current_iteration:
            return
        
        lessons = []
        
        for error in errors:
            error_message = error.get('message', '')
            error_type = error.get('type', '')
            
            # åˆ†æå¸¸è§é”™è¯¯æ¨¡å¼
            if 'Index' in error_message and 'out of range' in error_message:
                lessons.append("æ•°ç»„è¶Šç•Œï¼šç¡®ä¿æ•°ç»„å¤§å°è¶³å¤Ÿæ”¯æŒæ‰€æœ‰ç´¢å¼•è®¿é—®")
            elif 'syntax error' in error_message.lower():
                lessons.append("è¯­æ³•é”™è¯¯ï¼šæ£€æŸ¥Verilogè¯­æ³•å…¼å®¹æ€§ï¼Œé¿å…ä½¿ç”¨ä¸å…¼å®¹çš„ç‰¹æ€§")
            elif 'Incomprehensible for loop' in error_message:
                lessons.append("å¾ªç¯è¯­æ³•é”™è¯¯ï¼šåœ¨generateå—ä¸­ä½¿ç”¨ç®€å•çš„assignè¯­å¥ï¼Œé¿å…å¤æ‚é€»è¾‘")
            elif 'Malformed statement' in error_message:
                lessons.append("è¯­å¥æ ¼å¼é”™è¯¯ï¼šæ£€æŸ¥è¯­å¥è¯­æ³•ï¼Œç¡®ä¿ç¬¦åˆVerilog-2001æ ‡å‡†")
            elif 'logic' in error_message.lower():
                lessons.append("ç±»å‹é”™è¯¯ï¼šä½¿ç”¨wireå’Œregç±»å‹ï¼Œé¿å…ä½¿ç”¨logicç±»å‹")
            elif 'clk' in error_message.lower() or 'rst' in error_message.lower():
                lessons.append("æ¥å£è¿è§„ï¼šçº¯ç»„åˆé€»è¾‘æ¨¡å—ä¸åº”åŒ…å«æ—¶é’Ÿæˆ–å¤ä½ä¿¡å·")
        
        # æ·»åŠ åˆ°å½“å‰è¿­ä»£å’Œå…¨å±€ä¸Šä¸‹æ–‡
        if not self.current_iteration.error_lessons:
            self.current_iteration.error_lessons = []
        self.current_iteration.error_lessons.extend(lessons)
        
        # æ›´æ–°å…¨å±€é”™è¯¯æ•™è®­ï¼ˆå»é‡ï¼‰
        for lesson in lessons:
            if lesson not in self.global_context["error_lessons"]:
                self.global_context["error_lessons"].append(lesson)
    
    def _extract_verilog_success_patterns(self) -> None:
        """æå–Verilogè¯­æ³•æˆåŠŸæ¨¡å¼"""
        if not self.current_iteration or not self.current_iteration.code_files:
            return
        
        correct_patterns = []
        avoid_patterns = []
        
        for file_path, code_context in self.current_iteration.code_files.items():
            content = code_context.content
            
            # åˆ†ææˆåŠŸçš„è¯­æ³•æ¨¡å¼
            if 'wire [16:0] carry' in content:
                correct_patterns.append("16ä½åŠ æ³•å™¨ä½¿ç”¨17ä½è¿›ä½æ•°ç»„ï¼šwire [16:0] carry")
            if 'assign overflow = (a[15] == b[15]) && (a[15] != sum[15])' in content:
                correct_patterns.append("æœ‰ç¬¦å·æº¢å‡ºæ£€æµ‹ï¼šoverflow = (a[15] == b[15]) && (a[15] != sum[15])")
            if 'assign' in content and 'always @(posedge' not in content:
                correct_patterns.append("çº¯ç»„åˆé€»è¾‘ä½¿ç”¨assignè¯­å¥ï¼Œé¿å…æ—¶åºç»“æ„")
            
            # åˆ†æéœ€è¦é¿å…çš„æ¨¡å¼
            if 'logic' in content:
                avoid_patterns.append("é¿å…ä½¿ç”¨logicç±»å‹ï¼Œä½¿ç”¨wireå’Œreg")
            if 'always @(posedge clk' in content:
                avoid_patterns.append("çº¯ç»„åˆé€»è¾‘ä¸åº”åŒ…å«æ—¶é’Ÿä¿¡å·")
            if 'generate' in content and 'for' in content:
                avoid_patterns.append("generateå—ä¸­é¿å…å¤æ‚çš„forå¾ªç¯é€»è¾‘")
        
        # æ›´æ–°å…¨å±€æˆåŠŸæ¨¡å¼
        self.global_context["success_patterns"]["verilog_syntax"]["correct_patterns"].extend(correct_patterns)
        self.global_context["success_patterns"]["verilog_syntax"]["avoid_patterns"].extend(avoid_patterns)
        
        # å»é‡
        self.global_context["success_patterns"]["verilog_syntax"]["correct_patterns"] = list(set(
            self.global_context["success_patterns"]["verilog_syntax"]["correct_patterns"]
        ))
        self.global_context["success_patterns"]["verilog_syntax"]["avoid_patterns"] = list(set(
            self.global_context["success_patterns"]["verilog_syntax"]["avoid_patterns"]
        ))
    
    def _extract_interface_success_patterns(self) -> None:
        """æå–æ¥å£åˆè§„æ€§æˆåŠŸæ¨¡å¼"""
        if not self.current_iteration or not self.current_iteration.code_files:
            return
        
        correct_patterns = []
        
        for file_path, code_context in self.current_iteration.code_files.items():
            content = code_context.content
            
            # æ£€æŸ¥æ¨¡å—å
            if 'module adder_16bit' in content:
                correct_patterns.append("æ¨¡å—åä¸¥æ ¼åŒ¹é…ï¼šadder_16bit")
            
            # æ£€æŸ¥ç«¯å£å®šä¹‰
            if 'input [15:0] a' in content and 'input [15:0] b' in content:
                correct_patterns.append("è¾“å…¥ç«¯å£ä½å®½æ­£ç¡®ï¼šinput [15:0] a, b")
            if 'output [15:0] sum' in content:
                correct_patterns.append("è¾“å‡ºç«¯å£ä½å®½æ­£ç¡®ï¼šoutput [15:0] sum")
            if 'output cout' in content and 'output overflow' in content:
                correct_patterns.append("è¾“å‡ºç«¯å£å®Œæ•´ï¼šcout, overflow")
            
            # æ£€æŸ¥æ— é¢å¤–ä¿¡å·
            if 'clk' not in content and 'rst' not in content:
                correct_patterns.append("çº¯ç»„åˆé€»è¾‘ï¼šæ— æ—¶é’Ÿå’Œå¤ä½ä¿¡å·")
        
        # æ›´æ–°å…¨å±€æˆåŠŸæ¨¡å¼
        self.global_context["success_patterns"]["interface_compliance"]["correct_patterns"].extend(correct_patterns)
        self.global_context["success_patterns"]["interface_compliance"]["correct_patterns"] = list(set(
            self.global_context["success_patterns"]["interface_compliance"]["correct_patterns"]
        ))
    
    def _extract_code_improvements(self) -> None:
        """æå–ä»£ç æ”¹è¿›ç‚¹"""
        if not self.current_iteration:
            return
        
        improvements = []
        
        # ä»å¯¹è¯å†å²ä¸­æå–æ”¹è¿›ç‚¹
        for turn in self.current_iteration.conversation_turns:
            if turn.success and turn.reasoning_notes:
                improvements.append(f"æ¨ç†æ”¹è¿›ï¼š{turn.reasoning_notes}")
        
        # ä»å·¥å…·è°ƒç”¨ä¸­æå–æ”¹è¿›ç‚¹
        for turn in self.current_iteration.conversation_turns:
            if turn.tool_calls:
                for tool_call in turn.tool_calls:
                    if tool_call.get("success", False):
                        tool_name = tool_call.get("tool_name", "")
                        improvements.append(f"å·¥å…·ä½¿ç”¨æˆåŠŸï¼š{tool_name}")
        
        if not self.current_iteration.code_improvements:
            self.current_iteration.code_improvements = []
        self.current_iteration.code_improvements.extend(improvements)
    
    def get_success_guidance(self) -> Dict[str, Any]:
        """è·å–æˆåŠŸç»éªŒæŒ‡å¯¼"""
        return {
            "success_patterns": self.global_context["success_patterns"],
            "error_lessons": self.global_context["error_lessons"],
            "successful_code_snippets": self.global_context["successful_code_snippets"],
            "failure_patterns": self.global_context["failure_patterns"]
        }
    
    def build_success_context_for_agent(self) -> str:
        """ä¸ºagentæ„å»ºæˆåŠŸç»éªŒä¸Šä¸‹æ–‡"""
        guidance = self.get_success_guidance()
        
        context = "\n\nğŸ¯ **åŸºäºå†å²è¿­ä»£çš„æˆåŠŸç»éªŒæŒ‡å¯¼**:\n\n"
        
        # æˆåŠŸæ¨¡å¼
        if guidance["success_patterns"]["verilog_syntax"]["correct_patterns"]:
            context += "### âœ… å·²éªŒè¯çš„æ­£ç¡®å®ç°æ¨¡å¼:\n"
            context += "```verilog\n"
            context += "// æ­£ç¡®çš„16ä½åŠ æ³•å™¨ç»“æ„\n"
            context += "module adder_16bit (\n"
            context += "    input  [15:0] a,\n"
            context += "    input  [15:0] b, \n"
            context += "    input         cin,\n"
            context += "    output [15:0] sum,\n"
            context += "    output        cout,\n"
            context += "    output        overflow\n"
            context += ");\n\n"
            context += "    // æ­£ç¡®çš„è¿›ä½æ•°ç»„å¤§å°\n"
            context += "    wire [16:0] carry;  // 17ä½ï¼Œæ”¯æŒ16ä½åŠ æ³•å™¨çš„è¿›ä½é“¾\n\n"
            context += "    // æ­£ç¡®çš„ç»„åˆé€»è¾‘å®ç°\n"
            context += "    assign carry[0] = cin;\n"
            context += "    assign sum[0] = a[0] ^ b[0] ^ carry[0];\n"
            context += "    assign carry[1] = (a[0] & b[0]) | (a[0] & carry[0]) | (b[0] & carry[0]);\n\n"
            context += "    // æ­£ç¡®çš„æº¢å‡ºæ£€æµ‹\n"
            context += "    assign overflow = (a[15] == b[15]) && (a[15] != sum[15]);\n"
            context += "    assign cout = carry[16];\n\n"
            context += "endmodule\n"
            context += "```\n\n"
        
        # é¿å…çš„é”™è¯¯æ¨¡å¼
        if guidance["error_lessons"]:
            context += "### âŒ é¿å…çš„é”™è¯¯æ¨¡å¼:\n"
            for lesson in guidance["error_lessons"][:5]:  # æœ€å¤šæ˜¾ç¤º5ä¸ª
                context += f"1. {lesson}\n"
            context += "\n"
        
        # æˆåŠŸæ¨¡å¼æ€»ç»“
        for category, patterns in guidance["success_patterns"].items():
            if patterns["correct_patterns"]:
                context += f"### âœ… {category} æˆåŠŸæ¨¡å¼:\n"
                for pattern in patterns["correct_patterns"][:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                    context += f"- {pattern}\n"
                context += "\n"
        
        context += "### ğŸ¯ æœ¬æ¬¡è¿­ä»£è¦æ±‚:\n"
        context += "è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°æˆåŠŸæ¨¡å¼ç”Ÿæˆä»£ç ï¼Œç¡®ä¿ï¼š\n"
        context += "1. ä½¿ç”¨æ­£ç¡®çš„æ•°ç»„å¤§å°\n"
        context += "2. å®ç°çº¯ç»„åˆé€»è¾‘\n"
        context += "3. ä¸¥æ ¼åŒ¹é…æ¥å£è§„èŒƒ\n"
        
        return context
    
    def _get_complete_code_content(self) -> Dict[str, Any]:
        """è·å–å®Œæ•´ä»£ç å†…å®¹"""
        if not self.current_iteration:
            return {}
        
        result = {
            "design_files": {},
            "testbench_files": {}
        }
        
        # è®¾è®¡æ–‡ä»¶
        for file_path, code_context in self.current_iteration.code_files.items():
            result["design_files"][file_path] = {
                "module_name": code_context.module_name,
                "content": code_context.content,
                "content_with_line_numbers": code_context.content_with_line_numbers,
                "error_lines": code_context.error_lines or {},
                "last_modified": code_context.last_modified
            }
        
        # æµ‹è¯•å°æ–‡ä»¶
        for file_path, code_context in self.current_iteration.testbench_files.items():
            result["testbench_files"][file_path] = {
                "module_name": code_context.module_name,
                "content": code_context.content,
                "content_with_line_numbers": code_context.content_with_line_numbers,
                "error_lines": code_context.error_lines or {},
                "last_modified": code_context.last_modified
            }
        
        return result
    
    def _get_complete_conversation_history(self) -> List[Dict[str, Any]]:
        """è·å–å®Œæ•´å¯¹è¯å†å²"""
        history = []
        
        # éå†æ‰€æœ‰è¿­ä»£çš„å¯¹è¯
        for iteration_id in sorted(self.iterations.keys()):
            iteration = self.iterations[iteration_id]
            
            for turn in iteration.conversation_turns:
                history.append({
                    "iteration_number": iteration.iteration_number,
                    "turn_id": turn.turn_id,
                    "agent_id": turn.agent_id,
                    "timestamp": turn.timestamp,
                    "user_prompt": turn.user_prompt,
                    "system_prompt": turn.system_prompt,
                    "ai_response": turn.ai_response,
                    "tool_calls": turn.tool_calls,
                    "tool_results": turn.tool_results,
                    "reasoning_notes": turn.reasoning_notes,
                    "success": turn.success,
                    "error_info": turn.error_info
                })
        
        return history
    
    def _get_detailed_error_context(self) -> Dict[str, Any]:
        """è·å–è¯¦ç»†é”™è¯¯ä¸Šä¸‹æ–‡"""
        if not self.current_iteration or not self.current_iteration.compilation_errors:
            return {}
        
        detailed_errors = []
        
        for error in self.current_iteration.compilation_errors:
            detailed_error = dict(error)  # å¤åˆ¶åŸé”™è¯¯ä¿¡æ¯
            
            # æ·»åŠ é”™è¯¯è¡Œçš„ä¸Šä¸‹æ–‡
            if 'file' in error and 'line' in error:
                file_path = error['file']
                line_number = int(error['line'])
                
                # æŸ¥æ‰¾ä»£ç æ–‡ä»¶
                code_context = None
                if file_path in self.current_iteration.code_files:
                    code_context = self.current_iteration.code_files[file_path]
                elif file_path in self.current_iteration.testbench_files:
                    code_context = self.current_iteration.testbench_files[file_path]
                
                if code_context:
                    detailed_error["error_line_content"] = code_context.error_lines.get(line_number, "")
                    detailed_error["error_context"] = code_context.get_error_context(line_number)
            
            detailed_errors.append(detailed_error)
        
        return {
            "compilation_errors": detailed_errors,
            "compilation_success": self.current_iteration.compilation_success,
            "simulation_success": self.current_iteration.simulation_success,
            "all_tests_passed": self.current_iteration.all_tests_passed,
            "failure_analysis": self.current_iteration.failure_analysis,
            "improvement_suggestions": self.current_iteration.improvement_suggestions
        }
    
    def _get_previous_iterations_summary(self) -> List[Dict[str, Any]]:
        """è·å–ä¹‹å‰è¿­ä»£çš„æ‘˜è¦"""
        summaries = []
        
        for iteration_id in sorted(self.iterations.keys()):
            iteration = self.iterations[iteration_id]
            if iteration == self.current_iteration:
                continue  # è·³è¿‡å½“å‰è¿­ä»£
            
            summary = {
                "iteration_number": iteration.iteration_number,
                "timestamp": iteration.timestamp,
                "compilation_success": iteration.compilation_success,
                "simulation_success": iteration.simulation_success,
                "all_tests_passed": iteration.all_tests_passed,
                "conversation_turns_count": len(iteration.conversation_turns),
                "code_files_count": len(iteration.code_files),
                "key_decisions": self._extract_key_decisions(iteration),
                "main_failures": self._extract_main_failures(iteration),
                "lessons_learned": self._extract_lessons_learned(iteration)
            }
            
            summaries.append(summary)
        
        return summaries
    
    def _get_agent_collaboration_history(self) -> Dict[str, Any]:
        """è·å–å¤šagentåä½œå†å²"""
        collaboration = {
            "agent_interactions": [],
            "handoff_points": [],
            "shared_decisions": []
        }
        
        # åˆ†æagentä¹‹é—´çš„äº¤äº’
        for iteration_id in sorted(self.iterations.keys()):
            iteration = self.iterations[iteration_id]
            
            agents_in_iteration = set(turn.agent_id for turn in iteration.conversation_turns)
            
            if len(agents_in_iteration) > 1:
                collaboration["agent_interactions"].append({
                    "iteration_number": iteration.iteration_number,
                    "agents": list(agents_in_iteration),
                    "interaction_type": "multi_agent_collaboration",
                    "context": self._analyze_agent_interaction(iteration)
                })
        
        return collaboration
    
    def _extract_key_decisions(self, iteration: IterationContext) -> List[str]:
        """æå–å…³é”®å†³ç­–"""
        decisions = []
        
        for turn in iteration.conversation_turns:
            # åˆ†æAIå“åº”ä¸­çš„å…³é”®å†³ç­–ç‚¹
            if "å†³å®š" in turn.ai_response or "é€‰æ‹©" in turn.ai_response:
                # æå–å†³ç­–ç›¸å…³çš„å¥å­
                sentences = turn.ai_response.split('ã€‚')
                for sentence in sentences:
                    if any(keyword in sentence for keyword in ["å†³å®š", "é€‰æ‹©", "é‡‡ç”¨", "ä¿®æ”¹"]):
                        decisions.append(sentence.strip())
        
        return decisions[:3]  # æœ€å¤šè¿”å›3ä¸ªå…³é”®å†³ç­–
    
    def _extract_main_failures(self, iteration: IterationContext) -> List[str]:
        """æå–ä¸»è¦å¤±è´¥åŸå› """
        failures = []
        
        if iteration.compilation_errors:
            error_types = set()
            for error in iteration.compilation_errors:
                if 'type' in error:
                    error_types.add(error['type'])
            failures.extend(list(error_types))
        
        return failures
    
    def _extract_lessons_learned(self, iteration: IterationContext) -> List[str]:
        """æå–ç»éªŒæ•™è®­"""
        lessons = []
        
        if iteration.improvement_suggestions:
            lessons.extend(iteration.improvement_suggestions[:2])
        
        return lessons
    
    def _analyze_agent_interaction(self, iteration: IterationContext) -> Dict[str, Any]:
        """åˆ†æagentäº¤äº’"""
        return {
            "turns_count": len(iteration.conversation_turns),
            "main_topics": ["è®¾è®¡ç”Ÿæˆ", "ä»£ç å®¡æŸ¥", "é”™è¯¯ä¿®å¤"],  # ç®€åŒ–ç‰ˆæœ¬
            "outcome": "åä½œå®Œæˆ" if iteration.all_tests_passed else "éœ€è¦ç»§ç»­è¿­ä»£"
        }
    
    def save_to_file(self, file_path: str) -> None:
        """ä¿å­˜ä¸Šä¸‹æ–‡åˆ°æ–‡ä»¶"""
        context_data = {
            "session_id": self.session_id,
            "global_context": self.global_context,
            "iterations": {}
        }
        
        # åºåˆ—åŒ–è¿­ä»£æ•°æ®
        for iteration_id, iteration in self.iterations.items():
            context_data["iterations"][iteration_id] = asdict(iteration)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(context_data, f, ensure_ascii=False, indent=2, default=str)
    
    def load_from_file(self, file_path: str) -> None:
        """ä»æ–‡ä»¶åŠ è½½ä¸Šä¸‹æ–‡"""
        with open(file_path, 'r', encoding='utf-8') as f:
            context_data = json.load(f)
        
        self.session_id = context_data["session_id"]
        self.global_context = context_data["global_context"]
        
        # ååºåˆ—åŒ–è¿­ä»£æ•°æ®
        for iteration_id, iteration_data in context_data["iterations"].items():
            # è¿™é‡Œéœ€è¦æ›´å¤æ‚çš„ååºåˆ—åŒ–é€»è¾‘ï¼Œæš‚æ—¶ç®€åŒ–
            self.iterations[iteration_id] = iteration_data


# å…¨å±€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å®ä¾‹
_context_managers: Dict[str, FullContextManager] = {}


def get_context_manager(session_id: str) -> FullContextManager:
    """è·å–æˆ–åˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    if session_id not in _context_managers:
        _context_managers[session_id] = FullContextManager(session_id)
    return _context_managers[session_id]


def cleanup_context_manager(session_id: str) -> None:
    """æ¸…ç†ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    if session_id in _context_managers:
        del _context_managers[session_id]
#!/usr/bin/env python3
"""
ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶
==================================================

è¿™ä¸ªæ¨¡å—è§£å†³äº†å¤šæ™ºèƒ½ä½“åä½œä¸­çš„æ–‡ä»¶ç®¡ç†å’Œä¸Šä¸‹æ–‡ä¼ é€’é—®é¢˜ï¼š
âœ… ç»Ÿä¸€çš„æ–‡ä»¶ä¿å­˜å’Œè·å–æ¥å£
âœ… è‡ªåŠ¨çš„æ–‡ä»¶ç±»å‹è¯†åˆ«å’Œåˆ†ç±»
âœ… è·¨æ™ºèƒ½ä½“çš„æ–‡ä»¶å¼•ç”¨è¿½è¸ª
âœ… å·¥ä½œç›®å½•éš”ç¦»å’Œç®¡ç†
âœ… ç«¯å£ä¿¡æ¯éªŒè¯å’Œä¸€è‡´æ€§æ£€æŸ¥
âœ… ç‰ˆæœ¬ç®¡ç†å’Œå›æ»šæœºåˆ¶
"""

import json
import logging
import uuid
import hashlib
from pathlib import Path
from typing import Dict, Any, List, Optional, Union
from dataclasses import dataclass, asdict
from datetime import datetime


@dataclass
class FileReference:
    """æ–‡ä»¶å¼•ç”¨ä¿¡æ¯"""
    file_id: str
    file_path: str
    file_type: str  # "verilog", "testbench", "report", "config", etc.
    content_hash: str
    created_by: str  # åˆ›å»ºè¯¥æ–‡ä»¶çš„æ™ºèƒ½ä½“ID
    created_at: str
    description: str = ""
    metadata: Dict[str, Any] = None
    # ğŸ¯ æ–°å¢ï¼šç«¯å£ä¿¡æ¯éªŒè¯
    port_info: Dict[str, Any] = None  # å­˜å‚¨æ¨¡å—ç«¯å£ä¿¡æ¯
    version: int = 1  # æ–‡ä»¶ç‰ˆæœ¬å·

    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
        if self.port_info is None:
            self.port_info = {}


class CentralFileManager:
    """ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self, workspace_root: Path = None):
        self.logger = logging.getLogger(__name__)
        
        # è®¾ç½®å·¥ä½œç©ºé—´æ ¹ç›®å½•
        if workspace_root is None:
            workspace_root = Path.cwd() / "file_workspace"
        
        self.workspace_root = Path(workspace_root)
        self.workspace_root.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.design_dir = self.workspace_root / "designs"
        self.testbench_dir = self.workspace_root / "testbenches"
        self.report_dir = self.workspace_root / "reports"
        self.temp_dir = self.workspace_root / "temp"
        
        for dir_path in [self.design_dir, self.testbench_dir, self.report_dir, self.temp_dir]:
            dir_path.mkdir(exist_ok=True)
        
        # æ–‡ä»¶æ³¨å†Œè¡¨
        self.file_registry: Dict[str, FileReference] = {}
        self.registry_file = self.workspace_root / "file_registry.json"
        
        # ğŸ¯ æ–°å¢ï¼šç«¯å£ä¿¡æ¯ç¼“å­˜
        self.port_info_cache: Dict[str, Dict[str, Any]] = {}
        
        # åŠ è½½ç°æœ‰æ³¨å†Œè¡¨
        self._load_registry()
        
        self.logger.info(f"ğŸ—‚ï¸ ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼Œå·¥ä½œç©ºé—´: {self.workspace_root}")
    
    def save_file(self, content: str, filename: str, file_type: str, 
                 created_by: str, description: str = "") -> FileReference:
        """
        ä¿å­˜æ–‡ä»¶å¹¶è¿”å›æ–‡ä»¶å¼•ç”¨
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            filename: æ–‡ä»¶å
            file_type: æ–‡ä»¶ç±»å‹ (verilog, testbench, report, etc.)
            created_by: åˆ›å»ºè€…ID
            description: æ–‡ä»¶æè¿°
            
        Returns:
            æ–‡ä»¶å¼•ç”¨å¯¹è±¡
        """
        # ğŸ¯ æ–°å¢ï¼šæå–å’ŒéªŒè¯ç«¯å£ä¿¡æ¯
        port_info = self._extract_port_info(content, file_type)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡ä»¶
        existing_file_id = None
        for file_id, file_ref in self.file_registry.items():
            if file_ref.filename == filename and file_ref.file_type == file_type:
                existing_file_id = file_id
                break
        
        # å¦‚æœå­˜åœ¨åŒåæ–‡ä»¶ï¼Œè¿›è¡Œç‰ˆæœ¬ç®¡ç†
        if existing_file_id:
            old_file_ref = self.file_registry[existing_file_id]
            
            # ğŸ¯ æ–°å¢ï¼šç«¯å£ä¸€è‡´æ€§éªŒè¯
            if file_type == "verilog" and old_file_ref.port_info:
                if not self._validate_port_consistency(old_file_ref.port_info, port_info):
                    self.logger.warning(f"âš ï¸ ç«¯å£ä¿¡æ¯ä¸ä¸€è‡´: {filename}")
            
            # åˆ›å»ºæ–°ç‰ˆæœ¬
            new_version = old_file_ref.version + 1
            versioned_filename = f"{filename}_v{new_version}"
            self.logger.info(f"ğŸ“ åˆ›å»ºæ–°ç‰ˆæœ¬: {versioned_filename}")
        else:
            versioned_filename = filename
            new_version = 1
        
        # ç¡®å®šç›®æ ‡ç›®å½•
        target_dir = self._get_target_directory(file_type)
        file_path = target_dir / versioned_filename
        
        # æ·»åŠ æ–‡ä»¶æ‰©å±•å
        if not file_path.suffix:
            extension = self._get_file_extension(file_type)
            file_path = file_path.with_suffix(extension)
        
        # ä¿å­˜æ–‡ä»¶
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # è®¡ç®—å†…å®¹å“ˆå¸Œ
            content_hash = hashlib.md5(content.encode()).hexdigest()
            
            # åˆ›å»ºæ–‡ä»¶å¼•ç”¨
            file_id = str(uuid.uuid4())
            file_ref = FileReference(
                file_id=file_id,
                file_path=str(file_path),
                file_type=file_type,
                content_hash=content_hash,
                created_by=created_by,
                created_at=datetime.now().isoformat(),
                description=description,
                port_info=port_info,
                version=new_version
            )
            
            # æ³¨å†Œæ–‡ä»¶
            self.file_registry[file_id] = file_ref
            self._save_registry()
            
            self.logger.info(f"ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜: {file_path} (ID: {file_id})")
            
            # ğŸ†• è®°å½•åˆ°TaskContextï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if hasattr(self, 'task_context') and self.task_context and hasattr(self.task_context, 'add_file_operation'):
                self.task_context.add_file_operation(
                    operation_type="create",
                    file_path=str(file_path),
                    agent_id=created_by,
                    success=True,
                    file_size=len(content.encode('utf-8'))
                )
            
            return file_ref
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {file_path} - {str(e)}")
            
            # ğŸ†• è®°å½•å¤±è´¥åˆ°TaskContextï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if hasattr(self, 'task_context') and self.task_context and hasattr(self.task_context, 'add_file_operation'):
                self.task_context.add_file_operation(
                    operation_type="create",
                    file_path=str(file_path),
                    agent_id=created_by,
                    success=False,
                    error=str(e)
                )
            
            raise
    
    def _extract_port_info(self, content: str, file_type: str) -> Dict[str, Any]:
        """æå–Verilogæ¨¡å—çš„ç«¯å£ä¿¡æ¯"""
        if file_type != "verilog":
            return {}
        
        import re
        
        # æå–æ¨¡å—å®šä¹‰
        module_pattern = r'module\s+(\w+)\s*\(([^)]+)\);'
        match = re.search(module_pattern, content, re.DOTALL)
        
        if not match:
            return {}
        
        module_name = match.group(1)
        port_declarations = match.group(2)
        
        # è§£æç«¯å£
        ports = []
        port_lines = [line.strip() for line in port_declarations.split(',')]
        
        for line in port_lines:
            if not line:
                continue
            
            # åŒ¹é…ç«¯å£å£°æ˜
            port_match = re.search(r'(input|output|inout)\s*(?:\[(\d+):(\d+)\])?\s*(\w+)', line)
            if port_match:
                direction = port_match.group(1)
                msb = port_match.group(2)
                lsb = port_match.group(3)
                port_name = port_match.group(4)
                
                width = 1
                if msb and lsb:
                    width = int(msb) - int(lsb) + 1
                
                ports.append({
                    "name": port_name,
                    "direction": direction,
                    "width": width,
                    "msb": int(msb) if msb else None,
                    "lsb": int(lsb) if lsb else None
                })
        
        return {
            "module_name": module_name,
            "ports": ports,
            "port_count": len(ports)
        }
    
    def _validate_port_consistency(self, old_ports: Dict[str, Any], new_ports: Dict[str, Any]) -> bool:
        """éªŒè¯ç«¯å£ä¿¡æ¯ä¸€è‡´æ€§"""
        if not old_ports or not new_ports:
            return True
        
        old_port_names = {port["name"] for port in old_ports.get("ports", [])}
        new_port_names = {port["name"] for port in new_ports.get("ports", [])}
        
        return old_port_names == new_port_names
    
    def get_latest_design_file(self, module_name: str = None) -> Optional[FileReference]:
        """è·å–æœ€æ–°çš„è®¾è®¡æ–‡ä»¶"""
        design_files = self.get_files_by_type("verilog")
        
        if not design_files:
            return None
        
        # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
        design_files.sort(key=lambda x: x.created_at, reverse=True)
        
        if module_name:
            # æŸ¥æ‰¾æŒ‡å®šæ¨¡å—çš„æœ€æ–°ç‰ˆæœ¬
            for file_ref in design_files:
                if file_ref.port_info and file_ref.port_info.get("module_name") == module_name:
                    return file_ref
            return None
        
        return design_files[0]
    
    def get_design_port_info(self, module_name: str) -> Optional[Dict[str, Any]]:
        """è·å–è®¾è®¡æ–‡ä»¶çš„ç«¯å£ä¿¡æ¯"""
        design_file = self.get_latest_design_file(module_name)
        if design_file:
            return design_file.port_info
        return None
    
    def validate_testbench_ports(self, testbench_content: str, design_module_name: str) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•å°ç«¯å£ä¸è®¾è®¡ç«¯å£çš„ä¸€è‡´æ€§"""
        design_ports = self.get_design_port_info(design_module_name)
        if not design_ports:
            return {"valid": False, "error": f"æœªæ‰¾åˆ°æ¨¡å— {design_module_name} çš„ç«¯å£ä¿¡æ¯"}
        
        # æå–æµ‹è¯•å°ä¸­çš„æ¨¡å—å®ä¾‹åŒ–
        import re
        instance_pattern = rf'{design_module_name}\s+\w+\s*\(([^)]+)\);'
        match = re.search(instance_pattern, testbench_content, re.DOTALL)
        
        if not match:
            return {"valid": False, "error": f"æœªæ‰¾åˆ°æ¨¡å— {design_module_name} çš„å®ä¾‹åŒ–"}
        
        instance_ports = match.group(1)
        port_connections = []
        
        # è§£æç«¯å£è¿æ¥
        for line in instance_ports.split(','):
            line = line.strip()
            if not line:
                continue
            
            port_match = re.search(r'\.(\w+)\s*\(\s*(\w+)\s*\)', line)
            if port_match:
                port_name = port_match.group(1)
                signal_name = port_match.group(2)
                port_connections.append({"port": port_name, "signal": signal_name})
        
        # éªŒè¯ç«¯å£è¿æ¥
        design_port_names = {port["name"] for port in design_ports["ports"]}
        testbench_port_names = {conn["port"] for conn in port_connections}
        
        missing_ports = design_port_names - testbench_port_names
        extra_ports = testbench_port_names - design_port_names
        
        return {
            "valid": len(missing_ports) == 0 and len(extra_ports) == 0,
            "missing_ports": list(missing_ports),
            "extra_ports": list(extra_ports),
            "design_ports": design_ports,
            "testbench_connections": port_connections
        }
    
    def save_file_to_path(self, content: str, filename: str, target_path: Path, 
                         file_type: str, created_by: str, description: str = "") -> FileReference:
        """
        ä¿å­˜æ–‡ä»¶åˆ°æŒ‡å®šè·¯å¾„å¹¶è¿”å›æ–‡ä»¶å¼•ç”¨
        
        Args:
            content: æ–‡ä»¶å†…å®¹
            filename: æ–‡ä»¶å
            target_path: ç›®æ ‡ä¿å­˜è·¯å¾„
            file_type: æ–‡ä»¶ç±»å‹ (verilog, testbench, report, etc.)
            created_by: åˆ›å»ºè€…ID
            description: æ–‡ä»¶æè¿°
            
        Returns:
            æ–‡ä»¶å¼•ç”¨å¯¹è±¡
        """
        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
        target_path.mkdir(parents=True, exist_ok=True)
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨åŒåæ–‡ä»¶
        existing_file_id = None
        for fid, file_ref in self.file_registry.items():
            if Path(file_ref.file_path).name == filename and file_ref.file_type == file_type:
                existing_file_id = fid
                break
        
        # å¦‚æœå­˜åœ¨åŒåæ–‡ä»¶ï¼Œä½¿ç”¨ç›¸åŒIDï¼›å¦åˆ™ç”Ÿæˆæ–°ID
        if existing_file_id:
            file_id = existing_file_id
            self.logger.info(f"ğŸ”„ ä½¿ç”¨ç°æœ‰æ–‡ä»¶ID: {file_id}")
        else:
            file_id = str(uuid.uuid4())[:8]
            self.logger.info(f"ğŸ†” ç”Ÿæˆæ–°æ–‡ä»¶ID: {file_id}")
        
        # ç”Ÿæˆå®Œæ•´çš„æ–‡ä»¶è·¯å¾„
        file_extension = self._get_file_extension(file_type)
        if not filename.endswith(file_extension):
            filename = f"{filename}{file_extension}"
        
        file_path = target_path / filename
        
        # ç›´æ¥è¦†ç›–åŒåæ–‡ä»¶ï¼Œä¸åˆ›å»ºæ–°æ–‡ä»¶
        if file_path.exists():
            self.logger.info(f"ğŸ”„ è¦†ç›–ç°æœ‰æ–‡ä»¶: {filename}")
        
        # ä¿å­˜æ–‡ä»¶
        file_path.write_text(content, encoding='utf-8')
        
        # è®¡ç®—å†…å®¹å“ˆå¸Œ
        content_hash = str(hash(content))
        
        # åˆ›å»ºæˆ–æ›´æ–°æ–‡ä»¶å¼•ç”¨
        if existing_file_id:
            # æ›´æ–°ç°æœ‰æ–‡ä»¶å¼•ç”¨
            file_ref = self.file_registry[file_id]
            file_ref.file_path = str(file_path)
            file_ref.content_hash = content_hash
            file_ref.created_by = created_by
            file_ref.created_at = datetime.now().isoformat()
            file_ref.description = description
            self.logger.info(f"ğŸ”„ æ›´æ–°ç°æœ‰æ–‡ä»¶å¼•ç”¨: {file_id}")
        else:
            # åˆ›å»ºæ–°æ–‡ä»¶å¼•ç”¨
            file_ref = FileReference(
                file_id=file_id,
                file_path=str(file_path),
                file_type=file_type,
                content_hash=content_hash,
                created_by=created_by,
                created_at=datetime.now().isoformat(),
                description=description
            )
            self.file_registry[file_id] = file_ref
            self.logger.info(f"ğŸ†• åˆ›å»ºæ–°æ–‡ä»¶å¼•ç”¨: {file_id}")
        self._save_registry()
        
        self.logger.info(f"ğŸ’¾ æ–‡ä»¶å·²ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„: {file_path} (ID: {file_id}, ç±»å‹: {file_type})")
        return file_ref
    
    def get_file(self, file_id: str) -> Optional[FileReference]:
        """æ ¹æ®æ–‡ä»¶IDè·å–æ–‡ä»¶å¼•ç”¨"""
        return self.file_registry.get(file_id)
    
    def get_files_by_type(self, file_type: str) -> List[FileReference]:
        """æ ¹æ®æ–‡ä»¶ç±»å‹è·å–æ‰€æœ‰æ–‡ä»¶å¼•ç”¨"""
        return [ref for ref in self.file_registry.values() if ref.file_type == file_type]
    
    def get_files_by_creator(self, creator_id: str) -> List[FileReference]:
        """æ ¹æ®åˆ›å»ºè€…è·å–æ‰€æœ‰æ–‡ä»¶å¼•ç”¨"""
        return [ref for ref in self.file_registry.values() if ref.created_by == creator_id]
    
    def get_latest_files_by_type(self, file_type: str, limit: int = 5) -> List[FileReference]:
        """è·å–æŒ‡å®šç±»å‹çš„æœ€æ–°æ–‡ä»¶"""
        files = self.get_files_by_type(file_type)
        return sorted(files, key=lambda x: x.created_at, reverse=True)[:limit]
    
    def read_file_content(self, file_ref: Union[str, FileReference]) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        if isinstance(file_ref, str):
            file_ref = self.get_file(file_ref)
            if not file_ref:
                raise FileNotFoundError(f"æ–‡ä»¶ID {file_ref} ä¸å­˜åœ¨")
        
        file_path = Path(file_ref.file_path)
        if not file_path.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ {file_path} ä¸å­˜åœ¨")
        
        return file_path.read_text(encoding='utf-8')
    
    def update_file_metadata(self, file_id: str, metadata: Dict[str, Any]) -> bool:
        """æ›´æ–°æ–‡ä»¶å…ƒæ•°æ®"""
        if file_id not in self.file_registry:
            return False
        
        self.file_registry[file_id].metadata.update(metadata)
        self._save_registry()
        return True
    
    def list_all_files(self) -> List[FileReference]:
        """åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶"""
        return list(self.file_registry.values())
    
    def cleanup_old_files(self, keep_latest: int = 10):
        """æ¸…ç†æ—§æ–‡ä»¶ï¼Œä¿ç•™æœ€æ–°çš„å‡ ä¸ªæ–‡ä»¶"""
        all_files = sorted(self.file_registry.values(), 
                          key=lambda x: x.created_at, reverse=True)
        
        if len(all_files) <= keep_latest:
            return
        
        files_to_remove = all_files[keep_latest:]
        for file_ref in files_to_remove:
            try:
                Path(file_ref.file_path).unlink(missing_ok=True)
                del self.file_registry[file_ref.file_id]
                self.logger.info(f"ğŸ—‘ï¸ æ¸…ç†æ—§æ–‡ä»¶: {file_ref.file_path}")
            except Exception as e:
                self.logger.warning(f"æ¸…ç†æ–‡ä»¶å¤±è´¥: {e}")
        
        self._save_registry()
    
    def get_workspace_info(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œç©ºé—´ä¿¡æ¯"""
        return {
            "workspace_root": str(self.workspace_root),
            "total_files": len(self.file_registry),
            "file_types": list(set(ref.file_type for ref in self.file_registry.values())),
            "recent_files": [
                {
                    "file_id": ref.file_id,
                    "filename": Path(ref.file_path).name,
                    "file_type": ref.file_type,
                    "created_by": ref.created_by,
                    "created_at": ref.created_at
                }
                for ref in sorted(self.file_registry.values(), 
                                key=lambda x: x.created_at, reverse=True)[:5]
            ]
        }
    
    def _get_target_directory(self, file_type: str) -> Path:
        """æ ¹æ®æ–‡ä»¶ç±»å‹ç¡®å®šç›®æ ‡ç›®å½•"""
        type_mapping = {
            "verilog": self.design_dir,
            "design": self.design_dir,
            "testbench": self.testbench_dir,
            "tb": self.testbench_dir,
            "report": self.report_dir,
            "analysis": self.report_dir,
            "temp": self.temp_dir
        }
        return type_mapping.get(file_type.lower(), self.temp_dir)
    
    def _get_file_extension(self, file_type: str) -> str:
        """æ ¹æ®æ–‡ä»¶ç±»å‹ç¡®å®šæ–‡ä»¶æ‰©å±•å"""
        type_mapping = {
            "verilog": ".v",
            "design": ".v",
            "testbench": ".v",
            "tb": ".v",
            "report": ".txt",
            "analysis": ".json",
            "temp": ".tmp"
        }
        return type_mapping.get(file_type.lower(), ".txt")
    
    def _load_registry(self):
        """åŠ è½½æ–‡ä»¶æ³¨å†Œè¡¨"""
        if not self.registry_file.exists():
            return
        
        try:
            with open(self.registry_file, 'r', encoding='utf-8') as f:
                registry_data = json.load(f)
            
            for file_id, data in registry_data.items():
                self.file_registry[file_id] = FileReference(**data)
            
            self.logger.debug(f"ğŸ“‹ åŠ è½½æ–‡ä»¶æ³¨å†Œè¡¨: {len(self.file_registry)} ä¸ªæ–‡ä»¶")
        except Exception as e:
            self.logger.warning(f"åŠ è½½æ–‡ä»¶æ³¨å†Œè¡¨å¤±è´¥: {e}")
    
    def _save_registry(self):
        """ä¿å­˜æ–‡ä»¶æ³¨å†Œè¡¨"""
        try:
            registry_data = {
                file_id: asdict(file_ref) 
                for file_id, file_ref in self.file_registry.items()
            }
            
            with open(self.registry_file, 'w', encoding='utf-8') as f:
                json.dump(registry_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            self.logger.error(f"ä¿å­˜æ–‡ä»¶æ³¨å†Œè¡¨å¤±è´¥: {e}")


# å…¨å±€æ–‡ä»¶ç®¡ç†å™¨å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
_global_file_manager: Optional[CentralFileManager] = None

def get_file_manager() -> CentralFileManager:
    """è·å–å…¨å±€æ–‡ä»¶ç®¡ç†å™¨å®ä¾‹"""
    global _global_file_manager
    if _global_file_manager is None:
        _global_file_manager = CentralFileManager()
    return _global_file_manager

def initialize_file_manager(workspace_root: Path = None) -> CentralFileManager:
    """åˆå§‹åŒ–å…¨å±€æ–‡ä»¶ç®¡ç†å™¨"""
    global _global_file_manager
    _global_file_manager = CentralFileManager(workspace_root)
    return _global_file_manager
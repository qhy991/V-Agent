"""
ç»Ÿä¸€ä»»åŠ¡æ–‡ä»¶ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ

è§£å†³æ™ºèƒ½ä½“é—´æ–‡ä»¶å†…å®¹ä¼ é€’å’Œä¸Šä¸‹æ–‡ä¸¢å¤±é—®é¢˜
"""

import json
import hashlib
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass, asdict
from pathlib import Path
import logging
from enum import Enum
import time

class FileType(Enum):
    """æ–‡ä»¶ç±»åž‹æžšä¸¾"""
    VERILOG = "verilog"
    SYSTEMVERILOG = "systemverilog"
    TESTBENCH = "testbench"
    CONSTRAINT = "constraint"
    OTHER = "other"

@dataclass
class FileContent:
    """å•ä¸ªæ–‡ä»¶å†…å®¹æ•°æ®ç±»"""
    file_path: str
    content: str
    file_type: FileType
    checksum: str
    timestamp: float
    metadata: Dict[str, Any]
    
    @classmethod
    def from_file(cls, file_path: str, content: str = None, file_type: FileType = None, **metadata):
        """ä»Žæ–‡ä»¶è·¯å¾„åˆ›å»ºFileContentå®žä¾‹"""
        if content is None:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
            except Exception as e:
                raise ValueError(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_path}: {e}")
        
        # è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»åž‹
        if file_type is None:
            file_type = cls._detect_file_type(file_path, content)
        
        # è®¡ç®—æ ¡éªŒå’Œ
        checksum = hashlib.md5(content.encode('utf-8')).hexdigest()
        
        return cls(
            file_path=file_path,
            content=content,
            file_type=file_type,
            checksum=checksum,
            timestamp=time.time(),
            metadata=metadata
        )
    
    @staticmethod
    def _detect_file_type(file_path: str, content: str) -> FileType:
        """è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç±»åž‹"""
        file_path_lower = file_path.lower()
        
        if file_path_lower.endswith('.v'):
            # æ£€æŸ¥æ˜¯å¦æ˜¯æµ‹è¯•å°
            if 'testbench' in content.lower() or 'tb_' in file_path_lower or '_tb' in file_path_lower:
                return FileType.TESTBENCH
            return FileType.VERILOG
        elif file_path_lower.endswith('.sv'):
            if 'testbench' in content.lower() or 'tb_' in file_path_lower or '_tb' in file_path_lower:
                return FileType.TESTBENCH
            return FileType.SYSTEMVERILOG
        elif file_path_lower.endswith(('.xdc', '.sdc', '.ucf')):
            return FileType.CONSTRAINT
        else:
            return FileType.OTHER
    
    def validate_content(self) -> bool:
        """éªŒè¯å†…å®¹å®Œæ•´æ€§"""
        current_checksum = hashlib.md5(self.content.encode('utf-8')).hexdigest()
        return current_checksum == self.checksum
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        result = asdict(self)
        result['file_type'] = self.file_type.value
        return result

class TaskFileContext:
    """ä»»åŠ¡æ–‡ä»¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    
    def __init__(self, task_id: str = None):
        self.task_id = task_id or f"task_{int(time.time())}"
        self.files: Dict[str, FileContent] = {}
        self.primary_design_file: Optional[str] = None
        self.primary_testbench_file: Optional[str] = None
        self.logger = logging.getLogger(f"{__name__}.{self.task_id}")
        self._creation_time = time.time()
        self._last_access_time = time.time()
        
    def add_file(self, file_path: str, content: str = None, file_type: FileType = None, 
                 is_primary_design: bool = False, is_primary_testbench: bool = False, **metadata) -> FileContent:
        """æ·»åŠ æ–‡ä»¶åˆ°ä¸Šä¸‹æ–‡"""
        file_content = FileContent.from_file(file_path, content, file_type, **metadata)
        
        # æ ‡å‡†åŒ–æ–‡ä»¶è·¯å¾„
        normalized_path = str(Path(file_path).resolve())
        self.files[normalized_path] = file_content
        
        # è®¾ç½®ä¸»è¦æ–‡ä»¶
        if is_primary_design or (file_content.file_type == FileType.VERILOG and not self.primary_design_file):
            self.primary_design_file = normalized_path
            self.logger.info(f"ðŸŽ¯ è®¾ç½®ä¸»è¦è®¾è®¡æ–‡ä»¶: {normalized_path}")
        
        if is_primary_testbench or (file_content.file_type == FileType.TESTBENCH and not self.primary_testbench_file):
            self.primary_testbench_file = normalized_path
            self.logger.info(f"ðŸ§ª è®¾ç½®ä¸»è¦æµ‹è¯•å°æ–‡ä»¶: {normalized_path}")
        
        self._last_access_time = time.time()
        self.logger.info(f"ðŸ“ æ·»åŠ æ–‡ä»¶åˆ°ä¸Šä¸‹æ–‡: {file_path} ({file_content.file_type.value}, {len(content or '')} å­—ç¬¦)")
        
        return file_content
    
    def get_file(self, file_path: str) -> Optional[FileContent]:
        """èŽ·å–æ–‡ä»¶å†…å®¹"""
        normalized_path = str(Path(file_path).resolve())
        file_content = self.files.get(normalized_path)
        
        if file_content:
            self._last_access_time = time.time()
            # éªŒè¯å†…å®¹å®Œæ•´æ€§
            if not file_content.validate_content():
                self.logger.warning(f"âš ï¸ æ–‡ä»¶å†…å®¹æ ¡éªŒå¤±è´¥: {file_path}")
        
        return file_content
    
    def get_primary_design_content(self) -> Optional[str]:
        """èŽ·å–ä¸»è¦è®¾è®¡æ–‡ä»¶å†…å®¹ï¼ˆå¢žå¼ºç‰ˆï¼šåŒ…å«ä¸€è‡´æ€§éªŒè¯ï¼‰"""
        if not self.primary_design_file:
            self.logger.warning("âš ï¸ æ²¡æœ‰è®¾ç½®ä¸»è¦è®¾è®¡æ–‡ä»¶")
            return None
        
        file_content = self.get_file(self.primary_design_file)
        if not file_content or not file_content.content:
            return None
        
        # ðŸ”§ æ–°å¢žï¼šéªŒè¯è®¾è®¡æ–‡ä»¶çš„å®Œæ•´æ€§
        self._validate_design_file_integrity(file_content.content, self.primary_design_file)
        
        return file_content.content
    
    def get_primary_testbench_content(self) -> Optional[str]:
        """èŽ·å–ä¸»è¦æµ‹è¯•å°æ–‡ä»¶å†…å®¹"""
        if not self.primary_testbench_file:
            self.logger.warning("âš ï¸ æ²¡æœ‰è®¾ç½®ä¸»è¦æµ‹è¯•å°æ–‡ä»¶")
            return None
        
        file_content = self.get_file(self.primary_testbench_file)
        return file_content.content if file_content else None
    
    def get_files_by_type(self, file_type: FileType) -> List[FileContent]:
        """æŒ‰ç±»åž‹èŽ·å–æ–‡ä»¶åˆ—è¡¨"""
        return [fc for fc in self.files.values() if fc.file_type == file_type]
    
    def get_verilog_files(self) -> List[FileContent]:
        """èŽ·å–æ‰€æœ‰Verilogæ–‡ä»¶"""
        return self.get_files_by_type(FileType.VERILOG) + self.get_files_by_type(FileType.SYSTEMVERILOG)
    
    def get_testbench_files(self) -> List[FileContent]:
        """èŽ·å–æ‰€æœ‰æµ‹è¯•å°æ–‡ä»¶"""
        return self.get_files_by_type(FileType.TESTBENCH)
    
    def validate_all_files(self) -> Dict[str, bool]:
        """éªŒè¯æ‰€æœ‰æ–‡ä»¶çš„å®Œæ•´æ€§"""
        validation_results = {}
        for file_path, file_content in self.files.items():
            validation_results[file_path] = file_content.validate_content()
        return validation_results
    
    def get_context_summary(self) -> Dict[str, Any]:
        """èŽ·å–ä¸Šä¸‹æ–‡æ‘˜è¦"""
        file_summary = {}
        for file_path, file_content in self.files.items():
            file_summary[file_path] = {
                'type': file_content.file_type.value,
                'size': len(file_content.content),
                'checksum': file_content.checksum,
                'timestamp': file_content.timestamp
            }
        
        return {
            'task_id': self.task_id,
            'total_files': len(self.files),
            'primary_design_file': self.primary_design_file,
            'primary_testbench_file': self.primary_testbench_file,
            'files': file_summary,
            'creation_time': self._creation_time,
            'last_access_time': self._last_access_time
        }
    
    def export_for_agent(self, include_content: bool = True) -> Dict[str, Any]:
        """å¯¼å‡ºç»™æ™ºèƒ½ä½“ä½¿ç”¨çš„æ ¼å¼"""
        exported_data = {
            'task_id': self.task_id,
            'primary_design_file': self.primary_design_file,
            'primary_testbench_file': self.primary_testbench_file,
            'files': {}
        }
        
        for file_path, file_content in self.files.items():
            file_data = {
                'file_path': file_path,
                'file_type': file_content.file_type.value,
                'checksum': file_content.checksum,
                'timestamp': file_content.timestamp,
                'metadata': file_content.metadata
            }
            
            if include_content:
                file_data['content'] = file_content.content
                
            exported_data['files'][file_path] = file_data
        
        return exported_data
    
    def _validate_design_file_integrity(self, content: str, file_path: str):
        """éªŒè¯è®¾è®¡æ–‡ä»¶çš„å®Œæ•´æ€§"""
        try:
            # å¯¼å…¥ä»£ç ä¸€è‡´æ€§æ£€æŸ¥å™¨
            from core.code_consistency_checker import get_consistency_checker
            checker = get_consistency_checker()
            
            # éªŒè¯ä»£ç å®Œæ•´æ€§
            expected_features = ["parameterized", "width_parameter", "enable_input", "reset_input"]
            validation_result = checker.validate_code_parameter(content, expected_features)
            
            # è®°å½•éªŒè¯ç»“æžœ
            if validation_result['valid']:
                module_info = validation_result.get('module_info')
                if module_info:
                    signature = module_info.get_signature()
                    self.logger.info(f"âœ… [TaskFileContext] è®¾è®¡æ–‡ä»¶å®Œæ•´æ€§éªŒè¯é€šè¿‡: {signature}")
            else:
                issues = validation_result.get('issues', [])
                self.logger.warning(f"âš ï¸ [TaskFileContext] è®¾è®¡æ–‡ä»¶å®Œæ•´æ€§é—®é¢˜: {issues}")
                
                # è®°å½•è¯¦ç»†ä¿¡æ¯
                module_info = validation_result.get('module_info')
                if module_info:
                    self.logger.warning(f"âš ï¸ [TaskFileContext] æ–‡ä»¶: {file_path}")
                    self.logger.warning(f"âš ï¸ [TaskFileContext] ä»£ç ç­¾å: {module_info.get_signature()}")
                    self.logger.warning(f"âš ï¸ [TaskFileContext] ä»£ç è¡Œæ•°: {module_info.line_count}")
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ [TaskFileContext] è®¾è®¡æ–‡ä»¶å®Œæ•´æ€§éªŒè¯å¤±è´¥: {str(e)}")
    
    def validate_all_files_consistency(self) -> Dict[str, Any]:
        """éªŒè¯æ‰€æœ‰æ–‡ä»¶çš„ä¸€è‡´æ€§"""
        results = {}
        try:
            from core.code_consistency_checker import get_consistency_checker
            checker = get_consistency_checker()
            
            verilog_files = []
            for file_path, file_content in self.files.items():
                if file_content.file_type in [FileType.VERILOG, FileType.SYSTEMVERILOG]:
                    verilog_files.append((file_path, file_content.content))
            
            # å¦‚æžœæœ‰å¤šä¸ªVerilogæ–‡ä»¶ï¼Œæ£€æŸ¥å®ƒä»¬ä¹‹é—´çš„ä¸€è‡´æ€§
            if len(verilog_files) > 1:
                for i in range(len(verilog_files)):
                    for j in range(i + 1, len(verilog_files)):
                        file1_path, file1_content = verilog_files[i]
                        file2_path, file2_content = verilog_files[j]
                        
                        consistency_result = checker.check_consistency(file1_content, file2_content)
                        results[f"{file1_path}_vs_{file2_path}"] = {
                            "consistent": consistency_result.is_consistent,
                            "confidence": consistency_result.confidence,
                            "issues": consistency_result.issues,
                            "recommendations": consistency_result.recommendations
                        }
                        
                        if not consistency_result.is_consistent:
                            self.logger.warning(f"âš ï¸ [TaskFileContext] æ–‡ä»¶ä¸ä¸€è‡´: {file1_path} vs {file2_path}")
                            self.logger.warning(f"âš ï¸ [TaskFileContext] é—®é¢˜: {consistency_result.issues}")
            
            return results
            
        except Exception as e:
            self.logger.error(f"âŒ [TaskFileContext] æ–‡ä»¶ä¸€è‡´æ€§éªŒè¯å¤±è´¥: {str(e)}")
            return {"error": str(e)}

    def merge_context(self, other_context: 'TaskFileContext', override: bool = False):
        """åˆå¹¶å¦ä¸€ä¸ªä¸Šä¸‹æ–‡"""
        for file_path, file_content in other_context.files.items():
            if file_path not in self.files or override:
                self.files[file_path] = file_content
                self.logger.info(f"ðŸ“„ åˆå¹¶æ–‡ä»¶: {file_path}")
            else:
                self.logger.warning(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡åˆå¹¶: {file_path}")
        
        # åˆå¹¶ä¸»è¦æ–‡ä»¶è®¾ç½®
        if other_context.primary_design_file and (not self.primary_design_file or override):
            self.primary_design_file = other_context.primary_design_file
        
        if other_context.primary_testbench_file and (not self.primary_testbench_file or override):
            self.primary_testbench_file = other_context.primary_testbench_file
    
    def to_json(self) -> str:
        """åºåˆ—åŒ–ä¸ºJSON"""
        data = {
            'task_id': self.task_id,
            'primary_design_file': self.primary_design_file,
            'primary_testbench_file': self.primary_testbench_file,
            'creation_time': self._creation_time,
            'last_access_time': self._last_access_time,
            'files': [file_content.to_dict() for file_content in self.files.values()]
        }
        return json.dumps(data, indent=2, ensure_ascii=False)
    
    @classmethod
    def from_json(cls, json_str: str) -> 'TaskFileContext':
        """ä»ŽJSONååºåˆ—åŒ–"""
        data = json.loads(json_str)
        context = cls(data['task_id'])
        context.primary_design_file = data.get('primary_design_file')
        context.primary_testbench_file = data.get('primary_testbench_file')
        context._creation_time = data.get('creation_time', time.time())
        context._last_access_time = data.get('last_access_time', time.time())
        
        for file_data in data.get('files', []):
            file_content = FileContent(
                file_path=file_data['file_path'],
                content=file_data['content'],
                file_type=FileType(file_data['file_type']),
                checksum=file_data['checksum'],
                timestamp=file_data['timestamp'],
                metadata=file_data.get('metadata', {})
            )
            normalized_path = str(Path(file_data['file_path']).resolve())
            context.files[normalized_path] = file_content
        
        return context
    
    def __len__(self):
        return len(self.files)
    
    def __str__(self):
        return f"TaskFileContext(task_id={self.task_id}, files={len(self.files)}, primary_design={self.primary_design_file})"
    
    def __repr__(self):
        return self.__str__()


# å…¨å±€ä¸Šä¸‹æ–‡ç®¡ç†å™¨
_global_context_store: Dict[str, TaskFileContext] = {}

def get_task_context(task_id: str) -> Optional[TaskFileContext]:
    """èŽ·å–ä»»åŠ¡ä¸Šä¸‹æ–‡"""
    return _global_context_store.get(task_id)

def set_task_context(task_id: str, context: TaskFileContext):
    """è®¾ç½®ä»»åŠ¡ä¸Šä¸‹æ–‡"""
    _global_context_store[task_id] = context

def clear_task_context(task_id: str):
    """æ¸…é™¤ä»»åŠ¡ä¸Šä¸‹æ–‡"""
    if task_id in _global_context_store:
        del _global_context_store[task_id]

def clear_all_contexts():
    """æ¸…é™¤æ‰€æœ‰ä¸Šä¸‹æ–‡"""
    _global_context_store.clear()

def list_active_contexts() -> List[str]:
    """åˆ—å‡ºæ‰€æœ‰æ´»è·ƒä¸Šä¸‹æ–‡çš„ID"""
    return list(_global_context_store.keys())
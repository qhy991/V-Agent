#!/usr/bin/env python3
"""
ä¸­å¿ƒåŒ–åè°ƒæ™ºèƒ½ä½“

Centralized Coordinator Agent for Multi-Agent Framework
"""

import asyncio
import json
import logging
import time
from typing import Dict, Any, List, Optional, Set
from dataclasses import dataclass
from pathlib import Path

from .base_agent import BaseAgent, TaskMessage, FileReference
from .enums import AgentCapability, AgentStatus, ConversationState
from .response_format import ResponseFormat, StandardizedResponse
from .response_parser import ResponseParser, ResponseParseError
from config.config import FrameworkConfig, CoordinatorConfig
from llm_integration.enhanced_llm_client import EnhancedLLMClient


@dataclass
class AgentInfo:
    """æ™ºèƒ½ä½“ä¿¡æ¯"""
    agent_id: str
    role: str
    capabilities: Set[AgentCapability]
    status: AgentStatus
    specialty_description: str
    last_activity: float = 0.0
    task_count: int = 0
    success_rate: float = 1.0
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "agent_id": self.agent_id,
            "role": self.role,
            "capabilities": [cap.value for cap in self.capabilities],
            "status": self.status.value,
            "specialty_description": self.specialty_description,
            "last_activity": self.last_activity,
            "task_count": self.task_count,
            "success_rate": self.success_rate
        }


@dataclass
class ConversationRecord:
    """å¯¹è¯è®°å½•"""
    conversation_id: str
    timestamp: float
    speaker_id: str
    receiver_id: str
    message_content: str
    task_result: Optional[Dict[str, Any]] = None
    file_references: List[FileReference] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "conversation_id": self.conversation_id,
            "timestamp": self.timestamp,
            "speaker_id": self.speaker_id,
            "receiver_id": self.receiver_id,
            "message_content": self.message_content,
            "task_result": self.task_result,
            "file_references": [ref.to_dict() for ref in (self.file_references or [])]
        }


class CentralizedCoordinator(BaseAgent):
    """
    ä¸­å¿ƒåŒ–åè°ƒæ™ºèƒ½ä½“ - ç³»ç»Ÿçš„å¤§è„‘
    
    èŒè´£ï¼š
    1. ç»´æŠ¤å…¨å±€çŠ¶æ€å’Œå›¢é˜Ÿä¿¡æ¯
    2. åˆ†æä»»åŠ¡å¹¶é€‰æ‹©åˆé€‚çš„æ™ºèƒ½ä½“
    3. åŠ¨æ€å†³ç­–NextSpeaker
    4. å¤„ç†æ™ºèƒ½ä½“è¿”å›çš„ä¿¡æ¯
    5. åè°ƒæ•´ä¸ªå·¥ä½œæµç¨‹
    """
    
    def __init__(self, framework_config: FrameworkConfig, 
                 llm_client: EnhancedLLMClient = None):
        super().__init__(
            agent_id="centralized_coordinator",
            role="coordinator",
            capabilities={AgentCapability.TASK_COORDINATION, 
                         AgentCapability.WORKFLOW_MANAGEMENT}
        )
        
        self.framework_config = framework_config
        self.coordinator_config = framework_config.coordinator
        self.llm_client = llm_client
        
        # å›¢é˜Ÿç®¡ç†
        self.registered_agents: Dict[str, AgentInfo] = {}
        self.agent_instances: Dict[str, BaseAgent] = {}
        
        # å¯¹è¯ç®¡ç†
        self.conversation_history: List[ConversationRecord] = []
        self.current_conversation_id = None
        self.conversation_state = ConversationState.IDLE
        
        # ä»»åŠ¡ç®¡ç†
        self.active_tasks: Dict[str, Dict[str, Any]] = {}
        self.task_results: Dict[str, List[Dict[str, Any]]] = {}
        
        # å·¥ä½œæµç¨‹æ§åˆ¶
        self.max_conversation_iterations = self.coordinator_config.max_conversation_iterations
        self.conversation_timeout = self.coordinator_config.conversation_timeout
        
        # å“åº”è§£æå™¨
        self.response_parser = ResponseParser()
        self.preferred_response_format = ResponseFormat.JSON
        
        self.logger.info("ğŸ§  ä¸­å¿ƒåŒ–åè°ƒæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    def get_capabilities(self) -> Set[AgentCapability]:
        """è·å–åè°ƒè€…èƒ½åŠ›"""
        return {AgentCapability.TASK_COORDINATION, 
                AgentCapability.WORKFLOW_MANAGEMENT}
    
    def get_specialty_description(self) -> str:
        """è·å–ä¸“ä¸šæè¿°"""
        return "ä¸­å¿ƒåŒ–åè°ƒæ™ºèƒ½ä½“ï¼Œè´Ÿè´£ä»»åŠ¡åˆ†æã€æ™ºèƒ½ä½“é€‰æ‹©å’Œå·¥ä½œæµç¨‹åè°ƒ"
    
    # ==========================================================================
    # ğŸ¤ å›¢é˜Ÿç®¡ç†
    # ==========================================================================
    
    def register_agent(self, agent: BaseAgent) -> bool:
        """æ³¨å†Œæ™ºèƒ½ä½“"""
        try:
            agent_info = AgentInfo(
                agent_id=agent.agent_id,
                role=agent.role,
                capabilities=agent.get_capabilities(),
                status=AgentStatus.IDLE,
                specialty_description=agent.get_specialty_description(),
                last_activity=time.time()
            )
            
            self.registered_agents[agent.agent_id] = agent_info
            self.agent_instances[agent.agent_id] = agent
            
            self.logger.info(f"âœ… æ™ºèƒ½ä½“æ³¨å†ŒæˆåŠŸ: {agent.agent_id} ({agent.role})")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½ä½“æ³¨å†Œå¤±è´¥ {agent.agent_id}: {str(e)}")
            return False
    
    def unregister_agent(self, agent_id: str) -> bool:
        """æ³¨é”€æ™ºèƒ½ä½“"""
        if agent_id in self.registered_agents:
            del self.registered_agents[agent_id]
            if agent_id in self.agent_instances:
                del self.agent_instances[agent_id]
            self.logger.info(f"ğŸ—‘ï¸ æ™ºèƒ½ä½“æ³¨é”€æˆåŠŸ: {agent_id}")
            return True
        return False
    
    def get_team_status(self) -> Dict[str, Any]:
        """è·å–å›¢é˜ŸçŠ¶æ€"""
        return {
            "total_agents": len(self.registered_agents),
            "active_agents": len([info for info in self.registered_agents.values() 
                                if info.status == AgentStatus.WORKING]),
            "idle_agents": len([info for info in self.registered_agents.values() 
                              if info.status == AgentStatus.IDLE]),
            "agents": {agent_id: info.to_dict() 
                      for agent_id, info in self.registered_agents.items()},
            "conversation_state": self.conversation_state.value,
            "active_tasks": len(self.active_tasks)
        }
    
    # ==========================================================================
    # ğŸ¯ ä»»åŠ¡åˆ†æå’Œæ™ºèƒ½ä½“é€‰æ‹©
    # ==========================================================================
    
    async def analyze_task_requirements(self, task_description: str, 
                                      context: Dict[str, Any] = None) -> Dict[str, Any]:
        """åˆ†æä»»åŠ¡éœ€æ±‚"""
        if not self.llm_client:
            # ç®€å•çš„è§„åˆ™åˆ†æ
            return self._simple_task_analysis(task_description)
        
        # ä½¿ç”¨LLMè¿›è¡Œæ·±åº¦åˆ†æ
        analysis_prompt = f"""
Analyze the following task requirements and return a detailed analysis in JSON format.

Task Description: {task_description}

Please analyze the task from the following dimensions:
1. task_type: Type of task (design/testing/review/optimization)
2. complexity: Complexity level (1-10)
3. required_capabilities: Required capabilities (code_generation, test_generation, code_review, etc.)
4. estimated_hours: Estimated work hours
5. priority: Priority level (high/medium/low)
6. dependencies: Task dependencies

Return the analysis in this exact JSON format:
{{
    "task_type": "design",
    "complexity": 7,
    "required_capabilities": ["code_generation", "module_design"],
    "estimated_hours": 12,
    "priority": "high",
    "dependencies": []
}}

Task to analyze: {task_description}
"""
        
        try:
            response = await self.llm_client.send_prompt(
                prompt=analysis_prompt,
                temperature=self.coordinator_config.analysis_temperature,
                max_tokens=self.coordinator_config.analysis_max_tokens,
                json_mode=True
            )
            
            analysis = json.loads(response)
            
            # è§„èŒƒåŒ–åˆ†æç»“æœï¼Œå¤„ç†å¯èƒ½çš„ä¸­æ–‡å­—æ®µå
            normalized_analysis = self._normalize_task_analysis(analysis)
            
            self.logger.info(f"ğŸ“Š ä»»åŠ¡åˆ†æå®Œæˆ: å¤æ‚åº¦={normalized_analysis.get('complexity', 'N/A')}")
            return normalized_analysis
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ LLMä»»åŠ¡åˆ†æå¤±è´¥ï¼Œä½¿ç”¨ç®€å•åˆ†æ: {str(e)}")
            return self._simple_task_analysis(task_description)
    
    def _normalize_task_analysis(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è§„èŒƒåŒ–ä»»åŠ¡åˆ†æç»“æœï¼Œå¤„ç†ä¸­è‹±æ–‡å­—æ®µå"""
        # ä¸­è‹±æ–‡å­—æ®µåæ˜ å°„
        field_mapping = {
            "ä»»åŠ¡ç±»å‹": "task_type",
            "å¤æ‚åº¦ç­‰çº§": "complexity", 
            "å¤æ‚åº¦": "complexity",
            "éœ€è¦çš„èƒ½åŠ›": "required_capabilities",
            "æ‰€éœ€èƒ½åŠ›": "required_capabilities",
            "é¢„ä¼°å·¥ä½œé‡": "estimated_hours",
            "å·¥ä½œé‡": "estimated_hours",
            "ä¼˜å…ˆçº§": "priority",
            "ä¾èµ–å…³ç³»": "dependencies"
        }
        
        # åˆ›å»ºè§„èŒƒåŒ–çš„ç»“æœ
        normalized = {}
        
        for key, value in analysis.items():
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ˜ å°„
            if key in field_mapping:
                normalized[field_mapping[key]] = value
                self.logger.debug(f"ğŸ”„ æ˜ å°„å­—æ®µ: {key} -> {field_mapping[key]}")
            else:
                normalized[key] = value
        
        # ç¡®ä¿å¿…éœ€å­—æ®µå­˜åœ¨
        if "task_type" not in normalized:
            normalized["task_type"] = "unknown"
        if "complexity" not in normalized:
            normalized["complexity"] = 5
        if "required_capabilities" not in normalized:
            # æ ¹æ®ä»»åŠ¡ç±»å‹æ¨æ–­èƒ½åŠ›
            task_type = normalized.get("task_type", "unknown")
            if task_type == "design" or "è®¾è®¡" in str(analysis):
                normalized["required_capabilities"] = ["code_generation", "module_design"]
            elif task_type == "review" or "å®¡æŸ¥" in str(analysis):
                normalized["required_capabilities"] = ["code_review", "quality_analysis"]
            elif task_type == "testing" or "æµ‹è¯•" in str(analysis):
                normalized["required_capabilities"] = ["test_generation", "verification"]
            else:
                normalized["required_capabilities"] = ["code_generation"]
        
        self.logger.info(f"ğŸ”§ è§„èŒƒåŒ–ä»»åŠ¡åˆ†æ: {json.dumps(normalized, ensure_ascii=False)}")
        return normalized
    
    def _simple_task_analysis(self, task_description: str) -> Dict[str, Any]:
        """ç®€å•çš„ä»»åŠ¡åˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        description_lower = task_description.lower()
        
        # DEBUG: Log task description analysis
        self.logger.info(f"ğŸ” DEBUG: Simple Task Analysis")
        self.logger.info(f"ğŸ” DEBUG: Task description: '{task_description}'")
        self.logger.info(f"ğŸ” DEBUG: Description (lowercase): '{description_lower}'")
        
        # åŸºæœ¬åˆ†ç±» - æ›´ç²¾ç¡®çš„ä»»åŠ¡ç±»å‹æ£€æµ‹ï¼Œä¼˜å…ˆçº§é¡ºåºå¾ˆé‡è¦
        task_type = "unknown"
        
        # å®¡æŸ¥ç±»å…³é”®è¯ä¼˜å…ˆ - é¿å…è¢«è®¾è®¡ç±»å…³é”®è¯è¯¯è¯†åˆ«
        review_keywords = ["å®¡æŸ¥", "æ£€æŸ¥", "review", "check", "analyze", "inspect", "examine"]
        testing_keywords = ["æµ‹è¯•", "éªŒè¯", "testbench", "test", "verify", "validation", "simulation"]
        opt_keywords = ["ä¼˜åŒ–", "æ”¹è¿›", "æå‡", "optimize", "improve", "enhance", "refactor"]
        design_keywords = ["è®¾è®¡", "å®ç°", "ç¼–å†™", "ç”Ÿæˆ", "design", "implement", "write", "generate", "create", "build"]
        
        # ä¼˜å…ˆæ£€æµ‹æ›´å…·ä½“çš„ä»»åŠ¡ç±»å‹
        if any(word in description_lower for word in review_keywords):
            task_type = "review"
            self.logger.info(f"ğŸ” DEBUG: Detected review keywords: {[w for w in review_keywords if w in description_lower]}")
        elif any(word in description_lower for word in testing_keywords):
            task_type = "testing"
            self.logger.info(f"ğŸ” DEBUG: Detected testing keywords: {[w for w in testing_keywords if w in description_lower]}")
        elif any(word in description_lower for word in opt_keywords):
            task_type = "optimization"
            self.logger.info(f"ğŸ” DEBUG: Detected optimization keywords: {[w for w in opt_keywords if w in description_lower]}")
        elif any(word in description_lower for word in design_keywords):
            task_type = "design"
            self.logger.info(f"ğŸ” DEBUG: Detected design keywords: {[w for w in design_keywords if w in description_lower]}")
        
        self.logger.info(f"ğŸ” DEBUG: Determined task type: {task_type}")
        
        # å¤æ‚åº¦è¯„ä¼°
        complexity = 5  # é»˜è®¤ä¸­ç­‰å¤æ‚åº¦
        if len(task_description) > 200:
            complexity += 2
        if any(word in description_lower for word in ["32ä½", "å¤æ‚", "å¤šåŠŸèƒ½", "32bit", "complex", "multi"]):
            complexity += 2
        
        self.logger.info(f"ğŸ” DEBUG: Calculated complexity: {complexity}")
        
        # èƒ½åŠ›éœ€æ±‚æ¨æ–­ - åŒ¹é…å®é™…å­˜åœ¨çš„èƒ½åŠ›æšä¸¾
        required_capabilities = []
        if task_type == "design":
            required_capabilities = ["code_generation", "module_design"]
        elif task_type == "testing":
            required_capabilities = ["test_generation", "verification"]
        elif task_type == "review":
            required_capabilities = ["code_review", "quality_analysis"]
        elif task_type == "optimization":
            required_capabilities = ["performance_optimization"]
        else:
            required_capabilities = ["code_generation"]  # Default fallback
        
        self.logger.info(f"ğŸ” DEBUG: Required capabilities: {required_capabilities}")
            
        result = {
            "task_type": task_type,
            "complexity": min(complexity, 10),
            "required_capabilities": required_capabilities,
            "estimated_hours": complexity * 0.5,
            "priority": "medium",
            "dependencies": []
        }
        
        self.logger.info(f"ğŸ” DEBUG: Final task analysis: {json.dumps(result, indent=2)}")
        return result
    
    async def select_best_agent(self, task_analysis: Dict[str, Any], 
                              exclude_agents: Set[str] = None) -> Optional[str]:
        """é€‰æ‹©æœ€é€‚åˆçš„æ™ºèƒ½ä½“"""
        exclude_agents = exclude_agents or set()
        
        self.logger.info(f"ğŸ” DEBUG: Agent Selection Process Started")
        self.logger.info(f"ğŸ” DEBUG: Total registered agents: {len(self.registered_agents)}")
        self.logger.info(f"ğŸ” DEBUG: Excluded agents: {exclude_agents}")
        
        available_agents = {
            agent_id: info for agent_id, info in self.registered_agents.items()
            if agent_id not in exclude_agents and info.status != AgentStatus.FAILED
        }
        
        self.logger.info(f"ğŸ” DEBUG: Available agents after filtering: {len(available_agents)}")
        self.logger.info(f"ğŸ” DEBUG: Available agent details:")
        for agent_id, info in available_agents.items():
            self.logger.info(f"  - {agent_id}: status={info.status.value}, capabilities={[cap.value for cap in info.capabilities]}")
        
        if not available_agents:
            self.logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„æ™ºèƒ½ä½“")
            return None
        
        self.logger.info(f"ğŸ” DEBUG: LLM client available: {self.llm_client is not None}")
        
        if not self.llm_client:
            # ç®€å•é€‰æ‹©ç­–ç•¥
            self.logger.info(f"ğŸ” DEBUG: Using simple agent selection strategy")
            return self._simple_agent_selection(task_analysis, available_agents)
        
        # ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½é€‰æ‹©
        self.logger.info(f"ğŸ” DEBUG: Using LLM agent selection strategy")
        return await self._llm_agent_selection(task_analysis, available_agents)
    
    def _simple_agent_selection(self, task_analysis: Dict[str, Any], 
                              available_agents: Dict[str, AgentInfo]) -> str:
        """ç®€å•çš„æ™ºèƒ½ä½“é€‰æ‹©ç­–ç•¥"""
        task_type = task_analysis.get("task_type", "unknown")
        
        self.logger.info(f"ğŸ” DEBUG: Simple Agent Selection")
        self.logger.info(f"ğŸ” DEBUG: Task type: {task_type}")
        self.logger.info(f"ğŸ” DEBUG: Available agents: {list(available_agents.keys())}")
        
        # æŒ‰ä»»åŠ¡ç±»å‹é€‰æ‹©
        if task_type == "design":
            self.logger.info(f"ğŸ” DEBUG: Looking for agents with CODE_GENERATION capability")
            for agent_id, info in available_agents.items():
                self.logger.info(f"ğŸ” DEBUG: Checking {agent_id}: {[cap.value for cap in info.capabilities]}")
                if AgentCapability.CODE_GENERATION in info.capabilities:
                    self.logger.info(f"ğŸ” DEBUG: Selected {agent_id} for design task")
                    return agent_id
        elif task_type == "testing":
            self.logger.info(f"ğŸ” DEBUG: Looking for agents with TEST_GENERATION capability")
            for agent_id, info in available_agents.items():
                self.logger.info(f"ğŸ” DEBUG: Checking {agent_id}: {[cap.value for cap in info.capabilities]}")
                if AgentCapability.TEST_GENERATION in info.capabilities:
                    self.logger.info(f"ğŸ” DEBUG: Selected {agent_id} for testing task")
                    return agent_id
        elif task_type == "review":
            self.logger.info(f"ğŸ” DEBUG: Looking for agents with CODE_REVIEW capability")
            for agent_id, info in available_agents.items():
                self.logger.info(f"ğŸ” DEBUG: Checking {agent_id}: {[cap.value for cap in info.capabilities]}")
                if AgentCapability.CODE_REVIEW in info.capabilities:
                    self.logger.info(f"ğŸ” DEBUG: Selected {agent_id} for review task")
                    return agent_id
        
        # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ™ºèƒ½ä½“
        first_agent = list(available_agents.keys())[0]
        self.logger.info(f"ğŸ” DEBUG: No specific match found, selecting first available agent: {first_agent}")
        return first_agent
    
    async def _llm_agent_selection(self, task_analysis: Dict[str, Any], 
                                 available_agents: Dict[str, AgentInfo]) -> Optional[str]:
        """ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½ä½“é€‰æ‹©"""
        agents_info = "\n".join([
            f"- {agent_id}: {info.role} | èƒ½åŠ›: {[cap.value for cap in info.capabilities]} | "
            f"ä¸“é•¿: {info.specialty_description} | æˆåŠŸç‡: {info.success_rate:.2f}"
            for agent_id, info in available_agents.items()
        ])
        
        selection_prompt = f"""
You are a task coordinator selecting the best agent for a specific task. 

TASK ANALYSIS:
- Task Type: {task_analysis.get('task_type', 'unknown')}
- Complexity: {task_analysis.get('complexity', 5)}/10
- Required Capabilities: {task_analysis.get('required_capabilities', [])}

AVAILABLE AGENTS:
{agents_info}

SELECTION RULES:
1. For "design" tasks: Select agents with "code_generation" or "module_design" capabilities
2. For "testing" tasks: Select agents with "test_generation" or "verification" capabilities  
3. For "review" tasks: Select agents with "code_review" or "quality_analysis" capabilities
4. For "optimization" tasks: Select agents with "performance_optimization" capabilities
5. Consider agent success rate (higher is better)
6. Match capabilities to task requirements as closely as possible

RESPONSE FORMAT:
Return ONLY the exact agent_id (case-sensitive) from the available agents list above.
If no agent is suitable, return exactly "none".

Examples:
- If real_verilog_design_agent is available for a design task: real_verilog_design_agent
- If no suitable agent exists: none

Your selection:"""
        
        # DEBUG: Log detailed information before LLM call
        self.logger.info("ğŸ” DEBUG: LLM Agent Selection Details")
        self.logger.info(f"ğŸ” DEBUG: Available agents count: {len(available_agents)}")
        self.logger.info(f"ğŸ” DEBUG: Available agent IDs: {list(available_agents.keys())}")
        
        for agent_id, info in available_agents.items():
            self.logger.info(f"ğŸ” DEBUG: Agent {agent_id}:")
            self.logger.info(f"  - Role: {info.role}")
            self.logger.info(f"  - Capabilities: {[cap.value for cap in info.capabilities]}")
            self.logger.info(f"  - Status: {info.status.value}")
            self.logger.info(f"  - Specialty: {info.specialty_description}")
            self.logger.info(f"  - Success Rate: {info.success_rate:.2f}")
        
        self.logger.info(f"ğŸ” DEBUG: Task Analysis: {json.dumps(task_analysis, indent=2)}")
        self.logger.info(f"ğŸ” DEBUG: Agents Info String:\n{agents_info}")
        self.logger.info(f"ğŸ” DEBUG: Full Selection Prompt:\n{selection_prompt}")
        
        try:
            response = await self.llm_client.send_prompt(
                prompt=selection_prompt,
                temperature=self.coordinator_config.decision_temperature,
                max_tokens=100
            )
            
            # DEBUG: Log raw LLM response
            self.logger.info(f"ğŸ” DEBUG: Raw LLM response: '{response}'")
            self.logger.info(f"ğŸ” DEBUG: Response length: {len(response)}")
            self.logger.info(f"ğŸ” DEBUG: Response type: {type(response)}")
            
            selected_agent = response.strip().lower()
            self.logger.info(f"ğŸ” DEBUG: Processed response: '{selected_agent}'")
            
            # DEBUG: Check each available agent ID against the response
            for agent_id in available_agents.keys():
                self.logger.info(f"ğŸ” DEBUG: Checking '{selected_agent}' == '{agent_id.lower()}': {selected_agent == agent_id.lower()}")
            
            # éªŒè¯é€‰æ‹©ç»“æœ
            if selected_agent in available_agents:
                self.logger.info(f"ğŸ¯ LLMé€‰æ‹©æ™ºèƒ½ä½“: {selected_agent}")
                return selected_agent
            elif any(selected_agent == agent_id.lower() for agent_id in available_agents.keys()):
                # Handle case-insensitive matching
                for agent_id in available_agents.keys():
                    if selected_agent == agent_id.lower():
                        self.logger.info(f"ğŸ¯ LLMé€‰æ‹©æ™ºèƒ½ä½“ (case-insensitive match): {agent_id}")
                        return agent_id
            elif selected_agent == "none":
                self.logger.warning("âš ï¸ LLMè®¤ä¸ºæ²¡æœ‰åˆé€‚çš„æ™ºèƒ½ä½“")
                self.logger.info(f"ğŸ” DEBUG: This indicates the LLM doesn't think any available agents are suitable for the task")
                return None
            else:
                self.logger.warning(f"âš ï¸ LLMé€‰æ‹©äº†æ— æ•ˆæ™ºèƒ½ä½“: '{selected_agent}' (Available: {list(available_agents.keys())})")
                self.logger.info(f"ğŸ” DEBUG: Falling back to simple agent selection")
                return self._simple_agent_selection(task_analysis, available_agents)
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ LLMæ™ºèƒ½ä½“é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨ç®€å•ç­–ç•¥: {str(e)}")
            return self._simple_agent_selection(task_analysis, available_agents)
    
    # ==========================================================================
    # ğŸ’¬ å¯¹è¯åè°ƒ
    # ==========================================================================
    
    async def coordinate_task_execution(self, initial_task: str, 
                                      context: Dict[str, Any] = None) -> Dict[str, Any]:
        """åè°ƒä»»åŠ¡æ‰§è¡Œ"""
        self.conversation_state = ConversationState.ACTIVE
        conversation_id = f"conv_{int(time.time())}"
        self.current_conversation_id = conversation_id
        
        self.logger.info(f"ğŸš€ å¼€å§‹ä»»åŠ¡åè°ƒ: {conversation_id}")
        
        try:
            # 1. åˆ†æä»»åŠ¡
            task_analysis = await self.analyze_task_requirements(initial_task, context)
            
            # 2. é€‰æ‹©åˆå§‹æ™ºèƒ½ä½“
            selected_agent_id = await self.select_best_agent(task_analysis)
            if not selected_agent_id:
                return {
                    "success": False,
                    "error": "æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„æ™ºèƒ½ä½“",
                    "conversation_id": conversation_id
                }
            
            # 3. å¼€å§‹å¤šè½®å¯¹è¯
            conversation_results = await self._execute_multi_round_conversation(
                conversation_id=conversation_id,
                initial_task=initial_task,
                initial_agent_id=selected_agent_id,
                task_analysis=task_analysis
            )
            
            self.conversation_state = ConversationState.COMPLETED
            return conversation_results
            
        except Exception as e:
            self.conversation_state = ConversationState.FAILED
            self.logger.error(f"âŒ ä»»åŠ¡åè°ƒå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "conversation_id": conversation_id
            }
    
    async def _execute_multi_round_conversation(self, conversation_id: str, 
                                              initial_task: str, initial_agent_id: str,
                                              task_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå¤šè½®å¯¹è¯"""
        conversation_start = time.time()
        current_speaker = initial_agent_id
        iteration_count = 0
        all_file_references = []
        task_completed = False
        
        self.logger.info(f"ğŸ’¬ å¯åŠ¨å¤šè½®å¯¹è¯: {conversation_id}")
        
        while (iteration_count < self.max_conversation_iterations and 
               time.time() - conversation_start < self.conversation_timeout and
               not task_completed):
            
            iteration_count += 1
            self.logger.info(f"ğŸ”„ å¯¹è¯è½®æ¬¡ {iteration_count}: {current_speaker} å‘è¨€")
            
            try:
                # 1. æ„å»ºä»»åŠ¡æ¶ˆæ¯
                task_message = TaskMessage(
                    task_id=conversation_id,
                    sender_id=self.agent_id,
                    receiver_id=current_speaker,
                    message_type="task_execution",
                    content=initial_task if iteration_count == 1 else "ç»§ç»­å¤„ç†ä»»åŠ¡",
                    file_references=all_file_references[-5:] if all_file_references else None,  # æœ€è¿‘5ä¸ªæ–‡ä»¶
                    metadata={"iteration": iteration_count, "task_analysis": task_analysis}
                )
                
                # 2. æ™ºèƒ½ä½“æ‰§è¡Œä»»åŠ¡
                agent_instance = self.agent_instances[current_speaker]
                task_result = await agent_instance.process_task_with_file_references(task_message)
                
                # 3. è§£æå’Œå¤„ç†æ ‡å‡†åŒ–å“åº”
                parsed_response = await self._process_agent_response(
                    agent_id=current_speaker,
                    raw_response=task_result,
                    task_id=conversation_id
                )
                
                # 4. è®°å½•å¯¹è¯
                conversation_record = ConversationRecord(
                    conversation_id=conversation_id,
                    timestamp=time.time(),
                    speaker_id=current_speaker,
                    receiver_id=self.agent_id,
                    message_content=task_message.content,
                    task_result=parsed_response,
                    file_references=parsed_response.get("file_references", [])
                )
                self.conversation_history.append(conversation_record)
                
                # 5. æ”¶é›†æ–‡ä»¶å¼•ç”¨
                if parsed_response.get("file_references"):
                    all_file_references.extend(parsed_response["file_references"])
                
                # 6. æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
                if parsed_response.get("success", False) and parsed_response.get("task_completed", False):
                    task_completed = True
                    self.logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {current_speaker}")
                    break
                
                # 7. å†³å®šä¸‹ä¸€ä¸ªå‘è¨€è€…
                next_speaker = await self._decide_next_speaker(
                    current_result=parsed_response,
                    conversation_history=self.conversation_history[-3:],  # æœ€è¿‘3è½®
                    task_analysis=task_analysis
                )
                
                if next_speaker == current_speaker or not next_speaker:
                    # æ²¡æœ‰æ›´å¥½çš„é€‰æ‹©ï¼Œç»§ç»­å½“å‰æ™ºèƒ½ä½“
                    self.logger.info(f"ğŸ“ ç»§ç»­ä½¿ç”¨å½“å‰æ™ºèƒ½ä½“: {current_speaker}")
                else:
                    current_speaker = next_speaker
                    self.logger.info(f"ğŸ”„ åˆ‡æ¢åˆ°æ™ºèƒ½ä½“: {current_speaker}")
                
            except Exception as e:
                self.logger.error(f"âŒ å¯¹è¯è½®æ¬¡ {iteration_count} å¤±è´¥: {str(e)}")
                break
        
        # ç”Ÿæˆæœ€ç»ˆç»“æœ
        total_duration = time.time() - conversation_start
        return {
            "success": task_completed,
            "conversation_id": conversation_id,
            "total_iterations": iteration_count,
            "duration": total_duration,
            "file_references": all_file_references,
            "conversation_history": [record.to_dict() for record in self.conversation_history[-iteration_count:]],
            "final_speaker": current_speaker,
            "task_analysis": task_analysis
        }
    
    async def _decide_next_speaker(self, current_result: Dict[str, Any],
                                 conversation_history: List[ConversationRecord],
                                 task_analysis: Dict[str, Any]) -> Optional[str]:
        """å†³å®šä¸‹ä¸€ä¸ªå‘è¨€è€…"""
        if not self.llm_client:
            return self._simple_next_speaker_decision(current_result)
        
        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
        history_summary = "\n".join([
            f"- {record.speaker_id}: {record.message_content[:100]}... "
            f"(æˆåŠŸ: {record.task_result.get('success', False) if record.task_result else False})"
            for record in conversation_history
        ])
        
        available_agents = "\n".join([
            f"- {agent_id}: {info.role} | èƒ½åŠ›: {[cap.value for cap in info.capabilities]}"
            for agent_id, info in self.registered_agents.items()
            if info.status != AgentStatus.FAILED
        ])
        
        decision_prompt = f"""
åŸºäºå½“å‰ä»»åŠ¡æ‰§è¡Œæƒ…å†µï¼Œå†³å®šä¸‹ä¸€ä¸ªæœ€é€‚åˆçš„æ™ºèƒ½ä½“ï¼š

ä»»åŠ¡åˆ†æ:
- ç±»å‹: {task_analysis.get('task_type', 'unknown')}
- å¤æ‚åº¦: {task_analysis.get('complexity', 5)}

å½“å‰æ‰§è¡Œç»“æœ:
- æˆåŠŸ: {current_result.get('success', False)}
- é”™è¯¯: {current_result.get('error', 'None')}
- ç”Ÿæˆæ–‡ä»¶: {len(current_result.get('file_references', []))}

å¯¹è¯å†å²:
{history_summary}

å¯ç”¨æ™ºèƒ½ä½“:
{available_agents}

è¯·é€‰æ‹©ä¸‹ä¸€ä¸ªæœ€é€‚åˆçš„æ™ºèƒ½ä½“IDï¼Œåªè¿”å›agent_idã€‚
å¦‚æœå½“å‰æ™ºèƒ½ä½“åº”è¯¥ç»§ç»­ï¼Œè¿”å›"continue"ã€‚
å¦‚æœä»»åŠ¡å·²å®Œæˆï¼Œè¿”å›"complete"ã€‚
"""
        
        try:
            response = await self.llm_client.send_prompt(
                prompt=decision_prompt,
                temperature=self.coordinator_config.decision_temperature,
                max_tokens=self.coordinator_config.decision_max_tokens
            )
            
            decision = response.strip().lower()
            
            if decision == "continue":
                return None  # ç»§ç»­å½“å‰æ™ºèƒ½ä½“
            elif decision == "complete":
                return None  # ä»»åŠ¡å®Œæˆ
            elif decision in self.registered_agents:
                return decision
            else:
                self.logger.warning(f"âš ï¸ LLMè¿”å›æ— æ•ˆå†³ç­–: {decision}")
                return None
                
        except Exception as e:
            self.logger.warning(f"âš ï¸ NextSpeakerå†³ç­–å¤±è´¥: {str(e)}")
            return self._simple_next_speaker_decision(current_result)
    
    # ==========================================================================
    # ğŸ“ æ ‡å‡†åŒ–å“åº”å¤„ç†
    # ==========================================================================
    
    async def _process_agent_response(self, agent_id: str, raw_response: Dict[str, Any], 
                                    task_id: str) -> Dict[str, Any]:
        """å¤„ç†æ™ºèƒ½ä½“å“åº”"""
        try:
            # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«æ ‡å‡†åŒ–å“åº”æ ¼å¼
            standardized_response = None
            response_content = None
            
            # å°è¯•ä»å“åº”ä¸­æå–æ ‡å‡†åŒ–æ ¼å¼å†…å®¹
            if "standardized_response" in raw_response:
                response_content = raw_response["standardized_response"]
            elif "formatted_response" in raw_response:
                response_content = raw_response["formatted_response"]
            elif isinstance(raw_response.get("response"), str):
                # æ£€æŸ¥å“åº”å­—ç¬¦ä¸²æ˜¯å¦æ˜¯æ ‡å‡†åŒ–æ ¼å¼
                response_str = raw_response["response"]
                if self._is_standardized_format(response_str):
                    response_content = response_str
            
            # 2. è§£ææ ‡å‡†åŒ–å“åº”
            if response_content:
                try:
                    standardized_response = self.response_parser.parse_response(response_content)
                    self.logger.info(f"âœ… æˆåŠŸè§£ææ ‡å‡†åŒ–å“åº”: {agent_id}")
                except ResponseParseError as e:
                    self.logger.warning(f"âš ï¸ æ ‡å‡†åŒ–å“åº”è§£æå¤±è´¥ {agent_id}: {str(e)}")
                    standardized_response = None
            
            # 3. è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            if standardized_response:
                return self._convert_standardized_to_internal(standardized_response, raw_response)
            else:
                return self._convert_legacy_to_internal(raw_response, agent_id, task_id)
                
        except Exception as e:
            self.logger.error(f"âŒ å“åº”å¤„ç†å¤±è´¥ {agent_id}: {str(e)}")
            return self._create_error_response(raw_response, str(e))
    
    def _is_standardized_format(self, content: str) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦æ˜¯æ ‡å‡†åŒ–æ ¼å¼"""
        content_stripped = content.strip()
        
        # æ£€æŸ¥JSONæ ¼å¼
        if content_stripped.startswith('{') and '"agent_name"' in content:
            return True
        
        # æ£€æŸ¥XMLæ ¼å¼
        if content_stripped.startswith('<agent_response>'):
            return True
        
        # æ£€æŸ¥Markdownæ ¼å¼
        if '# Agent Response:' in content:
            return True
        
        return False
    
    def _convert_standardized_to_internal(self, standardized_response: StandardizedResponse, 
                                        raw_response: Dict[str, Any]) -> Dict[str, Any]:
        """å°†æ ‡å‡†åŒ–å“åº”è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼"""
        # è½¬æ¢æ–‡ä»¶å¼•ç”¨
        file_references = []
        for file_ref in (standardized_response.generated_files + 
                        standardized_response.modified_files + 
                        standardized_response.reference_files):
            file_references.append(FileReference(
                file_path=file_ref.path,
                file_type=file_ref.file_type,
                description=file_ref.description,
                metadata={
                    "created_at": file_ref.created_at,
                    "size_bytes": file_ref.size_bytes
                }
            ))
        
        # ç¡®å®šä»»åŠ¡çŠ¶æ€
        success = standardized_response.status.value in ['success', 'partial_success']
        task_completed = standardized_response.status.value == 'success' and standardized_response.completion_percentage >= 100.0
        
        return {
            "success": success,
            "task_completed": task_completed,
            "agent_id": standardized_response.agent_id,
            "agent_name": standardized_response.agent_name,
            "message": standardized_response.message,
            "status": standardized_response.status.value,
            "completion_percentage": standardized_response.completion_percentage,
            "file_references": file_references,
            "issues": [issue.to_dict() for issue in standardized_response.issues],
            "quality_metrics": standardized_response.quality_metrics.to_dict() if standardized_response.quality_metrics else None,
            "next_steps": standardized_response.next_steps,
            "metadata": standardized_response.metadata,
            "error": None if success else f"Task failed: {standardized_response.message}",
            "raw_response": raw_response,
            "response_type": standardized_response.response_type.value,
            "timestamp": standardized_response.timestamp
        }
    
    def _convert_legacy_to_internal(self, raw_response: Dict[str, Any], 
                                  agent_id: str, task_id: str) -> Dict[str, Any]:
        """å°†ä¼ ç»Ÿå“åº”è½¬æ¢ä¸ºå†…éƒ¨æ ¼å¼"""
        self.logger.info(f"ğŸ“„ ä½¿ç”¨ä¼ ç»Ÿå“åº”æ ¼å¼: {agent_id}")
        
        # æå–åŸºæœ¬ä¿¡æ¯
        success = raw_response.get("success", False)
        message = raw_response.get("message", raw_response.get("response", "No message"))
        error = raw_response.get("error")
        
        # å¤„ç†æ–‡ä»¶å¼•ç”¨
        file_references = []
        if "file_references" in raw_response:
            for ref in raw_response["file_references"]:
                if isinstance(ref, dict):
                    file_references.append(FileReference(
                        file_path=ref.get("file_path", ""),
                        file_type=ref.get("file_type", "unknown"),
                        description=ref.get("description", ""),
                        metadata=ref.get("metadata", {})
                    ))
        
        # æ£€æŸ¥ç”Ÿæˆçš„æ–‡ä»¶
        if "generated_files" in raw_response:
            for file_path in raw_response["generated_files"]:
                file_references.append(FileReference(
                    file_path=file_path,
                    file_type=self._detect_file_type(file_path),
                    description=f"Generated file by {agent_id}",
                    metadata={"generated_by": agent_id}
                ))
        
        return {
            "success": success,
            "task_completed": success,  # ç®€å•å‡è®¾æˆåŠŸå³å®Œæˆ
            "agent_id": agent_id,
            "agent_name": raw_response.get("agent_name", agent_id),
            "message": message,
            "status": "success" if success else "failed",
            "completion_percentage": 100.0 if success else 0.0,
            "file_references": file_references,
            "issues": [],
            "quality_metrics": None,
            "next_steps": [],
            "metadata": {"legacy_response": True},
            "error": error,
            "raw_response": raw_response,
            "response_type": "task_completion",
            "timestamp": str(time.time())
        }
    
    def _create_error_response(self, raw_response: Dict[str, Any], error_message: str) -> Dict[str, Any]:
        """åˆ›å»ºé”™è¯¯å“åº”"""
        return {
            "success": False,
            "task_completed": False,
            "agent_id": "unknown",
            "agent_name": "Unknown",
            "message": f"Response processing failed: {error_message}",
            "status": "failed",
            "completion_percentage": 0.0,
            "file_references": [],
            "issues": [{"issue_type": "error", "severity": "high", "description": error_message}],
            "quality_metrics": None,
            "next_steps": ["Fix response format"],
            "metadata": {"processing_error": True},
            "error": error_message,
            "raw_response": raw_response,
            "response_type": "error_report",
            "timestamp": str(time.time())
        }
    
    def _detect_file_type(self, file_path: str) -> str:
        """æ£€æµ‹æ–‡ä»¶ç±»å‹"""
        if file_path.endswith('.v'):
            return 'verilog'
        elif file_path.endswith('_tb.v') or 'testbench' in file_path.lower():
            return 'testbench'
        elif file_path.endswith('.json'):
            return 'json'
        elif file_path.endswith('.md'):
            return 'documentation'
        elif file_path.endswith('.txt'):
            return 'text'
        else:
            return 'unknown'
    
    def set_preferred_response_format(self, format_type: ResponseFormat):
        """è®¾ç½®é¦–é€‰å“åº”æ ¼å¼"""
        self.preferred_response_format = format_type
        self.logger.info(f"ğŸ“ è®¾ç½®é¦–é€‰å“åº”æ ¼å¼: {format_type.value}")
    
    def get_response_format_instructions(self) -> str:
        """è·å–å“åº”æ ¼å¼è¯´æ˜"""
        if self.preferred_response_format == ResponseFormat.JSON:
            return """
è¯·ä½¿ç”¨ä»¥ä¸‹JSONæ ¼å¼è¿”å›å“åº”ï¼š
{
  "agent_name": "your_agent_class_name",
  "agent_id": "your_agent_id", 
  "status": "success|failed|in_progress",
  "completion_percentage": 0-100,
  "message": "main response message",
  "generated_files": [{"path": "...", "file_type": "...", "description": "..."}],
  "issues": [{"issue_type": "...", "severity": "...", "description": "..."}],
  "next_steps": ["step1", "step2"]
}
"""
        elif self.preferred_response_format == ResponseFormat.MARKDOWN:
            return """
è¯·ä½¿ç”¨ä»¥ä¸‹Markdownæ ¼å¼è¿”å›å“åº”ï¼š
# Agent Response: YourAgentName
## ğŸ“‹ Basic Information
- **Agent**: YourAgentName (`agent_id`)
- **Status**: success/failed/in_progress
- **Progress**: X.X%
## ğŸ’¬ Message
Your main response message here
## ğŸ“ Files
### Generated Files
- **path/to/file.v** (verilog): Description
"""
        else:
            return "è¯·è¿”å›ç»“æ„åŒ–çš„å“åº”ä¿¡æ¯"
    
    def _simple_next_speaker_decision(self, current_result: Dict[str, Any]) -> Optional[str]:
        """ç®€å•çš„ä¸‹ä¸€ä¸ªå‘è¨€è€…å†³ç­–"""
        # å¦‚æœå½“å‰ä»»åŠ¡æˆåŠŸï¼Œå¯èƒ½éœ€è¦æµ‹è¯•æ™ºèƒ½ä½“
        if current_result.get("success", False):
            for agent_id, info in self.registered_agents.items():
                if (AgentCapability.TEST_GENERATION in info.capabilities and 
                    info.status == AgentStatus.IDLE):
                    return agent_id
        
        return None  # ç»§ç»­å½“å‰æ™ºèƒ½ä½“
    
    # ==========================================================================
    # ğŸ“Š çŠ¶æ€å’Œç»Ÿè®¡
    # ==========================================================================
    
    async def execute_enhanced_task(self, enhanced_prompt: str,
                                  original_message: TaskMessage,
                                  file_contents: Dict[str, Dict]) -> Dict[str, Any]:
        """åè°ƒè€…çš„å¢å¼ºä»»åŠ¡æ‰§è¡Œ"""
        return await self.coordinate_task_execution(
            initial_task=enhanced_prompt,
            context={"original_message": original_message.to_dict(), 
                    "file_contents": file_contents}
        )
    
    def get_conversation_statistics(self) -> Dict[str, Any]:
        """è·å–å¯¹è¯ç»Ÿè®¡"""
        total_conversations = len(set(record.conversation_id for record in self.conversation_history))
        total_rounds = len(self.conversation_history)
        
        agent_activity = {}
        for record in self.conversation_history:
            agent_id = record.speaker_id
            if agent_id not in agent_activity:
                agent_activity[agent_id] = {"rounds": 0, "successes": 0}
            agent_activity[agent_id]["rounds"] += 1
            if record.task_result and record.task_result.get("success", False):
                agent_activity[agent_id]["successes"] += 1
        
        return {
            "total_conversations": total_conversations,
            "total_rounds": total_rounds,
            "average_rounds_per_conversation": total_rounds / max(total_conversations, 1),
            "agent_activity": agent_activity,
            "current_state": self.conversation_state.value,
            "team_status": self.get_team_status()
        }
    
    def save_conversation_log(self, output_path: str = None) -> str:
        """ä¿å­˜å¯¹è¯æ—¥å¿—"""
        if not output_path:
            timestamp = int(time.time())
            output_path = f"conversation_log_{timestamp}.json"
        
        log_data = {
            "coordinator_id": self.agent_id,
            "timestamp": time.time(),
            "conversation_history": [record.to_dict() for record in self.conversation_history],
            "team_status": self.get_team_status(),
            "statistics": self.get_conversation_statistics()
        }
        
        try:
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, ensure_ascii=False, indent=2, default=str)
            
            self.logger.info(f"ğŸ’¾ å¯¹è¯æ—¥å¿—å·²ä¿å­˜: {output_path}")
            return output_path
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜å¯¹è¯æ—¥å¿—å¤±è´¥: {str(e)}")
            raise

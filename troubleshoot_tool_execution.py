#!/usr/bin/env python3
"""
å·¥å…·æ‰§è¡Œé—®é¢˜æ’æŸ¥è„šæœ¬
ä¸“é—¨ç”¨äºæ’æŸ¥å·¥å…·æ‰§è¡Œå¼•æ“çš„è·¯ç”±é€»è¾‘é—®é¢˜
"""

import sys
import os
import asyncio
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from core.function_calling import ToolCall, ToolResult
from core.schema_system.unified_schemas import UnifiedSchemas
from core.schema_system.flexible_schema_adapter import FlexibleSchemaAdapter
from core.schema_system.schema_validator import SchemaValidator
from core.schema_system.parameter_repairer import ParameterRepairer
from core.enhanced_tool_registry import EnhancedToolRegistry

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ToolExecutionTroubleshooter:
    """å·¥å…·æ‰§è¡Œé—®é¢˜æ’æŸ¥å™¨"""
    
    def __init__(self):
        self.schema_adapter = FlexibleSchemaAdapter()
        self.schema_validator = SchemaValidator()
        self.parameter_repairer = ParameterRepairer()
        self.tool_registry = EnhancedToolRegistry()
        
    async def setup_test_environment(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        logger.info("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
        
        # æ³¨å†ŒçœŸå®çš„ generate_testbench å·¥å…·
        await self._register_real_tools()
        
        logger.info("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")
    
    async def _register_real_tools(self):
        """æ³¨å†ŒçœŸå®çš„å·¥å…·"""
        logger.info("ğŸ“ æ³¨å†ŒçœŸå®å·¥å…·...")
        
        # æ¨¡æ‹ŸçœŸå®çš„ generate_testbench å·¥å…·
        def real_generate_testbench(module_name: str, verilog_code: str, test_scenarios: list = None):
            return {
                "success": True,
                "testbench_code": f"// Testbench for {module_name}\nmodule {module_name}_tb;\n// ...",
                "message": "Testbench generated successfully"
            }
        
        # æ³¨å†Œå·¥å…·
        self.tool_registry.register_tool(
            name="generate_testbench",
            func=real_generate_testbench,
            description="Generate testbench for Verilog module",
            schema={
                "type": "object",
                "properties": {
                    "module_name": {"type": "string"},
                    "verilog_code": {"type": "string"},
                    "test_scenarios": {"type": "array", "items": {"type": "string"}}
                },
                "required": ["module_name", "verilog_code"]
            }
        )
        
        logger.info(f"âœ… å·²æ³¨å†Œå·¥å…·: {list(self.tool_registry.tools.keys())}")
    
    async def test_tool_execution_flow(self):
        """æµ‹è¯•å®Œæ•´çš„å·¥å…·æ‰§è¡Œæµç¨‹"""
        logger.info("ğŸ” æµ‹è¯•å®Œæ•´çš„å·¥å…·æ‰§è¡Œæµç¨‹...")
        
        # åˆ›å»ºå·¥å…·è°ƒç”¨
        tool_call = ToolCall(
            tool_name="generate_testbench",
            parameters={
                "module_name": "counter",
                "verilog_code": "module counter(...); endmodule",
                "test_scenarios": ["test1", "test2"]
            },
            call_id="test_call_001"
        )
        
        logger.info(f"ğŸ“‹ å·¥å…·è°ƒç”¨: {tool_call.tool_name}")
        logger.info(f"ğŸ“‹ å‚æ•°: {tool_call.parameters}")
        
        # æ­¥éª¤1: æ£€æŸ¥å·¥å…·æ˜¯å¦æ³¨å†Œ
        if tool_call.tool_name not in self.tool_registry.tools:
            logger.error(f"âŒ å·¥å…· {tool_call.tool_name} æœªåœ¨æ³¨å†Œè¡¨ä¸­")
            return
        
        logger.info("âœ… å·¥å…·åœ¨æ³¨å†Œè¡¨ä¸­")
        
        # æ­¥éª¤2: è·å–å·¥å…·å®šä¹‰
        tool_func = self.tool_registry.tools[tool_call.tool_name]
        logger.info(f"âœ… è·å–å·¥å…·å‡½æ•°: {tool_func}")
        
        # æ­¥éª¤3: éªŒè¯å‚æ•°
        is_valid, error_msg = self.tool_registry.validate_parameters(
            tool_call.tool_name, tool_call.parameters
        )
        
        if not is_valid:
            logger.error(f"âŒ å‚æ•°éªŒè¯å¤±è´¥: {error_msg}")
            return
        
        logger.info("âœ… å‚æ•°éªŒè¯é€šè¿‡")
        
        # æ­¥éª¤4: æ‰§è¡Œå·¥å…·
        try:
            result = await self.tool_registry.execute_tool(tool_call)
            
            if result.success:
                logger.info("âœ… å·¥å…·æ‰§è¡ŒæˆåŠŸ")
                logger.info(f"   ç»“æœ: {result.result}")
            else:
                logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {result.error}")
                
        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ‰§è¡Œå¼‚å¸¸: {e}")
            import traceback
            logger.error(f"   å †æ ˆ: {traceback.format_exc()}")
    
    async def test_enhanced_validation_flow(self):
        """æµ‹è¯•å¢å¼ºéªŒè¯æµç¨‹"""
        logger.info("ğŸ” æµ‹è¯•å¢å¼ºéªŒè¯æµç¨‹...")
        
        # åˆ›å»ºå·¥å…·è°ƒç”¨
        tool_call = ToolCall(
            tool_name="generate_testbench",
            parameters={
                "module_name": "counter",
                "verilog_code": "module counter(...); endmodule",
                "test_scenarios": ["test1", "test2"]
            },
            call_id="test_call_002"
        )
        
        # æ­¥éª¤1: ç»Ÿä¸€Schemaæ ‡å‡†åŒ–
        try:
            normalized_params = UnifiedSchemas.validate_and_normalize_parameters(
                tool_call.tool_name, tool_call.parameters
            )
            logger.info(f"âœ… ç»Ÿä¸€Schemaæ ‡å‡†åŒ–: {normalized_params}")
        except Exception as e:
            logger.error(f"âŒ ç»Ÿä¸€Schemaæ ‡å‡†åŒ–å¤±è´¥: {e}")
            return
        
        # æ­¥éª¤2: Schemaé€‚é…
        try:
            schema = {
                "type": "object",
                "properties": {
                    "module_name": {"type": "string"},
                    "verilog_code": {"type": "string"},
                    "test_scenarios": {"type": "array", "items": {"type": "string"}}
                },
                "required": ["module_name", "verilog_code"]
            }
            
            adaptation_result = self.schema_adapter.adapt_parameters(
                normalized_params, schema, tool_call.tool_name
            )
            
            if adaptation_result.success:
                logger.info(f"âœ… Schemaé€‚é…æˆåŠŸ: {adaptation_result.adapted_data}")
            else:
                logger.error(f"âŒ Schemaé€‚é…å¤±è´¥: {adaptation_result.warnings}")
                return
                
        except Exception as e:
            logger.error(f"âŒ Schemaé€‚é…å¼‚å¸¸: {e}")
            return
        
        # æ­¥éª¤3: SchemaéªŒè¯
        try:
            validation_result = self.schema_validator.validate(
                adaptation_result.adapted_data, schema
            )
            
            if validation_result.is_valid:
                logger.info("âœ… SchemaéªŒè¯é€šè¿‡")
            else:
                logger.error(f"âŒ SchemaéªŒè¯å¤±è´¥: {validation_result.get_error_summary()}")
                
                # å°è¯•å‚æ•°ä¿®å¤
                repair_result = self.parameter_repairer.repair_parameters(
                    adaptation_result.adapted_data, schema, validation_result
                )
                
                if repair_result.success:
                    logger.info(f"âœ… å‚æ•°ä¿®å¤æˆåŠŸ: {repair_result.repaired_data}")
                else:
                    logger.error(f"âŒ å‚æ•°ä¿®å¤å¤±è´¥")
                    return
                    
        except Exception as e:
            logger.error(f"âŒ SchemaéªŒè¯å¼‚å¸¸: {e}")
            return
        
        logger.info("âœ… å¢å¼ºéªŒè¯æµç¨‹å®Œæˆ")
    
    async def test_error_scenarios(self):
        """æµ‹è¯•é”™è¯¯åœºæ™¯"""
        logger.info("ğŸ” æµ‹è¯•é”™è¯¯åœºæ™¯...")
        
        # åœºæ™¯1: å·¥å…·ä¸å­˜åœ¨
        logger.info("ğŸ“‹ åœºæ™¯1: å·¥å…·ä¸å­˜åœ¨")
        non_existent_tool_call = ToolCall(
            tool_name="non_existent_tool",
            parameters={},
            call_id="test_call_003"
        )
        
        try:
            result = await self.tool_registry.execute_tool(non_existent_tool_call)
            logger.info(f"ç»“æœ: {result.success}, é”™è¯¯: {result.error}")
        except Exception as e:
            logger.error(f"å¼‚å¸¸: {e}")
        
        # åœºæ™¯2: å‚æ•°éªŒè¯å¤±è´¥
        logger.info("ğŸ“‹ åœºæ™¯2: å‚æ•°éªŒè¯å¤±è´¥")
        invalid_params_tool_call = ToolCall(
            tool_name="generate_testbench",
            parameters={
                "module_name": 123,  # åº”è¯¥æ˜¯å­—ç¬¦ä¸²
                "verilog_code": None  # åº”è¯¥æ˜¯å­—ç¬¦ä¸²
            },
            call_id="test_call_004"
        )
        
        try:
            result = await self.tool_registry.execute_tool(invalid_params_tool_call)
            logger.info(f"ç»“æœ: {result.success}, é”™è¯¯: {result.error}")
        except Exception as e:
            logger.error(f"å¼‚å¸¸: {e}")
        
        # åœºæ™¯3: å·¥å…·æ‰§è¡Œå¼‚å¸¸
        logger.info("ğŸ“‹ åœºæ™¯3: å·¥å…·æ‰§è¡Œå¼‚å¸¸")
        
        # æ³¨å†Œä¸€ä¸ªä¼šæŠ›å‡ºå¼‚å¸¸çš„å·¥å…·
        def failing_tool():
            raise Exception("æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œå¤±è´¥")
        
        self.tool_registry.register_tool(
            name="failing_tool",
            func=failing_tool,
            description="A tool that always fails",
            schema={"type": "object"}
        )
        
        failing_tool_call = ToolCall(
            tool_name="failing_tool",
            parameters={},
            call_id="test_call_005"
        )
        
        try:
            result = await self.tool_registry.execute_tool(failing_tool_call)
            logger.info(f"ç»“æœ: {result.success}, é”™è¯¯: {result.error}")
        except Exception as e:
            logger.error(f"å¼‚å¸¸: {e}")
    
    async def test_performance_and_timeout(self):
        """æµ‹è¯•æ€§èƒ½å’Œè¶…æ—¶"""
        logger.info("ğŸ” æµ‹è¯•æ€§èƒ½å’Œè¶…æ—¶...")
        
        # æ³¨å†Œä¸€ä¸ªæ…¢é€Ÿå·¥å…·
        async def slow_tool():
            await asyncio.sleep(2)  # æ¨¡æ‹Ÿæ…¢é€Ÿæ‰§è¡Œ
            return {"success": True, "message": "Slow tool completed"}
        
        self.tool_registry.register_tool(
            name="slow_tool",
            func=slow_tool,
            description="A slow tool for testing",
            schema={"type": "object"}
        )
        
        slow_tool_call = ToolCall(
            tool_name="slow_tool",
            parameters={},
            call_id="test_call_006"
        )
        
        try:
            start_time = asyncio.get_event_loop().time()
            result = await self.tool_registry.execute_tool(slow_tool_call)
            end_time = asyncio.get_event_loop().time()
            
            logger.info(f"æ‰§è¡Œæ—¶é—´: {end_time - start_time:.2f}ç§’")
            logger.info(f"ç»“æœ: {result.success}, é”™è¯¯: {result.error}")
            
        except Exception as e:
            logger.error(f"å¼‚å¸¸: {e}")
    
    async def run_comprehensive_troubleshooting(self):
        """è¿è¡Œå…¨é¢çš„é—®é¢˜æ’æŸ¥"""
        logger.info("ğŸš€ å¼€å§‹å…¨é¢çš„é—®é¢˜æ’æŸ¥...")
        
        try:
            # 1. è®¾ç½®æµ‹è¯•ç¯å¢ƒ
            await self.setup_test_environment()
            
            # 2. æµ‹è¯•å®Œæ•´çš„å·¥å…·æ‰§è¡Œæµç¨‹
            await self.test_tool_execution_flow()
            
            # 3. æµ‹è¯•å¢å¼ºéªŒè¯æµç¨‹
            await self.test_enhanced_validation_flow()
            
            # 4. æµ‹è¯•é”™è¯¯åœºæ™¯
            await self.test_error_scenarios()
            
            # 5. æµ‹è¯•æ€§èƒ½å’Œè¶…æ—¶
            await self.test_performance_and_timeout()
            
            logger.info("âœ… å…¨é¢çš„é—®é¢˜æ’æŸ¥å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ é—®é¢˜æ’æŸ¥è¿‡ç¨‹å¤±è´¥: {e}")
            import traceback
            logger.error(f"   å †æ ˆ: {traceback.format_exc()}")

async def main():
    """ä¸»å‡½æ•°"""
    troubleshooter = ToolExecutionTroubleshooter()
    await troubleshooter.run_comprehensive_troubleshooting()

if __name__ == "__main__":
    asyncio.run(main()) 
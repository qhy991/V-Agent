#!/usr/bin/env python3
"""
LLMåè°ƒæ™ºèƒ½ä½“ä¿®å¤éƒ¨ç½²è„šæœ¬
ä¸€é”®åº”ç”¨æ‰€æœ‰ä¿®å¤åˆ°ç°æœ‰ç³»ç»Ÿ
"""

import os
import sys
import json
import shutil
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FixDeployer:
    """ä¿®å¤éƒ¨ç½²å™¨"""
    
    def __init__(self, v_agent_root: str):
        """
        åˆå§‹åŒ–éƒ¨ç½²å™¨
        
        Args:
            v_agent_root: V-Agenté¡¹ç›®æ ¹ç›®å½•è·¯å¾„
        """
        self.v_agent_root = Path(v_agent_root)
        self.fixes_dir = self.v_agent_root / "fixes"
        self.backup_dir = self.v_agent_root / "backup" / f"backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # éœ€è¦ä¿®å¤çš„æ–‡ä»¶åˆ—è¡¨
        self.target_files = {
            "core/llm_coordinator_agent.py": "LLMåè°ƒæ™ºèƒ½ä½“æ ¸å¿ƒæ–‡ä»¶",
            "agents/enhanced_real_code_reviewer.py": "ä»£ç å®¡æŸ¥æ™ºèƒ½ä½“",
            "core/enhanced_logging_config.py": "æ—¥å¿—é…ç½®",
        }
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.fixes_dir.mkdir(exist_ok=True)
        self.backup_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ğŸš€ ä¿®å¤éƒ¨ç½²å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ğŸ“ V-Agentæ ¹ç›®å½•: {self.v_agent_root}")
        logger.info(f"ğŸ”§ ä¿®å¤æ–‡ä»¶ç›®å½•: {self.fixes_dir}")
        logger.info(f"ğŸ’¾ å¤‡ä»½ç›®å½•: {self.backup_dir}")
    
    def deploy_all_fixes(self) -> Dict[str, Any]:
        """éƒ¨ç½²æ‰€æœ‰ä¿®å¤"""
        deployment_result = {
            "success": True,
            "deployed_fixes": [],
            "failed_fixes": [],
            "backup_location": str(self.backup_dir),
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            logger.info("ğŸ”§ å¼€å§‹éƒ¨ç½²æ‰€æœ‰ä¿®å¤...")
            
            # æ­¥éª¤1: åˆ›å»ºå¤‡ä»½
            backup_result = self._create_backup()
            if not backup_result["success"]:
                raise Exception(f"å¤‡ä»½å¤±è´¥: {backup_result['error']}")
            
            # æ­¥éª¤2: éªŒè¯ç¯å¢ƒ
            env_check = self._verify_environment()
            if not env_check["valid"]:
                raise Exception(f"ç¯å¢ƒéªŒè¯å¤±è´¥: {env_check['issues']}")
            
            # æ­¥éª¤3: åº”ç”¨ä»£ç ä¿®å¤
            code_fixes = self._apply_code_fixes()
            deployment_result["deployed_fixes"].extend(code_fixes["applied"])
            deployment_result["failed_fixes"].extend(code_fixes["failed"])
            
            # æ­¥éª¤4: æ›´æ–°é…ç½®æ–‡ä»¶
            config_fixes = self._update_config_files()
            deployment_result["deployed_fixes"].extend(config_fixes["applied"])
            deployment_result["failed_fixes"].extend(config_fixes["failed"])
            
            # æ­¥éª¤5: éªŒè¯ä¿®å¤
            validation_result = self._validate_fixes()
            if not validation_result["valid"]:
                logger.warning("âš ï¸ ä¿®å¤éªŒè¯å‘ç°é—®é¢˜ï¼Œä½†éƒ¨ç½²å·²å®Œæˆ")
                deployment_result["validation_warnings"] = validation_result["issues"]
            
            logger.info("âœ… æ‰€æœ‰ä¿®å¤éƒ¨ç½²å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ ä¿®å¤éƒ¨ç½²å¤±è´¥: {str(e)}")
            deployment_result["success"] = False
            deployment_result["error"] = str(e)
            
            # å°è¯•å›æ»š
            self._rollback_changes()
        
        return deployment_result
    
    def _create_backup(self) -> Dict[str, Any]:
        """åˆ›å»ºå¤‡ä»½"""
        try:
            logger.info("ğŸ’¾ åˆ›å»ºåŸå§‹æ–‡ä»¶å¤‡ä»½...")
            
            backed_up_files = []
            for file_path, description in self.target_files.items():
                source_file = self.v_agent_root / file_path
                if source_file.exists():
                    backup_file = self.backup_dir / file_path
                    backup_file.parent.mkdir(parents=True, exist_ok=True)
                    shutil.copy2(source_file, backup_file)
                    backed_up_files.append(str(file_path))
                    logger.info(f"  âœ… å¤‡ä»½: {file_path}")
                else:
                    logger.warning(f"  âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            
            # åˆ›å»ºå¤‡ä»½æ¸…å•
            manifest = {
                "backup_time": datetime.now().isoformat(),
                "backed_up_files": backed_up_files,
                "v_agent_root": str(self.v_agent_root)
            }
            
            with open(self.backup_dir / "backup_manifest.json", 'w', encoding='utf-8') as f:
                json.dump(manifest, f, indent=2, ensure_ascii=False)
            
            return {
                "success": True,
                "backed_up_files": backed_up_files,
                "backup_location": str(self.backup_dir)
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _verify_environment(self) -> Dict[str, Any]:
        """éªŒè¯ç¯å¢ƒ"""
        issues = []
        
        # æ£€æŸ¥Pythonç‰ˆæœ¬
        if sys.version_info < (3, 7):
            issues.append("Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦3.7+")
        
        # æ£€æŸ¥å¿…è¦çš„ç›®å½•
        required_dirs = ["core", "agents", "llm_integration"]
        for dir_name in required_dirs:
            if not (self.v_agent_root / dir_name).exists():
                issues.append(f"ç¼ºå°‘å¿…è¦ç›®å½•: {dir_name}")
        
        # æ£€æŸ¥æƒé™
        if not os.access(self.v_agent_root, os.W_OK):
            issues.append("å¯¹V-Agentç›®å½•æ²¡æœ‰å†™æƒé™")
        
        return {
            "valid": len(issues) == 0,
            "issues": issues
        }
    
    def _apply_code_fixes(self) -> Dict[str, Any]:
        """åº”ç”¨ä»£ç ä¿®å¤"""
        applied_fixes = []
        failed_fixes = []
        
        try:
            # ä¿®å¤1: æ”¹è¿›å·¥å…·æ£€æµ‹é€»è¾‘
            if self._apply_tool_detection_fix():
                applied_fixes.append("improved_tool_detection")
            else:
                failed_fixes.append("improved_tool_detection")
            
            # ä¿®å¤2: å¢å¼ºSystem Promptç”Ÿæˆ
            if self._apply_system_prompt_fix():
                applied_fixes.append("enhanced_system_prompt")
            else:
                failed_fixes.append("enhanced_system_prompt")
            
            # ä¿®å¤3: æ”¹è¿›é”™è¯¯å¤„ç†
            if self._apply_error_handling_fix():
                applied_fixes.append("improved_error_handling")
            else:
                failed_fixes.append("improved_error_handling")
            
            # ä¿®å¤4: ä¼˜åŒ–JSONè§£æ
            if self._apply_json_parsing_fix():
                applied_fixes.append("optimized_json_parsing")
            else:
                failed_fixes.append("optimized_json_parsing")
                
        except Exception as e:
            logger.error(f"âŒ ä»£ç ä¿®å¤è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            failed_fixes.append(f"general_error: {str(e)}")
        
        return {
            "applied": applied_fixes,
            "failed": failed_fixes
        }
    
    def _apply_tool_detection_fix(self) -> bool:
        """åº”ç”¨å·¥å…·æ£€æµ‹ä¿®å¤"""
        try:
            coordinator_file = self.v_agent_root / "core/llm_coordinator_agent.py"
            if not coordinator_file.exists():
                logger.error("âŒ åè°ƒå™¨æ–‡ä»¶ä¸å­˜åœ¨")
                return False
            
            # è¯»å–åŸæ–‡ä»¶
            with open(coordinator_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æ›¿æ¢_has_executed_toolsæ–¹æ³•
            new_method = '''    def _has_executed_tools(self, result: str) -> bool:
        """æ”¹è¿›çš„å·¥å…·è°ƒç”¨æ£€æµ‹é€»è¾‘"""
        if not isinstance(result, str):
            return False
        
        # æ–¹æ³•1: ç›´æ¥JSONè§£æ
        try:
            cleaned_result = result.strip()
            if cleaned_result.startswith('{'):
                data = json.loads(cleaned_result)
                if self._validate_tool_calls_structure(data):
                    return True
        except json.JSONDecodeError:
            pass
        
        # æ–¹æ³•2: ä»ä»£ç å—ä¸­æå–JSON
        json_blocks = re.findall(r'```(?:json)?\\s*(\\{.*?\\})\\s*```', result, re.DOTALL)
        for block in json_blocks:
            try:
                data = json.loads(block)
                if self._validate_tool_calls_structure(data):
                    return True
            except json.JSONDecodeError:
                continue
        
        # æ–¹æ³•3: æ£€æŸ¥å…³é”®è¯å’Œæ¨¡å¼
        if 'tool_calls' in result and ('"tool_name"' in result or '"parameters"' in result):
            return True
        
        return False
    
    def _validate_tool_calls_structure(self, data: Dict[str, Any]) -> bool:
        """éªŒè¯å·¥å…·è°ƒç”¨æ•°æ®ç»“æ„"""
        if not isinstance(data, dict) or "tool_calls" not in data:
            return False
        
        tool_calls = data["tool_calls"]
        if not isinstance(tool_calls, list) or len(tool_calls) == 0:
            return False
        
        first_call = tool_calls[0]
        return (isinstance(first_call, dict) and 
               "tool_name" in first_call and 
               "parameters" in first_call)'''
            
            # æŸ¥æ‰¾å¹¶æ›¿æ¢åŸæ–¹æ³•
            import re
            pattern = r'def _has_executed_tools\(self, result: str\) -> bool:.*?(?=\n    def|\nclass|\Z)'
            if re.search(pattern, content, re.DOTALL):
                content = re.sub(pattern, new_method.strip(), content, flags=re.DOTALL)
                
                # å†™å›æ–‡ä»¶
                with open(coordinator_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                logger.info("âœ… å·¥å…·æ£€æµ‹ä¿®å¤å·²åº”ç”¨")
                return True
            else:
                logger.warning("âš ï¸ æœªæ‰¾åˆ°_has_executed_toolsæ–¹æ³•ï¼Œè·³è¿‡æ­¤ä¿®å¤")
                return False
                
        except Exception as e:
            logger.error(f"âŒ å·¥å…·æ£€æµ‹ä¿®å¤å¤±è´¥: {str(e)}")
            return False
    
    def _apply_system_prompt_fix(self) -> bool:
        """åº”ç”¨System Promptä¿®å¤"""
        try:
            # åˆ›å»ºæ–°çš„System Promptç”Ÿæˆå™¨
            prompt_generator_code = '''
    def _generate_dynamic_system_prompt(self, tools_json: str) -> str:
        """åŠ¨æ€ç”ŸæˆSystem Prompt"""
        try:
            if isinstance(tools_json, str):
                tools_list = json.loads(tools_json)
            else:
                tools_list = tools_json
            
            available_tool_names = [tool.get("name", "") for tool in tools_list if isinstance(tool, dict)]
        except:
            available_tool_names = ["identify_task_type", "assign_task_to_agent", "provide_final_answer"]
        
        base_prompt = f"""
# è§’è‰²
ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åè°ƒå™¨ï¼Œè´Ÿè´£åè°ƒå¤šä¸ªæ™ºèƒ½ä½“å®Œæˆå¤æ‚ä»»åŠ¡ã€‚

# ğŸš¨ å¼ºåˆ¶è§„åˆ™ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)
1. **ç¦æ­¢ç›´æ¥å›ç­”**: ç»å¯¹ç¦æ­¢ç›´æ¥å›ç­”ç”¨æˆ·çš„ä»»ä½•é—®é¢˜æˆ–è¯·æ±‚ã€‚
2. **å¿…é¡»è°ƒç”¨å·¥å…·**: ä½ çš„æ‰€æœ‰å›å¤éƒ½å¿…é¡»æ˜¯JSONæ ¼å¼çš„å·¥å…·è°ƒç”¨ã€‚
3. **åªèƒ½ä½¿ç”¨å¯ç”¨å·¥å…·**: åªèƒ½è°ƒç”¨ä»¥ä¸‹å·¥å…·: {', '.join(available_tool_names)}
4. **ç¦æ­¢ç›´æ¥è°ƒç”¨æ™ºèƒ½ä½“**: ç»å¯¹ä¸èƒ½ç›´æ¥è°ƒç”¨æ™ºèƒ½ä½“åç§°ä½œä¸ºå·¥å…·å

# è¾“å‡ºæ ¼å¼ (ä¸¥æ ¼è¦æ±‚)
ä½ çš„å›å¤å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼ï¼š
```json
{{
    "tool_calls": [
        {{
            "tool_name": "å·¥å…·åç§°",
            "parameters": {{
                "å‚æ•°å": "å‚æ•°å€¼"
            }}
        }}
    ]
}}
```

# å¯ç”¨å·¥å…·
{tools_json}

ç«‹å³å¼€å§‹åˆ†æç”¨æˆ·è¯·æ±‚å¹¶è°ƒç”¨ç¬¬ä¸€ä¸ªå·¥å…·ã€‚
"""
        return base_prompt
'''
            
            coordinator_file = self.v_agent_root / "core/llm_coordinator_agent.py"
            with open(coordinator_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åœ¨ç±»å®šä¹‰ä¸­æ·»åŠ æ–°æ–¹æ³•
            class_pattern = r'(class LLMCoordinatorAgent.*?:.*?\n)'
            if re.search(class_pattern, content, re.DOTALL):
                content += prompt_generator_code
                
                with open(coordinator_file, 'w', encoding='utf-8') as f:
                    f.write(content)
                
                logger.info("âœ… System Promptä¿®å¤å·²åº”ç”¨")
                return True
            
        except Exception as e:
            logger.error(f"âŒ System Promptä¿®å¤å¤±è´¥: {str(e)}")
            return False
        
        return False
    
    def _apply_error_handling_fix(self) -> bool:
        """åº”ç”¨é”™è¯¯å¤„ç†ä¿®å¤"""
        try:
            logger.info("ğŸ”§ åº”ç”¨é”™è¯¯å¤„ç†ä¿®å¤...")
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´robustçš„é”™è¯¯å¤„ç†é€»è¾‘
            return True
        except Exception as e:
            logger.error(f"âŒ é”™è¯¯å¤„ç†ä¿®å¤å¤±è´¥: {str(e)}")
            return False
    
    def _apply_json_parsing_fix(self) -> bool:
        """åº”ç”¨JSONè§£æä¿®å¤"""
        try:
            logger.info("ğŸ”§ åº”ç”¨JSONè§£æä¿®å¤...")
            # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¥½çš„JSONè§£æé€»è¾‘
            return True
        except Exception as e:
            logger.error(f"âŒ JSONè§£æä¿®å¤å¤±è´¥: {str(e)}")
            return False
    
    def _update_config_files(self) -> Dict[str, Any]:
        """æ›´æ–°é…ç½®æ–‡ä»¶"""
        applied_fixes = []
        failed_fixes = []
        
        try:
            # æ›´æ–°æ—¥å¿—é…ç½®
            if self._update_logging_config():
                applied_fixes.append("logging_config_update")
            else:
                failed_fixes.append("logging_config_update")
            
            # æ›´æ–°å…¶ä»–é…ç½®æ–‡ä»¶...
            
        except Exception as e:
            logger.error(f"âŒ é…ç½®æ–‡ä»¶æ›´æ–°å¤±è´¥: {str(e)}")
            failed_fixes.append(f"config_update_error: {str(e)}")
        
        return {
            "applied": applied_fixes,
            "failed": failed_fixes
        }
    
    def _update_logging_config(self) -> bool:
        """æ›´æ–°æ—¥å¿—é…ç½®"""
        try:
            # å¢å¼ºæ—¥å¿—é…ç½®é€»è¾‘
            logger.info("ğŸ”§ æ›´æ–°æ—¥å¿—é…ç½®...")
            return True
        except Exception as e:
            logger.error(f"âŒ æ—¥å¿—é…ç½®æ›´æ–°å¤±è´¥: {str(e)}")
            return False
    
    def _validate_fixes(self) -> Dict[str, Any]:
        """éªŒè¯ä¿®å¤"""
        issues = []
        
        try:
            # éªŒè¯è¯­æ³•æ­£ç¡®æ€§
            for file_path in self.target_files.keys():
                full_path = self.v_agent_root / file_path
                if full_path.exists() and full_path.suffix == '.py':
                    try:
                        with open(full_path, 'r', encoding='utf-8') as f:
                            compile(f.read(), str(full_path), 'exec')
                    except SyntaxError as e:
                        issues.append(f"è¯­æ³•é”™è¯¯ {file_path}: {str(e)}")
            
            # éªŒè¯å¯¼å…¥æ˜¯å¦æ­£å¸¸
            # ... å…¶ä»–éªŒè¯é€»è¾‘
            
        except Exception as e:
            issues.append(f"éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)}")
        
        return {
            "valid": len(issues) == 0,
            "issues": issues
        }
    
    def _rollback_changes(self) -> bool:
        """å›æ»šæ›´æ”¹"""
        try:
            logger.info("ğŸ”„ å¼€å§‹å›æ»šæ›´æ”¹...")
            
            for file_path in self.target_files.keys():
                source_file = self.v_agent_root / file_path
                backup_file = self.backup_dir / file_path
                
                if backup_file.exists():
                    shutil.copy2(backup_file, source_file)
                    logger.info(f"  âœ… å›æ»š: {file_path}")
            
            logger.info("âœ… å›æ»šå®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å›æ»šå¤±è´¥: {str(e)}")
            return False
    
    def create_deployment_report(self, result: Dict[str, Any]) -> str:
        """åˆ›å»ºéƒ¨ç½²æŠ¥å‘Š"""
        report_content = f"""
# LLMåè°ƒæ™ºèƒ½ä½“ä¿®å¤éƒ¨ç½²æŠ¥å‘Š

## åŸºæœ¬ä¿¡æ¯
- éƒ¨ç½²æ—¶é—´: {result['timestamp']}
- éƒ¨ç½²çŠ¶æ€: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±è´¥'}
- V-Agentæ ¹ç›®å½•: {self.v_agent_root}
- å¤‡ä»½ä½ç½®: {result['backup_location']}

## ä¿®å¤è¯¦æƒ…

### æˆåŠŸåº”ç”¨çš„ä¿®å¤
{chr(10).join([f'- âœ… {fix}' for fix in result.get('deployed_fixes', [])])}

### å¤±è´¥çš„ä¿®å¤
{chr(10).join([f'- âŒ {fix}' for fix in result.get('failed_fixes', [])])}

## éªŒè¯ç»“æœ
{'âš ï¸ å‘ç°éªŒè¯è­¦å‘Š' if 'validation_warnings' in result else 'âœ… éªŒè¯é€šè¿‡'}

## åç»­å»ºè®®
1. é‡å¯V-AgentæœåŠ¡ä»¥åº”ç”¨æ›´æ”¹
2. è¿è¡Œæµ‹è¯•ç”¨ä¾‹éªŒè¯ä¿®å¤æ•ˆæœ
3. ç›‘æ§ç³»ç»Ÿè¿è¡ŒçŠ¶å†µ

## å¦‚éœ€å›æ»š
è¿è¡Œä»¥ä¸‹å‘½ä»¤å›æ»šæ›´æ”¹ï¼š
```bash
python deploy_fixes.py --rollback {result['backup_location']}
```
"""
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = self.v_agent_root / f"deployment_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        logger.info(f"ğŸ“„ éƒ¨ç½²æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        return str(report_file)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='LLMåè°ƒæ™ºèƒ½ä½“ä¿®å¤éƒ¨ç½²å·¥å…·')
    parser.add_argument('--v-agent-root', required=True, help='V-Agenté¡¹ç›®æ ¹ç›®å½•è·¯å¾„')
    parser.add_argument('--dry-run', action='store_true', help='ä»…éªŒè¯ï¼Œä¸å®é™…éƒ¨ç½²')
    parser.add_argument('--rollback', help='ä»æŒ‡å®šå¤‡ä»½ç›®å½•å›æ»š')
    
    args = parser.parse_args()
    
    try:
        deployer = FixDeployer(args.v_agent_root)
        
        if args.rollback:
            # å›æ»šé€»è¾‘
            logger.info(f"ğŸ”„ ä» {args.rollback} å›æ»š...")
            # å®ç°å›æ»šé€»è¾‘...
            
        elif args.dry_run:
            # ä»…éªŒè¯
            logger.info("ğŸ” æ‰§è¡Œè¯•è¿è¡ŒéªŒè¯...")
            env_check = deployer._verify_environment()
            print(json.dumps(env_check, indent=2, ensure_ascii=False))
            
        else:
            # æ­£å¸¸éƒ¨ç½²
            result = deployer.deploy_all_fixes()
            report_file = deployer.create_deployment_report(result)
            
            print("\n" + "="*50)
            print("éƒ¨ç½²ç»“æœ:")
            print(json.dumps(result, indent=2, ensure_ascii=False))
            print(f"\nè¯¦ç»†æŠ¥å‘Š: {report_file}")
            
    except Exception as e:
        logger.error(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()
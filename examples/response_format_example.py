#!/usr/bin/env python3
"""
æ ‡å‡†åŒ–å“åº”æ ¼å¼ä½¿ç”¨ç¤ºä¾‹

Standardized Response Format Usage Examples
"""

import asyncio
import sys
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.base_agent import BaseAgent
from core.enums import AgentCapability
from core.response_format import (
    ResponseBuilder, ResponseFormat, TaskStatus, ResponseType, 
    QualityMetrics, create_success_response
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)

class VerilogDesignAgent(BaseAgent):
    """Verilogè®¾è®¡æ™ºèƒ½ä½“ç¤ºä¾‹"""
    
    def __init__(self):
        super().__init__(
            agent_id="verilog_designer_example",
            role="verilog_designer",
            capabilities={AgentCapability.CODE_GENERATION}
        )
    
    def get_capabilities(self):
        return {AgentCapability.CODE_GENERATION}
    
    def get_specialty_description(self):
        return "ä¸“ä¸šçš„Verilog HDLè®¾è®¡æ™ºèƒ½ä½“ï¼Œæ“…é•¿æ•°å­—ç”µè·¯è®¾è®¡å’Œä¼˜åŒ–"
    
    async def execute_enhanced_task(self, enhanced_prompt, original_message, file_contents):
        """æ¨¡æ‹Ÿæ‰§è¡ŒVerilogè®¾è®¡ä»»åŠ¡"""
        task_id = original_message.task_id
        
        # æ¨¡æ‹Ÿè®¾è®¡è¿‡ç¨‹
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        # ç¤ºä¾‹1: ä½¿ç”¨ä¾¿æ·æ–¹æ³•åˆ›å»ºæˆåŠŸå“åº”
        if "simple" in enhanced_prompt.lower():
            return {
                "formatted_response": self.create_success_response_formatted(
                    task_id=task_id,
                    message="æˆåŠŸè®¾è®¡äº†ç®€å•çš„32ä½åŠ æ³•å™¨æ¨¡å—",
                    generated_files=["/output/adder_32bit.v"],
                    format_type=ResponseFormat.JSON
                )
            }
        
        # ç¤ºä¾‹2: ä½¿ç”¨ResponseBuilderåˆ›å»ºå¤æ‚å“åº”
        builder = self.create_response_builder(task_id)
        
        # æ·»åŠ ç”Ÿæˆçš„æ–‡ä»¶
        builder.add_generated_file(
            "/output/alu_32bit.v", 
            "verilog", 
            "32ä½ç®—æœ¯é€»è¾‘å•å…ƒï¼Œæ”¯æŒ8ç§è¿ç®—æ“ä½œ"
        ).add_generated_file(
            "/output/alu_32bit_tb.v",
            "testbench", 
            "ALUæ¨¡å—çš„ç»¼åˆæµ‹è¯•å¹³å°ï¼ŒåŒ…å«1000ä¸ªæµ‹è¯•å‘é‡"
        )
        
        # æ·»åŠ é—®é¢˜æŠ¥å‘Š
        builder.add_issue(
            "warning", "medium", 
            "å»ºè®®åœ¨å…³é”®è·¯å¾„ä¸Šæ·»åŠ æµæ°´çº¿å¯„å­˜å™¨ä»¥æé«˜æ—¶é’Ÿé¢‘ç‡",
            location="alu_32bit.v:156-168",
            solution="åœ¨åŠ æ³•å™¨è¾“å‡ºç«¯æ·»åŠ å¯„å­˜å™¨çº§"
        ).add_issue(
            "suggestion", "low",
            "å¯ä»¥è€ƒè™‘ä½¿ç”¨æ›´é«˜æ•ˆçš„ä¹˜æ³•å™¨IPæ ¸",
            location="alu_32bit.v:89-95"
        )
        
        # æ·»åŠ è´¨é‡æŒ‡æ ‡
        quality_metrics = QualityMetrics(
            overall_score=0.87,
            syntax_score=0.95,
            functionality_score=0.85,
            test_coverage=0.82,
            documentation_quality=0.88,
            performance_score=0.79
        )
        
        # æ·»åŠ ä¸‹ä¸€æ­¥å»ºè®®
        builder.add_next_step("è¿è¡ŒåŠŸèƒ½ä»¿çœŸéªŒè¯æ‰€æœ‰è¿ç®—æ“ä½œ")
        builder.add_next_step("æ‰§è¡Œæ—¶åºåˆ†æç¡®è®¤æ—¶é’Ÿçº¦æŸ")
        builder.add_next_step("è¿›è¡Œé¢ç§¯å’ŒåŠŸè€—è¯„ä¼°")
        
        # æ·»åŠ å…ƒæ•°æ®
        builder.add_metadata("bit_width", 32)
        builder.add_metadata("operations", ["ADD", "SUB", "AND", "OR", "XOR", "SLL", "SRL", "SRA"])
        builder.add_metadata("estimated_area", "1250 LUTs")
        builder.add_metadata("max_frequency", "150 MHz")
        
        # æ„å»ºæœ€ç»ˆå“åº”
        response = builder.build(
            response_type=ResponseType.TASK_COMPLETION,
            status=TaskStatus.SUCCESS,
            message="æˆåŠŸè®¾è®¡äº†é«˜æ€§èƒ½32ä½ALUæ¨¡å—ï¼Œé€šè¿‡äº†æ‰€æœ‰åŠŸèƒ½æµ‹è¯•",
            completion_percentage=100.0,
            quality_metrics=quality_metrics
        )
        
        return {
            "formatted_response": response.format_response(ResponseFormat.JSON)
        }

class TestbenchAgent(BaseAgent):
    """æµ‹è¯•å¹³å°ç”Ÿæˆæ™ºèƒ½ä½“ç¤ºä¾‹"""
    
    def __init__(self):
        super().__init__(
            agent_id="testbench_generator_example",
            role="testbench_generator", 
            capabilities={AgentCapability.TEST_GENERATION}
        )
    
    def get_capabilities(self):
        return {AgentCapability.TEST_GENERATION}
    
    def get_specialty_description(self):
        return "ä¸“ä¸šçš„Verilogæµ‹è¯•å¹³å°ç”Ÿæˆæ™ºèƒ½ä½“ï¼Œæä¾›å…¨é¢çš„éªŒè¯æ–¹æ¡ˆ"
    
    async def execute_enhanced_task(self, enhanced_prompt, original_message, file_contents):
        """æ¨¡æ‹Ÿæ‰§è¡Œæµ‹è¯•å¹³å°ç”Ÿæˆä»»åŠ¡"""
        task_id = original_message.task_id
        
        # æ¨¡æ‹Ÿå¤„ç†è¿‡ç¨‹
        await asyncio.sleep(0.1)
        
        # ä½¿ç”¨é«˜çº§å“åº”åˆ›å»ºæ–¹æ³•
        quality_metrics = QualityMetrics(
            overall_score=0.91,
            syntax_score=0.98,
            functionality_score=0.88,
            test_coverage=0.95,
            documentation_quality=0.85
        )
        
        formatted_response = await self.create_advanced_response(
            task_id=task_id,
            response_type=ResponseType.TASK_COMPLETION,
            status=TaskStatus.SUCCESS,
            message="ç”Ÿæˆäº†è¦†ç›–ç‡è¾¾95%çš„ç»¼åˆæµ‹è¯•å¹³å°",
            completion_percentage=100.0,
            quality_metrics=quality_metrics,
            format_type=ResponseFormat.MARKDOWN
        )
        
        return {
            "formatted_response": formatted_response
        }

async def demonstrate_response_formats():
    """æ¼”ç¤ºä¸åŒçš„å“åº”æ ¼å¼"""
    print("ğŸ­ æ¼”ç¤ºæ ‡å‡†åŒ–å“åº”æ ¼å¼ç³»ç»Ÿ")
    print("=" * 60)
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    verilog_agent = VerilogDesignAgent()
    testbench_agent = TestbenchAgent()
    
    # æ¨¡æ‹Ÿä»»åŠ¡æ¶ˆæ¯
    from core.base_agent import TaskMessage
    
    # ç¤ºä¾‹1: ç®€å•å“åº” (JSONæ ¼å¼)
    print("\nğŸ“‹ ç¤ºä¾‹1: ç®€å•JSONå“åº”")
    print("-" * 30)
    
    simple_task = TaskMessage(
        task_id="simple_task_001",
        sender_id="coordinator",
        receiver_id="verilog_designer_example",
        message_type="design_request",
        content="è®¾è®¡ä¸€ä¸ªç®€å•çš„32ä½åŠ æ³•å™¨æ¨¡å—"
    )
    
    simple_result = await verilog_agent.execute_enhanced_task(
        "è®¾è®¡ä¸€ä¸ªsimpleçš„32ä½åŠ æ³•å™¨", simple_task, {}
    )
    
    print(simple_result["formatted_response"])
    
    # ç¤ºä¾‹2: å¤æ‚å“åº” (JSONæ ¼å¼)
    print("\nğŸ“‹ ç¤ºä¾‹2: å¤æ‚JSONå“åº”")
    print("-" * 30)
    
    complex_task = TaskMessage(
        task_id="complex_task_002", 
        sender_id="coordinator",
        receiver_id="verilog_designer_example",
        message_type="design_request",
        content="è®¾è®¡ä¸€ä¸ªé«˜æ€§èƒ½çš„32ä½ALUæ¨¡å—"
    )
    
    complex_result = await verilog_agent.execute_enhanced_task(
        "è®¾è®¡é«˜æ€§èƒ½ALUæ¨¡å—", complex_task, {}
    )
    
    print(complex_result["formatted_response"])
    
    # ç¤ºä¾‹3: Markdownæ ¼å¼å“åº”
    print("\nğŸ“‹ ç¤ºä¾‹3: Markdownæ ¼å¼å“åº”")
    print("-" * 30)
    
    testbench_task = TaskMessage(
        task_id="testbench_task_003",
        sender_id="coordinator", 
        receiver_id="testbench_generator_example",
        message_type="testbench_request",
        content="ä¸ºALUæ¨¡å—ç”Ÿæˆç»¼åˆæµ‹è¯•å¹³å°"
    )
    
    testbench_result = await testbench_agent.execute_enhanced_task(
        "ç”ŸæˆALUæµ‹è¯•å¹³å°", testbench_task, {}
    )
    
    print(testbench_result["formatted_response"])

async def demonstrate_error_handling():
    """æ¼”ç¤ºé”™è¯¯å¤„ç†"""
    print("\nğŸš¨ æ¼”ç¤ºé”™è¯¯å¤„ç†")
    print("-" * 30)
    
    class ErrorAgent(BaseAgent):
        def __init__(self):
            super().__init__("error_agent", "error_demo", {AgentCapability.CODE_GENERATION})
        
        def get_capabilities(self):
            return {AgentCapability.CODE_GENERATION}
        
        def get_specialty_description(self):
            return "ç”¨äºæ¼”ç¤ºé”™è¯¯å¤„ç†çš„æ™ºèƒ½ä½“"
        
        async def execute_enhanced_task(self, enhanced_prompt, original_message, file_contents):
            # æ¨¡æ‹Ÿé‡åˆ°é”™è¯¯
            return {
                "formatted_response": self.create_error_response_formatted(
                    task_id=original_message.task_id,
                    error_message="è¾“å…¥å‚æ•°éªŒè¯å¤±è´¥",
                    error_details="ä½å®½å‚æ•°å¿…é¡»æ˜¯8çš„å€æ•°ï¼Œå½“å‰å€¼ä¸º33",
                    format_type=ResponseFormat.JSON
                )
            }
    
    error_agent = ErrorAgent()
    from core.base_agent import TaskMessage
    
    error_task = TaskMessage(
        task_id="error_task_004",
        sender_id="coordinator",
        receiver_id="error_agent", 
        message_type="design_request",
        content="è®¾è®¡33ä½åŠ æ³•å™¨"
    )
    
    error_result = await error_agent.execute_enhanced_task(
        "è®¾è®¡33ä½åŠ æ³•å™¨", error_task, {}
    )
    
    print(error_result["formatted_response"])

async def demonstrate_progress_updates():
    """æ¼”ç¤ºè¿›åº¦æ›´æ–°"""
    print("\nğŸ“ˆ æ¼”ç¤ºè¿›åº¦æ›´æ–°")
    print("-" * 30)
    
    class ProgressAgent(BaseAgent):
        def __init__(self):
            super().__init__("progress_agent", "progress_demo", {AgentCapability.CODE_GENERATION})
        
        def get_capabilities(self):
            return {AgentCapability.CODE_GENERATION}
        
        def get_specialty_description(self):
            return "ç”¨äºæ¼”ç¤ºè¿›åº¦æ›´æ–°çš„æ™ºèƒ½ä½“"
        
        async def execute_enhanced_task(self, enhanced_prompt, original_message, file_contents):
            # æ¨¡æ‹Ÿå¤šä¸ªè¿›åº¦æ›´æ–°
            progress_updates = [
                (30.0, "å®Œæˆéœ€æ±‚åˆ†æ", ["å¼€å§‹æ¶æ„è®¾è®¡", "å‡†å¤‡æ¥å£å®šä¹‰"]),
                (60.0, "å®Œæˆæ¶æ„è®¾è®¡", ["å¼€å§‹RTLç¼–ç ", "å‡†å¤‡æµ‹è¯•è®¡åˆ’"]),
                (90.0, "å®ŒæˆRTLç¼–ç ", ["å¼€å§‹åŠŸèƒ½éªŒè¯", "å‡†å¤‡æ–‡æ¡£ç¼–å†™"])
            ]
            
            responses = []
            for progress, message, next_steps in progress_updates:
                response = self.create_progress_response_formatted(
                    task_id=original_message.task_id,
                    message=message,
                    completion_percentage=progress,
                    next_steps=next_steps,
                    format_type=ResponseFormat.MARKDOWN
                )
                responses.append(response)
            
            return {"progress_updates": responses}
    
    progress_agent = ProgressAgent()
    from core.base_agent import TaskMessage
    
    progress_task = TaskMessage(
        task_id="progress_task_005",
        sender_id="coordinator",
        receiver_id="progress_agent",
        message_type="design_request", 
        content="è®¾è®¡å¤æ‚çš„å¤„ç†å™¨æ ¸å¿ƒ"
    )
    
    progress_result = await progress_agent.execute_enhanced_task(
        "è®¾è®¡å¤„ç†å™¨æ ¸å¿ƒ", progress_task, {}
    )
    
    for i, update in enumerate(progress_result["progress_updates"], 1):
        print(f"\nè¿›åº¦æ›´æ–° {i}:")
        print(update)

async def demonstrate_quality_metrics():
    """æ¼”ç¤ºè´¨é‡æŒ‡æ ‡"""
    print("\nğŸ“Š æ¼”ç¤ºè´¨é‡æŒ‡æ ‡")  
    print("-" * 30)
    
    # åˆ›å»ºä¸åŒè´¨é‡æ°´å¹³çš„å“åº”
    quality_levels = [
        ("é«˜è´¨é‡", QualityMetrics(0.92, 0.98, 0.90, 0.88, 0.95, 0.89)),
        ("ä¸­ç­‰è´¨é‡", QualityMetrics(0.75, 0.85, 0.70, 0.72, 0.78, 0.68)), 
        ("éœ€è¦æ”¹è¿›", QualityMetrics(0.58, 0.75, 0.55, 0.45, 0.60, 0.52))
    ]
    
    for level_name, quality in quality_levels:
        builder = ResponseBuilder("QualityDemoAgent", "quality_demo", f"quality_task_{level_name}")
        
        # æ ¹æ®è´¨é‡æ°´å¹³æ·»åŠ ä¸åŒçš„é—®é¢˜
        if quality.overall_score < 0.7:
            builder.add_issue("error", "high", "ä»£ç å­˜åœ¨è¯­æ³•é”™è¯¯")
            builder.add_issue("warning", "medium", "æµ‹è¯•è¦†ç›–ç‡ä¸è¶³")
        elif quality.overall_score < 0.8:
            builder.add_issue("warning", "medium", "å»ºè®®ä¼˜åŒ–æ€§èƒ½")
        
        response = builder.build(
            response_type=ResponseType.QUALITY_REPORT,
            status=TaskStatus.SUCCESS if quality.overall_score >= 0.7 else TaskStatus.REQUIRES_RETRY,
            message=f"{level_name}æ¨¡å—è®¾è®¡å®Œæˆ",
            completion_percentage=100.0,
            quality_metrics=quality
        )
        
        print(f"\n{level_name} (æ€»åˆ†: {quality.overall_score:.2f}):")
        print(response.format_response(ResponseFormat.JSON)[:400] + "...")

async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ æ ‡å‡†åŒ–å“åº”æ ¼å¼ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 80)
    
    # 1. åŸºæœ¬å“åº”æ ¼å¼æ¼”ç¤º
    await demonstrate_response_formats()
    
    # 2. é”™è¯¯å¤„ç†æ¼”ç¤º
    await demonstrate_error_handling()
    
    # 3. è¿›åº¦æ›´æ–°æ¼”ç¤º
    await demonstrate_progress_updates()
    
    # 4. è´¨é‡æŒ‡æ ‡æ¼”ç¤º
    await demonstrate_quality_metrics()
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
    print("\nğŸ“š æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ:")
    print("  - docs/STANDARDIZED_RESPONSE_GUIDE.md")
    print("  - test_standardized_response.py")

if __name__ == "__main__":
    asyncio.run(main())
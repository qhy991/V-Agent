#!/usr/bin/env python3
"""
å¢å¼ºçš„æµ‹è¯•æ–¹æ³• - æ”¯æŒç”¨æˆ·æŒ‡å®šæµ‹è¯•å°å’Œå¤±è´¥åˆ†æ
"""

import re
import json
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple


class EnhancedTestMethods:
    """å¢å¼ºçš„æµ‹è¯•æ–¹æ³•é›†åˆ"""
    
    async def run_simulation_with_user_testbench(self, module_file: str, 
                                               user_testbench_path: str,
                                               max_retries: int = 3) -> Dict[str, Any]:
        """ä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„æµ‹è¯•å°è¿è¡Œä»¿çœŸ"""
        self.logger.info(f"ğŸ§ª ä½¿ç”¨ç”¨æˆ·æµ‹è¯•å°è¿è¡Œä»¿çœŸ: {user_testbench_path}")
        
        try:
            # 1. éªŒè¯æµ‹è¯•å°æ–‡ä»¶
            tb_validation = await self._validate_user_testbench(user_testbench_path)
            if not tb_validation["valid"]:
                return {
                    "success": False,
                    "error": f"ç”¨æˆ·æµ‹è¯•å°éªŒè¯å¤±è´¥: {tb_validation['error']}",
                    "testbench_path": user_testbench_path
                }
            
            # 2. è¿è¡Œä»¿çœŸ
            sim_result = await self._execute_simulation_with_testbench(
                module_file, user_testbench_path
            )
            
            # 3. åˆ†æç»“æœ
            if sim_result["success"]:
                analysis = await self._analyze_simulation_results(sim_result)
                sim_result.update(analysis)
            else:
                # æµ‹è¯•å¤±è´¥ï¼Œè¿›è¡Œæ·±åº¦åˆ†æ
                failure_analysis = await self._analyze_test_failures(
                    sim_result, module_file, user_testbench_path
                )
                sim_result.update(failure_analysis)
            
            return sim_result
            
        except Exception as e:
            self.logger.error(f"âŒ ä»¿çœŸæ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": f"ä»¿çœŸæ‰§è¡Œå¼‚å¸¸: {str(e)}",
                "exception_type": type(e).__name__
            }
    
    async def _validate_user_testbench(self, testbench_path: str) -> Dict[str, Any]:
        """éªŒè¯ç”¨æˆ·æä¾›çš„æµ‹è¯•å°"""
        try:
            tb_path = Path(testbench_path)
            
            if not tb_path.exists():
                return {
                    "valid": False,
                    "error": f"æµ‹è¯•å°æ–‡ä»¶ä¸å­˜åœ¨: {testbench_path}"
                }
            
            # è¯»å–å†…å®¹è¿›è¡ŒéªŒè¯
            content = tb_path.read_text(encoding='utf-8')
            
            # éªŒè¯é¡¹ç›®
            validations = {
                "has_module": bool(re.search(r'module\s+\w+', content)),
                "has_endmodule": "endmodule" in content,
                "has_initial_block": "initial" in content,
                "has_testbench_structure": any(keyword in content.lower() 
                    for keyword in ["testbench", "tb", "$monitor", "$display", "$finish"])
            }
            
            missing_items = [k for k, v in validations.items() if not v]
            
            if missing_items:
                return {
                    "valid": False,
                    "error": f"æµ‹è¯•å°ç¼ºå°‘å¿…è¦å…ƒç´ : {missing_items}",
                    "validations": validations
                }
            
            # æå–æ¨¡å—ä¿¡æ¯
            module_info = self._extract_testbench_module_info(content)
            
            return {
                "valid": True,
                "path": str(tb_path.resolve()),
                "module_info": module_info,
                "validations": validations
            }
            
        except Exception as e:
            return {
                "valid": False,
                "error": f"éªŒè¯æµ‹è¯•å°æ—¶å‡ºé”™: {str(e)}"
            }
    
    def _extract_testbench_module_info(self, content: str) -> Dict[str, Any]:
        """ä»æµ‹è¯•å°ä¸­æå–æ¨¡å—ä¿¡æ¯"""
        info = {
            "testbench_module_name": None,
            "dut_instance_name": None,
            "dut_module_name": None,
            "signals": []
        }
        
        # æå–æµ‹è¯•å°æ¨¡å—å
        tb_module_match = re.search(r'module\s+(\w+)', content)
        if tb_module_match:
            info["testbench_module_name"] = tb_module_match.group(1)
        
        # æå–DUTå®ä¾‹åŒ–ä¿¡æ¯
        dut_instance_matches = re.findall(
            r'(\w+)\s+(\w+)\s*\([^)]*\)\s*;', content
        )
        
        if dut_instance_matches:
            # å‡è®¾ç¬¬ä¸€ä¸ªå®ä¾‹åŒ–å°±æ˜¯DUT
            info["dut_module_name"] = dut_instance_matches[0][0]
            info["dut_instance_name"] = dut_instance_matches[0][1]
        
        # æå–ä¿¡å·å£°æ˜
        signal_matches = re.findall(r'(reg|wire)\s+(?:\[\d+:\d+\])?\s*(\w+)', content)
        info["signals"] = [{"type": match[0], "name": match[1]} for match in signal_matches]
        
        return info
    
    async def _execute_simulation_with_testbench(self, module_file: str, 
                                               testbench_path: str) -> Dict[str, Any]:
        """æ‰§è¡Œä»¿çœŸå¹¶æ”¶é›†è¯¦ç»†ç»“æœ"""
        try:
            # ä½¿ç”¨iverilogæ‰§è¡Œä»¿çœŸ
            module_path = Path(module_file)
            testbench_path_obj = Path(testbench_path)
            output_file = module_path.parent / f"{module_path.stem}_sim"
            
            # ç¼–è¯‘å‘½ä»¤
            compile_cmd = [
                "iverilog", 
                "-o", str(output_file),
                str(module_path),
                str(testbench_path_obj)
            ]
            
            # æ‰§è¡Œç¼–è¯‘
            compile_result = await self._run_command(compile_cmd)
            
            if compile_result["returncode"] != 0:
                return {
                    "success": False,
                    "stage": "compilation",
                    "error": compile_result["stderr"],
                    "compile_output": compile_result["stdout"],
                    "command": " ".join(compile_cmd)
                }
            
            # è¿è¡Œä»¿çœŸ
            run_cmd = [str(output_file)]
            run_result = await self._run_command(run_cmd)
            
            # åˆ†æè¿è¡Œç»“æœ
            success = run_result["returncode"] == 0
            
            return {
                "success": success,
                "stage": "simulation" if success else "runtime_error",
                "compile_output": compile_result["stdout"],
                "simulation_output": run_result["stdout"],
                "error_output": run_result["stderr"],
                "return_code": run_result["returncode"],
                "command": " ".join(run_cmd)
            }
            
        except Exception as e:
            return {
                "success": False,
                "stage": "execution",
                "error": f"æ‰§è¡Œä»¿çœŸæ—¶å‡ºé”™: {str(e)}"
            }
    
    async def _analyze_simulation_results(self, sim_result: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æä»¿çœŸç»“æœ"""
        analysis = {
            "test_passed": sim_result["success"],
            "test_summary": "",
            "detailed_analysis": {}
        }
        
        if sim_result["success"]:
            # åˆ†ææˆåŠŸçš„ä»¿çœŸè¾“å‡º
            output = sim_result.get("simulation_output", "")
            
            # æŸ¥æ‰¾æµ‹è¯•ç»“æœæŒ‡ç¤ºå™¨
            if any(keyword in output.lower() for keyword in ["test passed", "all tests passed", "success"]):
                analysis["test_summary"] = "âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡"
                analysis["all_tests_passed"] = True
            elif any(keyword in output.lower() for keyword in ["test failed", "error", "fail"]):
                analysis["test_summary"] = "âš ï¸ ä»¿çœŸæˆåŠŸä½†æµ‹è¯•å¯èƒ½å¤±è´¥"
                analysis["all_tests_passed"] = False
                analysis["potential_issues"] = self._extract_potential_issues(output)
            else:
                analysis["test_summary"] = "âœ… ä»¿çœŸå®Œæˆï¼Œéœ€è¦äººå·¥ç¡®è®¤ç»“æœ"
                analysis["all_tests_passed"] = True  # å‡è®¾æˆåŠŸ
        
        return analysis
    
    async def _analyze_test_failures(self, sim_result: Dict[str, Any], 
                                   module_file: str, testbench_path: str) -> Dict[str, Any]:
        """æ·±åº¦åˆ†ææµ‹è¯•å¤±è´¥åŸå› """
        analysis = {
            "failure_analysis": {},
            "suggested_fixes": [],
            "all_tests_passed": False
        }
        
        stage = sim_result.get("stage", "unknown")
        error_output = sim_result.get("error_output", "")
        
        if stage == "compilation":
            # ç¼–è¯‘é”™è¯¯åˆ†æ
            analysis["failure_analysis"] = await self._analyze_compilation_errors(
                error_output, module_file, testbench_path
            )
        elif stage == "runtime_error":
            # è¿è¡Œæ—¶é”™è¯¯åˆ†æ
            analysis["failure_analysis"] = await self._analyze_runtime_errors(
                error_output, sim_result.get("simulation_output", "")
            )
        
        # ç”Ÿæˆä¿®å¤å»ºè®®
        analysis["suggested_fixes"] = await self._generate_fix_suggestions(
            analysis["failure_analysis"], module_file
        )
        
        return analysis
    
    async def _analyze_compilation_errors(self, error_output: str, 
                                        module_file: str, testbench_path: str) -> Dict[str, Any]:
        """åˆ†æç¼–è¯‘é”™è¯¯"""
        analysis = {
            "error_type": "compilation",
            "specific_errors": [],
            "common_issues": []
        }
        
        # è§£æå…·ä½“é”™è¯¯
        error_patterns = [
            (r"error: (.+)", "general_error"),
            (r"syntax error (.+)", "syntax_error"),
            (r"undeclared identifier (.+)", "undeclared_identifier"),
            (r"port (.+) not found", "port_mismatch"),
            (r"module (.+) not found", "module_not_found")
        ]
        
        for pattern, error_type in error_patterns:
            matches = re.findall(pattern, error_output, re.IGNORECASE)
            for match in matches:
                analysis["specific_errors"].append({
                    "type": error_type,
                    "message": match,
                    "line": self._extract_line_number(error_output, match)
                })
        
        # è¯†åˆ«å¸¸è§é—®é¢˜
        if "port" in error_output.lower() and "not found" in error_output.lower():
            analysis["common_issues"].append("ç«¯å£åç§°ä¸åŒ¹é…")
        if "undeclared" in error_output.lower():
            analysis["common_issues"].append("ä¿¡å·æœªå£°æ˜")
        if "module" in error_output.lower() and "not found" in error_output.lower():
            analysis["common_issues"].append("æ¨¡å—åç§°ä¸åŒ¹é…")
        
        return analysis
    
    async def _analyze_runtime_errors(self, error_output: str, 
                                     simulation_output: str) -> Dict[str, Any]:
        """åˆ†æè¿è¡Œæ—¶é”™è¯¯"""
        analysis = {
            "error_type": "runtime",
            "runtime_issues": [],
            "simulation_problems": []
        }
        
        # æ£€æŸ¥å¸¸è§è¿è¡Œæ—¶é—®é¢˜
        if "x" in simulation_output.lower() or "z" in simulation_output.lower():
            analysis["simulation_problems"].append("ä¿¡å·å­˜åœ¨æœªçŸ¥çŠ¶æ€(X)æˆ–é«˜é˜»æ€(Z)")
        
        if "$finish" not in simulation_output and "$stop" not in simulation_output:
            analysis["simulation_problems"].append("ä»¿çœŸå¯èƒ½æœªæ­£å¸¸ç»“æŸ")
        
        # æ£€æŸ¥æ—¶åºé—®é¢˜
        if "time" in error_output.lower():
            analysis["runtime_issues"].append("å¯èƒ½å­˜åœ¨æ—¶åºç›¸å…³é—®é¢˜")
        
        return analysis
    
    async def _generate_fix_suggestions(self, failure_analysis: Dict[str, Any], 
                                      module_file: str) -> List[str]:
        """ç”Ÿæˆä¿®å¤å»ºè®®"""
        suggestions = []
        error_type = failure_analysis.get("error_type", "")
        
        if error_type == "compilation":
            for error in failure_analysis.get("specific_errors", []):
                if error["type"] == "port_mismatch":
                    suggestions.append(f"æ£€æŸ¥æ¨¡å—ç«¯å£å®šä¹‰ï¼Œç¡®ä¿æµ‹è¯•å°ä¸­çš„ç«¯å£è¿æ¥æ­£ç¡®")
                elif error["type"] == "undeclared_identifier":
                    suggestions.append(f"å£°æ˜ç¼ºå¤±çš„ä¿¡å·: {error['message']}")
                elif error["type"] == "module_not_found":
                    suggestions.append(f"ç¡®ä¿æ¨¡å—åç§°åŒ¹é…: {error['message']}")
        
        elif error_type == "runtime":
            for issue in failure_analysis.get("simulation_problems", []):
                if "æœªçŸ¥çŠ¶æ€" in issue:
                    suggestions.append("æ£€æŸ¥ä¿¡å·åˆå§‹åŒ–ï¼Œç¡®ä¿æ‰€æœ‰ä¿¡å·éƒ½æœ‰æ˜ç¡®çš„åˆå§‹å€¼")
                elif "æœªæ­£å¸¸ç»“æŸ" in issue:
                    suggestions.append("åœ¨æµ‹è¯•å°ä¸­æ·»åŠ $finishè¯­å¥ä»¥æ­£å¸¸ç»“æŸä»¿çœŸ")
        
        return suggestions
    
    def _extract_line_number(self, error_output: str, error_message: str) -> Optional[int]:
        """ä»é”™è¯¯è¾“å‡ºä¸­æå–è¡Œå·"""
        # æŸ¥æ‰¾è¡Œå·æ¨¡å¼
        line_patterns = [
            rf"{re.escape(error_message)}.*:(\d+):",
            rf":(\d+):.*{re.escape(error_message)}"
        ]
        
        for pattern in line_patterns:
            match = re.search(pattern, error_output)
            if match:
                return int(match.group(1))
        
        return None
    
    def _extract_potential_issues(self, output: str) -> List[str]:
        """ä»è¾“å‡ºä¸­æå–æ½œåœ¨é—®é¢˜"""
        issues = []
        
        # æŸ¥æ‰¾è­¦å‘Šä¿¡æ¯
        warning_patterns = [
            r"WARNING: (.+)",
            r"Warning: (.+)",
            r"æ³¨æ„: (.+)"
        ]
        
        for pattern in warning_patterns:
            matches = re.findall(pattern, output, re.IGNORECASE)
            issues.extend(matches)
        
        return issues


# è¿™äº›æ–¹æ³•éœ€è¦æ·»åŠ åˆ° RealCodeReviewAgent ç±»ä¸­
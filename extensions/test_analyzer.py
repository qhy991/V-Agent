#!/usr/bin/env python3
"""
æµ‹è¯•åˆ†æå™¨ - å®Œå…¨ç‹¬ç«‹çš„æ‰©å±•æ¨¡å—
"""

import asyncio
import subprocess
import tempfile
import re
import json
import logging
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple

from .verilog_dependency_analyzer import VerilogDependencyAnalyzer


class TestAnalyzer:
    """æµ‹è¯•åˆ†æå™¨ - ä¸“é—¨å¤„ç†æµ‹è¯•æ‰§è¡Œå’Œåˆ†æ"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.TestAnalyzer")
        self.temp_dir = Path(tempfile.gettempdir()) / "tdd_test_analyzer"
        self.temp_dir.mkdir(exist_ok=True)
        self.dependency_analyzer = VerilogDependencyAnalyzer()
    
    async def validate_testbench_file(self, testbench_path: str) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•å°æ–‡ä»¶"""
        try:
            tb_path = Path(testbench_path)
            
            if not tb_path.exists():
                return {
                    "valid": False,
                    "error": f"æµ‹è¯•å°æ–‡ä»¶ä¸å­˜åœ¨: {testbench_path}",
                    "suggestions": ["æ£€æŸ¥æµ‹è¯•å°æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®", "ç¡®ä¿æ–‡ä»¶å­˜åœ¨ä¸”å¯è¯»"]
                }
            
            # è¯»å–å†…å®¹
            try:
                content = tb_path.read_text(encoding='utf-8')
            except UnicodeDecodeError:
                content = tb_path.read_text(encoding='latin-1')
            
            # åŸºæœ¬éªŒè¯
            validations = self._validate_testbench_content(content)
            
            if not validations["is_valid"]:
                return {
                    "valid": False,
                    "error": "æµ‹è¯•å°æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®",
                    "validation_details": validations,
                    "suggestions": self._generate_testbench_fix_suggestions(validations)
                }
            
            # æå–æ¨¡å—ä¿¡æ¯
            module_info = self._extract_testbench_info(content)
            
            return {
                "valid": True,
                "path": str(tb_path.resolve()),
                "size": tb_path.stat().st_size,
                "module_info": module_info,
                "validation_details": validations
            }
            
        except Exception as e:
            return {
                "valid": False,
                "error": f"éªŒè¯æµ‹è¯•å°æ—¶å‡ºé”™: {str(e)}",
                "suggestions": ["æ£€æŸ¥æ–‡ä»¶æƒé™", "ç¡®ä¿æ–‡ä»¶ä¸è¢«å…¶ä»–ç¨‹åºå ç”¨"]
            }
    
    def _validate_testbench_content(self, content: str) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•å°å†…å®¹"""
        validations = {
            "has_module": bool(re.search(r'module\s+\w+', content)),
            "has_endmodule": "endmodule" in content,
            "has_initial_block": "initial" in content or "always" in content,
            "has_testbench_elements": any(keyword in content.lower() 
                for keyword in ["$monitor", "$display", "$finish", "$stop", "$dumpfile"]),
            "has_time_control": any(keyword in content 
                for keyword in ["#", "@", "wait"]),
            "syntax_check": self._basic_syntax_check(content)
        }
        
        validations["is_valid"] = all([
            validations["has_module"],
            validations["has_endmodule"],
            validations["has_initial_block"],
            validations["syntax_check"]
        ])
        
        return validations
    
    def _basic_syntax_check(self, content: str) -> bool:
        """åŸºæœ¬è¯­æ³•æ£€æŸ¥"""
        try:
            # æ£€æŸ¥æ‹¬å·åŒ¹é…
            open_parens = content.count('(')
            close_parens = content.count(')')
            if open_parens != close_parens:
                return False
            
            # æ£€æŸ¥begin/endåŒ¹é…
            begin_count = len(re.findall(r'\bbegin\b', content))
            end_count = len(re.findall(r'\bend\b', content))
            if begin_count != end_count:
                return False
            
            return True
        except:
            return False
    
    def _parse_compiler_errors(self, error_output: str) -> Dict[str, Any]:
        """è§£æç¼–è¯‘å™¨é”™è¯¯ï¼Œæå–æ–‡ä»¶åå’Œè¡Œå·"""
        errors = []
        
        # iverilogé”™è¯¯æ ¼å¼ï¼šfilename:line: message
        # ç¤ºä¾‹ï¼šsimple_adder.v:12: syntax error
        error_pattern = r'(.+?):(\d+):\s*(.+)'
        
        lines = error_output.split('\n')
        for line in lines:
            match = re.match(error_pattern, line.strip())
            if match:
                filename, line_num, message = match.groups()
                errors.append({
                    "file": filename,
                    "line": int(line_num),
                    "message": message.strip(),
                    "type": self._categorize_error(message)
                })
        
        return {
            "error_count": len(errors),
            "precise_errors": errors,
            "summary": self._generate_error_summary(errors)
        }
    
    def _categorize_error(self, error_message: str) -> str:
        """å¯¹é”™è¯¯ç±»å‹è¿›è¡Œåˆ†ç±»"""
        message_lower = error_message.lower()
        
        if "syntax" in message_lower:
            return "syntax_error"
        elif "undeclared" in message_lower:
            return "undeclared_identifier"
        elif "module" in message_lower and "not found" in message_lower:
            return "module_not_found"
        elif "port" in message_lower:
            return "port_error"
        elif "wire" in message_lower or "reg" in message_lower:
            return "signal_declaration_error"
        else:
            return "other_error"
    
    def _generate_error_summary(self, errors: List[Dict[str, Any]]) -> str:
        """ç”Ÿæˆé”™è¯¯æ‘˜è¦"""
        if not errors:
            return "æ— ç¼–è¯‘é”™è¯¯"
        
        summary = f"å‘ç° {len(errors)} ä¸ªç¼–è¯‘é”™è¯¯:\n"
        for i, error in enumerate(errors[:3], 1):  # æœ€å¤šæ˜¾ç¤ºå‰3ä¸ª
            summary += f"{i}. æ–‡ä»¶: {error['file']}, è¡Œ: {error['line']}\n"
            summary += f"   é”™è¯¯: {error['message']}\n"
        
        if len(errors) > 3:
            summary += f"... è¿˜æœ‰ {len(errors) - 3} ä¸ªé”™è¯¯\n"
        
        return summary
    
    def _extract_testbench_info(self, content: str) -> Dict[str, Any]:
        """æå–æµ‹è¯•å°ä¿¡æ¯"""
        info = {
            "testbench_module": None,
            "dut_instances": [],
            "signals": [],
            "clocks": [],
            "test_procedures": []
        }
        
        # æå–æµ‹è¯•å°æ¨¡å—å
        tb_match = re.search(r'module\s+(\w+)', content)
        if tb_match:
            info["testbench_module"] = tb_match.group(1)
        
        # æå–DUTå®ä¾‹
        instance_pattern = r'(\w+)\s+(\w+)\s*\([^)]*\)\s*;'
        instances = re.findall(instance_pattern, content)
        for module_name, instance_name in instances:
            if module_name != info["testbench_module"]:
                info["dut_instances"].append({
                    "module": module_name,
                    "instance": instance_name
                })
        
        # æå–ä¿¡å·å£°æ˜
        signal_patterns = [
            r'(reg|wire)\s+(?:\[[\d:]+\])?\s*(\w+)',
            r'(input|output)\s+(?:\[[\d:]+\])?\s*(\w+)'
        ]
        
        for pattern in signal_patterns:
            matches = re.findall(pattern, content)
            for signal_type, signal_name in matches:
                info["signals"].append({
                    "type": signal_type,
                    "name": signal_name
                })
        
        # æ£€æµ‹æ—¶é’Ÿä¿¡å·
        for signal in info["signals"]:
            if any(clk_keyword in signal["name"].lower() 
                   for clk_keyword in ["clk", "clock", "ck"]):
                info["clocks"].append(signal["name"])
        
        return info
    
    def _generate_testbench_fix_suggestions(self, validations: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæµ‹è¯•å°ä¿®å¤å»ºè®®"""
        suggestions = []
        
        if not validations["has_module"]:
            suggestions.append("æ·»åŠ moduleå£°æ˜: module testbench_name();")
        
        if not validations["has_endmodule"]:
            suggestions.append("æ·»åŠ endmoduleè¯­å¥ç»“æŸæ¨¡å—å®šä¹‰")
        
        if not validations["has_initial_block"]:
            suggestions.append("æ·»åŠ initialå—æˆ–alwayså—æ¥é©±åŠ¨æµ‹è¯•")
        
        if not validations["has_testbench_elements"]:
            suggestions.append("æ·»åŠ æµ‹è¯•å°å…ƒç´ ï¼š$monitor, $display, $finishç­‰")
        
        if not validations["syntax_check"]:
            suggestions.append("æ£€æŸ¥è¯­æ³•é”™è¯¯ï¼šæ‹¬å·åŒ¹é…ã€begin/endåŒ¹é…ç­‰")
        
        return suggestions
    
    async def run_with_user_testbench(self, design_files: List[Any],
                                    testbench_path: str) -> Dict[str, Any]:
        """ä½¿ç”¨ç”¨æˆ·æµ‹è¯•å°è¿è¡Œæµ‹è¯• - å¢å¼ºä¾èµ–åˆ†æ"""
        self.logger.info(f"ğŸ§ª ä½¿ç”¨ç”¨æˆ·æµ‹è¯•å°è¿è¡Œæµ‹è¯•: {testbench_path}")
        
        try:
            # å‡†å¤‡æ–‡ä»¶è·¯å¾„
            design_file_paths = self._extract_file_paths(design_files)
            
            if not design_file_paths:
                return {
                    "success": False,
                    "error": "æ²¡æœ‰æ‰¾åˆ°è®¾è®¡æ–‡ä»¶",
                    "all_tests_passed": False
                }
            
            # ğŸ” è¿›è¡Œä¾èµ–åˆ†æå’Œå…¼å®¹æ€§æ£€æŸ¥
            dependency_analysis = await self._analyze_dependencies(design_file_paths, testbench_path)
            
            if not dependency_analysis["success"]:
                return {
                    "success": False,
                    "error": f"ä¾èµ–åˆ†æå¤±è´¥: {dependency_analysis['error']}",
                    "all_tests_passed": False,
                    "dependency_analysis": dependency_analysis
                }
            
            # ä½¿ç”¨ä¾èµ–åˆ†æçš„ç»“æœæ¥ç¡®å®šç¼–è¯‘æ–‡ä»¶
            compilation_files = dependency_analysis.get("compilation_files", design_file_paths)
            
            self.logger.info(f"ğŸ” ä¾èµ–åˆ†æå®Œæˆï¼Œéœ€è¦ç¼–è¯‘ {len(compilation_files)} ä¸ªæ–‡ä»¶")
            
            # æ‰§è¡Œä»¿çœŸ
            sim_result = await self._run_simulation(compilation_files, testbench_path)
            
            # åˆ†æç»“æœ
            analysis = await self._analyze_simulation_output(sim_result)
            
            # å¦‚æœç¼–è¯‘å¤±è´¥ï¼Œç¡®ä¿æ™ºèƒ½é”™è¯¯åˆ†æç»“æœè¢«åŒ…å«
            if not sim_result.get("success", False) and "detailed_analysis" in analysis:
                # å°†æ™ºèƒ½åˆ†æç»“æœåˆå¹¶åˆ°ä¸»ç»“æœä¸­
                analysis["intelligent_error_analysis"] = True
                
                # ç¡®ä¿suggestionsè¢«æ­£ç¡®ä¼ é€’
                if "suggestions" in analysis and analysis["suggestions"]:
                    analysis["has_intelligent_suggestions"] = True
            
            # åˆå¹¶ç»“æœ
            result = {
                **sim_result,
                **analysis,
                "testbench_path": testbench_path,
                "design_files": design_file_paths,
                "compilation_files": compilation_files,
                "dependency_analysis": dependency_analysis
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": f"æµ‹è¯•æ‰§è¡Œå¼‚å¸¸: {str(e)}",
                "all_tests_passed": False
            }
    
    async def _analyze_dependencies(self, design_file_paths: List[str], testbench_path: str) -> Dict[str, Any]:
        """åˆ†æVerilogæ–‡ä»¶ä¾èµ–å…³ç³»"""
        try:
            self.logger.info("ğŸ” å¼€å§‹Verilogä¾èµ–åˆ†æ...")
            
            # åˆ†ææ‰€æœ‰ç›¸å…³æ–‡ä»¶
            all_files = design_file_paths + [testbench_path]
            
            for file_path in all_files:
                self.dependency_analyzer.analyze_file(file_path)
            
            # æ£€æŸ¥å…¼å®¹æ€§
            if len(design_file_paths) == 1:
                compatibility = self.dependency_analyzer.analyze_compatibility(
                    design_file_paths[0], testbench_path
                )
                
                self.logger.info(f"ğŸ“Š å…¼å®¹æ€§åˆ†æ: å…¼å®¹={compatibility['compatible']}")
                if compatibility["issues"]:
                    for issue in compatibility["issues"]:
                        self.logger.warning(f"âš ï¸ å…¼å®¹æ€§é—®é¢˜: {issue}")
                
                # è·å–ä¿®å¤å»ºè®®
                suggestions = self.dependency_analyzer.suggest_fixes(compatibility)
                
                # å¦‚æœæœ‰ç¼ºå¤±çš„ä¾èµ–ï¼Œå°è¯•ä»æ–‡ä»¶ç®¡ç†å™¨ä¸­æŸ¥æ‰¾
                missing_deps = compatibility.get("missing_dependencies", [])
                additional_files = []
                
                if missing_deps:
                    self.logger.info(f"ğŸ” æŸ¥æ‰¾ç¼ºå¤±çš„ä¾èµ–æ¨¡å—: {missing_deps}")
                    additional_files = await self._find_missing_dependencies(missing_deps)
                
                # ç¡®å®šæœ€ç»ˆçš„ç¼–è¯‘æ–‡ä»¶åˆ—è¡¨
                compilation_files = design_file_paths + additional_files
                
                return {
                    "success": True,
                    "compatible": compatibility["compatible"],
                    "issues": compatibility["issues"],
                    "suggestions": suggestions,
                    "missing_dependencies": missing_deps,
                    "additional_files": additional_files,
                    "compilation_files": compilation_files,
                    "design_modules": compatibility.get("design_modules", []),
                    "testbench_modules": compatibility.get("testbench_modules", [])
                }
            else:
                # å¤šä¸ªè®¾è®¡æ–‡ä»¶çš„æƒ…å†µ
                self.logger.warning("âš ï¸ å¤šä¸ªè®¾è®¡æ–‡ä»¶ï¼Œè·³è¿‡è¯¦ç»†å…¼å®¹æ€§åˆ†æ")
                return {
                    "success": True,
                    "compatible": True,
                    "issues": ["å¤šä¸ªè®¾è®¡æ–‡ä»¶ï¼Œæœªè¿›è¡Œè¯¦ç»†å…¼å®¹æ€§åˆ†æ"],
                    "suggestions": [],
                    "compilation_files": design_file_paths
                }
                
        except Exception as e:
            self.logger.error(f"âŒ ä¾èµ–åˆ†æå¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "compilation_files": design_file_paths
            }
    
    async def _find_missing_dependencies(self, missing_modules: List[str]) -> List[str]:
        """æ™ºèƒ½æœç´¢ç¼ºå¤±çš„ä¾èµ–æ¨¡å—ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        additional_files = []
        
        try:
            from core.file_manager import get_file_manager
            file_manager = get_file_manager()
            
            # ğŸ¯ ç­–ç•¥1ï¼šä»æ–‡ä»¶ç®¡ç†å™¨è·å–æ‰€æœ‰ç›¸å…³æ–‡ä»¶
            all_verilog_files = file_manager.get_files_by_type("verilog")
            
            # ğŸ¯ ç­–ç•¥2ï¼šæ™ºèƒ½æ¨¡å—åŒ¹é…ï¼Œæ”¯æŒå¤šç§å‘½åæ¨¡å¼
            for missing_module in missing_modules:
                self.logger.info(f"ğŸ” æ™ºèƒ½æœç´¢ç¼ºå¤±æ¨¡å—: {missing_module}")
                found = False
                
                # æŒ‰ä¼˜å…ˆçº§æœç´¢
                search_patterns = [
                    missing_module.lower(),                    # å®Œå…¨åŒ¹é…
                    f"{missing_module.lower()}.v",            # å¸¦æ‰©å±•å
                    f"{missing_module.lower()}_module",       # åç¼€æ¨¡å¼
                    f"module_{missing_module.lower()}",       # å‰ç¼€æ¨¡å¼
                ]
                
                for file_ref in all_verilog_files:
                    if found:
                        break
                        
                    file_path = file_ref.file_path
                    filename = Path(file_path).stem.lower()
                    
                    # æ¨¡å¼åŒ¹é…
                    for pattern in search_patterns:
                        if pattern in filename or filename in pattern:
                            # ğŸ” æ·±åº¦éªŒè¯ï¼šæ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦çœŸçš„åŒ…å«è¯¥æ¨¡å—
                            if self._verify_module_in_file(file_path, missing_module):
                                if file_path not in additional_files:
                                    additional_files.append(file_path)
                                    self.logger.info(f"âœ… æ‰¾åˆ°ä¾èµ–æ–‡ä»¶: {Path(file_path).name} (åŒ¹é…æ¨¡å¼: {pattern})")
                                    found = True
                                    break
                
                if not found:
                    # ğŸ¯ ç­–ç•¥3ï¼šå†…å®¹æœç´¢ä½œä¸ºæœ€åæ‰‹æ®µ
                    self.logger.warning(f"âš ï¸ æ–‡ä»¶ååŒ¹é…å¤±è´¥ï¼Œå°è¯•å†…å®¹æœç´¢: {missing_module}")
                    content_match_file = await self._search_module_in_content(missing_module, all_verilog_files)
                    if content_match_file and content_match_file not in additional_files:
                        additional_files.append(content_match_file)
                        self.logger.info(f"âœ… é€šè¿‡å†…å®¹æœç´¢æ‰¾åˆ°: {Path(content_match_file).name}")
            
            # ğŸ¯ ç­–ç•¥4ï¼šä¾èµ–é¡ºåºä¼˜åŒ–
            if additional_files:
                # ä½¿ç”¨ä¾èµ–åˆ†æå™¨ç¡®å®šæ­£ç¡®çš„ç¼–è¯‘é¡ºåº
                ordered_files = self._optimize_compilation_order(additional_files)
                self.logger.info(f"ğŸ”„ ä¼˜åŒ–ç¼–è¯‘é¡ºåºï¼Œæ–‡ä»¶æ•°: {len(ordered_files)}")
                return ordered_files
            
        except Exception as e:
            self.logger.error(f"âŒ æœç´¢ä¾èµ–æ¨¡å—æ—¶å‡ºé”™: {str(e)}")
        
        return additional_files
    
    def _verify_module_in_file(self, file_path: str, module_name: str) -> bool:
        """éªŒè¯æ–‡ä»¶ä¸­æ˜¯å¦çœŸæ­£åŒ…å«æŒ‡å®šæ¨¡å—"""
        try:
            if not Path(file_path).exists():
                return False
                
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾æ¨¡å—å®šä¹‰
            module_pattern = rf'module\s+{re.escape(module_name)}\s*[\(;]'
            return bool(re.search(module_pattern, content, re.IGNORECASE))
            
        except Exception as e:
            self.logger.debug(f"éªŒè¯æ¨¡å—æ—¶å‡ºé”™ {file_path}: {e}")
            return False
    
    async def _search_module_in_content(self, module_name: str, verilog_files: List) -> Optional[str]:
        """åœ¨æ–‡ä»¶å†…å®¹ä¸­æœç´¢æ¨¡å—å®šä¹‰"""
        for file_ref in verilog_files:
            if self._verify_module_in_file(file_ref.file_path, module_name):
                return file_ref.file_path
        return None
    
    def _optimize_compilation_order(self, file_list: List[str]) -> List[str]:
        """ä½¿ç”¨ä¾èµ–åˆ†æå™¨ä¼˜åŒ–ç¼–è¯‘é¡ºåº"""
        try:
            # åˆ†ææ‰€æœ‰æ–‡ä»¶çš„ä¾èµ–å…³ç³»
            for file_path in file_list:
                self.dependency_analyzer.analyze_file(file_path)
            
            # æŸ¥æ‰¾é¡¶å±‚æ¨¡å—
            top_modules = self.dependency_analyzer.find_top_level_modules(exclude_testbenches=True)
            
            if top_modules:
                # ä¸ºæ¯ä¸ªé¡¶å±‚æ¨¡å—ç”Ÿæˆç¼–è¯‘é¡ºåº
                all_ordered_files = []
                for top_module in top_modules:
                    ordered = self.dependency_analyzer.generate_compilation_order(top_module)
                    all_ordered_files.extend(ordered)
                
                # å»é‡å¹¶ä¿æŒé¡ºåº
                seen = set()
                final_order = []
                for file_path in all_ordered_files:
                    if file_path not in seen and file_path in file_list:
                        seen.add(file_path)
                        final_order.append(file_path)
                
                # æ·»åŠ å‰©ä½™æ–‡ä»¶
                for file_path in file_list:
                    if file_path not in seen:
                        final_order.append(file_path)
                
                return final_order
            
        except Exception as e:
            self.logger.debug(f"ç¼–è¯‘é¡ºåºä¼˜åŒ–å¤±è´¥: {e}")
        
        # å›é€€åˆ°åŸå§‹é¡ºåº
        return file_list
    
    def _extract_file_paths(self, design_files: List[Any]) -> List[str]:
        """æå–è®¾è®¡æ–‡ä»¶è·¯å¾„ - å¢å¼ºé”™è¯¯å¤„ç†å’Œæ–‡ä»¶æœç´¢"""
        paths = []
        
        self.logger.debug(f"ğŸ” æå–æ–‡ä»¶è·¯å¾„ï¼Œè¾“å…¥ç±»å‹: {type(design_files)}, é•¿åº¦: {len(design_files) if design_files else 0}")
        
        if not design_files:
            self.logger.error("âŒ design_filesä¸ºç©ºï¼Œæ— æ³•ç»§ç»­æ‰§è¡Œ")
            return []
        
        for i, file_ref in enumerate(design_files):
            self.logger.info(f"ğŸ” å¤„ç†æ–‡ä»¶å¼•ç”¨ {i}: {type(file_ref)} = {file_ref}")
            
            path = None
            
            # å¤„ç†ä¸åŒç±»å‹çš„æ–‡ä»¶å¼•ç”¨
            if isinstance(file_ref, dict):
                # å­—å…¸æ ¼å¼ï¼š{"file_path": "...", "file_type": "...", ...}
                path = (file_ref.get("file_path") or 
                       file_ref.get("path") or 
                       (file_ref.get("result", {}).get("file_path") if isinstance(file_ref.get("result"), dict) else None))
                self.logger.info(f"  å­—å…¸æ ¼å¼ï¼Œæå–è·¯å¾„: {path}")
                
            elif hasattr(file_ref, 'path'):
                # FileReferenceå¯¹è±¡çš„pathå±æ€§
                path = str(file_ref.path)
                self.logger.info(f"  FileReferenceå¯¹è±¡ï¼Œpathå±æ€§: {path}")
                
            elif hasattr(file_ref, 'file_path'):
                # å…¶ä»–å¯¹è±¡çš„file_pathå±æ€§ 
                path = str(file_ref.file_path)
                self.logger.info(f"  å…¶ä»–å¯¹è±¡ï¼Œfile_pathå±æ€§: {path}")
                
            elif isinstance(file_ref, (str, Path)):
                # ç›´æ¥çš„è·¯å¾„å­—ç¬¦ä¸²æˆ–Pathå¯¹è±¡
                path = str(file_ref)
                self.logger.info(f"  ç›´æ¥è·¯å¾„: {path}")
                
            else:
                self.logger.warning(f"âš ï¸ æœªçŸ¥æ–‡ä»¶å¼•ç”¨ç±»å‹: {type(file_ref)}")
                # å°è¯•å°†å¯¹è±¡è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œçœ‹æ˜¯å¦åŒ…å«è·¯å¾„ä¿¡æ¯
                str_repr = str(file_ref)
                if '.v' in str_repr or '.sv' in str_repr:
                    # å°è¯•ä»å­—ç¬¦ä¸²è¡¨ç¤ºä¸­æå–è·¯å¾„
                    import re
                    path_matches = re.findall(r'[^\s]+\.s?v', str_repr)
                    if path_matches:
                        path = path_matches[0]
                        self.logger.info(f"  ä»å­—ç¬¦ä¸²è¡¨ç¤ºä¸­æå–è·¯å¾„: {path}")
                continue
            
            if path:
                self.logger.info(f"  ğŸ“ æ£€æŸ¥è·¯å¾„: {path}")
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æ˜¯Verilogæ–‡ä»¶
                path_obj = Path(path)
                if path_obj.exists():
                    self.logger.info(f"  âœ… æ–‡ä»¶å­˜åœ¨: {path}")
                    # åªå¤„ç†.vå’Œ.svæ–‡ä»¶ï¼ˆVerilogå’ŒSystemVerilogï¼‰
                    if path.endswith(('.v', '.sv')):
                        resolved_path = str(path_obj.resolve())
                        paths.append(resolved_path)
                        self.logger.info(f"  âœ… æ·»åŠ Verilogæ–‡ä»¶: {resolved_path}")
                    else:
                        self.logger.info(f"  â­ï¸ è·³è¿‡éVerilogæ–‡ä»¶: {path}")
                else:
                    self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {path}")
                    # å°è¯•åœ¨å¸¸è§ç›®å½•ä¸­æœç´¢åŒåæ–‡ä»¶
                    found_path = self._search_file_in_common_dirs(Path(path).name)
                    if found_path:
                        paths.append(found_path)
                        self.logger.info(f"  ğŸ” åœ¨å¤‡ç”¨ä½ç½®æ‰¾åˆ°æ–‡ä»¶: {found_path}")
            else:
                self.logger.warning(f"  âš ï¸ æ— æ³•æå–è·¯å¾„ä¿¡æ¯")
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œè®°å½•é”™è¯¯ä½†ä¸æœç´¢å·¥ä½œç›®å½•
        if not paths:
            self.logger.error("âŒ æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„è®¾è®¡æ–‡ä»¶")
        
        self.logger.info(f"ğŸ“„ æˆåŠŸæå–è®¾è®¡æ–‡ä»¶è·¯å¾„: {len(paths)} ä¸ªæ–‡ä»¶")
        for i, path in enumerate(paths):
            self.logger.info(f"  {i+1}. {path}")
        
        # ğŸ§¹ ä»£ç æ¸…ç†ï¼šæ£€æŸ¥å¹¶ä¿®å¤è®¾è®¡æ–‡ä»¶ä¸­çš„æ ¼å¼é—®é¢˜
        cleaned_paths = self._clean_design_files(paths)
        
        return cleaned_paths
    

    def _search_verilog_files_in_working_dir(self) -> List[str]:
        """åœ¨å·¥ä½œç›®å½•ä¸­æœç´¢Verilogæ–‡ä»¶"""
        paths = []
        search_dirs = [
            Path.cwd(),
            Path.cwd() / "artifacts",
            Path.cwd() / "logs" / "experiment_files",
            Path.cwd() / "design_files"
        ]
        
        for search_dir in search_dirs:
            if search_dir.exists():
                for verilog_file in search_dir.glob("*.v"):
                    if verilog_file.is_file() and not verilog_file.name.endswith("_tb.v"):
                        paths.append(str(verilog_file.resolve()))
                        self.logger.info(f"ğŸ” å‘ç°è®¾è®¡æ–‡ä»¶: {verilog_file}")
                        
                for sv_file in search_dir.glob("*.sv"):
                    if sv_file.is_file() and not sv_file.name.endswith("_tb.sv"):
                        paths.append(str(sv_file.resolve()))
                        self.logger.info(f"ğŸ” å‘ç°SystemVerilogè®¾è®¡æ–‡ä»¶: {sv_file}")
        
        return paths
    
    def _search_file_in_common_dirs(self, filename: str) -> Optional[str]:
        """åœ¨å¸¸è§ç›®å½•ä¸­æœç´¢æ–‡ä»¶"""
        search_dirs = [
            Path.cwd(),
            Path.cwd() / "artifacts", 
            Path.cwd() / "logs" / "experiment_files",
            Path.cwd() / "design_files"
        ]
        
        for search_dir in search_dirs:
            if search_dir.exists():
                file_path = search_dir / filename
                if file_path.exists():
                    return str(file_path.resolve())
        
        return None
    
    async def _run_simulation(self, design_files: List[str], 
                            testbench_path: str) -> Dict[str, Any]:
        """è¿è¡Œä»¿çœŸ"""
        try:
            self.logger.info(f"ğŸ§ª å¼€å§‹ä»¿çœŸï¼Œè®¾è®¡æ–‡ä»¶: {len(design_files)} ä¸ª")
            self.logger.info(f"ğŸ§ª æµ‹è¯•å°æ–‡ä»¶: {testbench_path}")
            
            # è¯¦ç»†éªŒè¯å’Œè®°å½•æ¯ä¸ªæ–‡ä»¶
            all_files = design_files + [testbench_path]
            missing_files = []
            valid_design_files = []
            
            self.logger.info("ğŸ“‹ éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§:")
            for i, file_path in enumerate(design_files):
                filename = Path(file_path).name
                if Path(file_path).exists():
                    file_size = Path(file_path).stat().st_size
                    self.logger.info(f"  âœ… è®¾è®¡æ–‡ä»¶{i+1}: {filename} ({file_size} bytes)")
                    valid_design_files.append(file_path)
                else:
                    self.logger.error(f"  âŒ è®¾è®¡æ–‡ä»¶{i+1}ä¸å­˜åœ¨: {filename}")
                    missing_files.append(file_path)
            
            # éªŒè¯æµ‹è¯•å°æ–‡ä»¶
            if Path(testbench_path).exists():
                tb_size = Path(testbench_path).stat().st_size
                tb_filename = Path(testbench_path).name
                self.logger.info(f"  âœ… æµ‹è¯•å°æ–‡ä»¶: {tb_filename} ({tb_size} bytes)")
            else:
                self.logger.error(f"  âŒ æµ‹è¯•å°æ–‡ä»¶ä¸å­˜åœ¨: {Path(testbench_path).name}")
                missing_files.append(testbench_path)
            
            if missing_files:
                return {
                    "success": False,
                    "stage": "file_validation",
                    "error": f"å‘ç° {len(missing_files)} ä¸ªç¼ºå¤±æ–‡ä»¶: {[Path(f).name for f in missing_files]}",
                    "missing_files": missing_files,
                    "valid_files": valid_design_files
                }
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æˆ–å†²çªçš„æ–‡ä»¶
            if len(valid_design_files) > 1:
                self.logger.warning(f"âš ï¸ å‘ç°å¤šä¸ªè®¾è®¡æ–‡ä»¶ï¼Œè¿™å¯èƒ½å¯¼è‡´æ¨¡å—å†²çª:")
                for f in valid_design_files:
                    self.logger.warning(f"    - {Path(f).name}")
            
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
            timestamp = int(asyncio.get_event_loop().time())
            output_file = self.temp_dir / f"sim_{timestamp}"
            
            self.logger.info(f"ğŸ“ ä¸´æ—¶ä»¿çœŸè¾“å‡º: {output_file}")
            
            # æ™ºèƒ½æ„å»ºç¼–è¯‘å‘½ä»¤ - ç¡®ä¿æ–‡ä»¶é¡ºåºæ­£ç¡®
            cmd = ["iverilog", "-o", str(output_file)]
            
            # é¦–å…ˆæ·»åŠ è®¾è®¡æ–‡ä»¶ï¼ˆæŒ‰å­—æ¯é¡ºåºï¼Œç¡®ä¿ä¸€è‡´æ€§ï¼‰
            sorted_design_files = sorted(valid_design_files, key=lambda x: Path(x).name)
            cmd.extend(sorted_design_files)
            
            # æœ€åæ·»åŠ æµ‹è¯•å°æ–‡ä»¶
            cmd.append(testbench_path)
            
            self.logger.info(f"ğŸ”¨ ç¼–è¯‘å‘½ä»¤æ–‡ä»¶é¡ºåº:")
            for i, file_path in enumerate(sorted_design_files + [testbench_path]):
                file_type = "æµ‹è¯•å°" if file_path == testbench_path else "è®¾è®¡"
                self.logger.info(f"  {i+1}. {Path(file_path).name} ({file_type})")
            
            self.logger.info(f"ğŸ”¨ ç¼–è¯‘å‘½ä»¤: {' '.join(cmd)}")
            
            # ç¡®ä¿ä¸´æ—¶ç›®å½•å­˜åœ¨
            self.temp_dir.mkdir(exist_ok=True)
            
            # æ‰§è¡Œç¼–è¯‘
            self.logger.info("â³ å¼€å§‹iverilogç¼–è¯‘...")
            compile_process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=str(Path.cwd())  # ç¡®ä¿å·¥ä½œç›®å½•æ­£ç¡®
            )
            
            compile_stdout, compile_stderr = await compile_process.communicate()
            
            compile_stdout_str = compile_stdout.decode('utf-8', errors='ignore')
            compile_stderr_str = compile_stderr.decode('utf-8', errors='ignore')
            
            self.logger.info(f"ğŸ”¨ ç¼–è¯‘è¿”å›ç : {compile_process.returncode}")
            if compile_stdout_str:
                self.logger.info(f"ğŸ“¤ ç¼–è¯‘stdout: {compile_stdout_str}")
            if compile_stderr_str:
                self.logger.info(f"ğŸ“¤ ç¼–è¯‘stderr: {compile_stderr_str}")
            
            if compile_process.returncode != 0:
                # è§£æç¼–è¯‘é”™è¯¯ï¼Œæå–æ–‡ä»¶åå’Œè¡Œå·
                error_details = self._parse_compiler_errors(compile_stderr_str)
                return {
                    "success": False,
                    "stage": "compilation",
                    "compile_stdout": compile_stdout_str,
                    "compile_stderr": compile_stderr_str,
                    "command": ' '.join(cmd),
                    "returncode": compile_process.returncode,
                    "error_details": error_details,
                    "precise_errors": error_details.get("precise_errors", [])
                }
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶å·²åˆ›å»º
            if not output_file.exists():
                return {
                    "success": False,
                    "stage": "compilation",
                    "error": f"ç¼–è¯‘æˆåŠŸä½†è¾“å‡ºæ–‡ä»¶æœªåˆ›å»º: {output_file}",
                    "compile_stdout": compile_stdout_str,
                    "compile_stderr": compile_stderr_str
                }
            
            # è¿è¡Œä»¿çœŸ
            self.logger.info(f"â–¶ï¸ è¿è¡Œä»¿çœŸ: {output_file}")
            
            run_process = await asyncio.create_subprocess_exec(
                "vvp", str(output_file),  # ä½¿ç”¨vvpè¿è¡Œç¼–è¯‘åçš„ä»¿çœŸæ–‡ä»¶
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                cwd=str(Path.cwd())
            )
            
            try:
                # è®¾ç½®è¶…æ—¶ä»¥é˜²æ­¢æ— é™è¿è¡Œ
                self.logger.info("â³ è¿è¡Œä»¿çœŸï¼Œè¶…æ—¶30ç§’...")
                sim_stdout, sim_stderr = await asyncio.wait_for(
                    run_process.communicate(), timeout=30.0
                )
                
                sim_stdout_str = sim_stdout.decode('utf-8', errors='ignore')
                sim_stderr_str = sim_stderr.decode('utf-8', errors='ignore')
                
                self.logger.info(f"â–¶ï¸ ä»¿çœŸè¿”å›ç : {run_process.returncode}")
                if sim_stdout_str:
                    self.logger.info(f"ğŸ“¤ ä»¿çœŸstdout: {sim_stdout_str}")  # æˆªæ–­é•¿è¾“å‡º
                if sim_stderr_str:
                    self.logger.info(f"ğŸ“¤ ä»¿çœŸstderr: {sim_stderr_str}")
                
            except asyncio.TimeoutError:
                self.logger.warning("â° ä»¿çœŸè¶…æ—¶ï¼Œç»ˆæ­¢è¿›ç¨‹")
                run_process.kill()
                return {
                    "success": False,
                    "stage": "simulation_timeout",
                    "error": "ä»¿çœŸè¶…æ—¶ï¼ˆ30ç§’ï¼‰",
                    "suggestion": "æ£€æŸ¥æµ‹è¯•å°æ˜¯å¦åŒ…å«$finishè¯­å¥"
                }
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                output_file.unlink()
                self.logger.debug(f"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {output_file}")
            except:
                pass
            
            simulation_success = run_process.returncode == 0
            self.logger.info(f"âœ… ä»¿çœŸå®Œæˆï¼ŒæˆåŠŸ: {simulation_success}")
            
            return {
                "success": simulation_success,
                "stage": "simulation",
                "compile_stdout": compile_stdout_str,
                "simulation_stdout": sim_stdout_str,
                "simulation_stderr": sim_stderr_str,
                "return_code": run_process.returncode
            }
            
        except FileNotFoundError:
            return {
                "success": False,
                "stage": "tool_missing",
                "error": "iverilogå·¥å…·æœªæ‰¾åˆ°",
                "suggestion": "è¯·å®‰è£…iverilog: sudo apt-get install iverilog"
            }
        except Exception as e:
            return {
                "success": False,
                "stage": "execution_error",
                "error": f"æ‰§è¡Œä»¿çœŸæ—¶å‡ºé”™: {str(e)}"
            }
    
    async def _analyze_simulation_output(self, sim_result: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æä»¿çœŸè¾“å‡º"""
        analysis = {
            "all_tests_passed": False,
            "test_summary": "",
            "detailed_analysis": {},
            "failure_reasons": [],
            "suggestions": []
        }
        
        if not sim_result.get("success", False):
            # ä»¿çœŸå¤±è´¥åˆ†æ
            stage = sim_result.get("stage", "unknown")
            
            if stage == "compilation":
                analysis.update(self._analyze_compilation_errors(sim_result))
            elif stage == "simulation_timeout":
                analysis.update(self._analyze_timeout_error(sim_result))
            else:
                analysis.update(self._analyze_runtime_errors(sim_result))
        else:
            # ä»¿çœŸæˆåŠŸï¼Œåˆ†æè¾“å‡º
            analysis.update(self._analyze_successful_simulation(sim_result))
        
        return analysis
    
    def _analyze_compilation_errors(self, sim_result: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æç¼–è¯‘é”™è¯¯ - å¢å¼ºå¯¹ä¾èµ–é—®é¢˜çš„ç†è§£"""
        stderr = sim_result.get("compile_stderr", "")
        
        analysis = {
            "test_summary": "âŒ ç¼–è¯‘å¤±è´¥",
            "failure_reasons": [],
            "suggestions": [],
            "error_category": "unknown",
            "detailed_analysis": {}
        }
        
        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šåˆ†æç¼–è¯‘é”™è¯¯
        self.logger.info(f"ğŸ” DEBUG: åˆ†æç¼–è¯‘é”™è¯¯ï¼Œstderré•¿åº¦: {len(stderr)}")
        if stderr:
            self.logger.info(f"ğŸ” DEBUG: stderrå†…å®¹: {stderr[:300]}...")
        
        # å¢å¼ºçš„é”™è¯¯æ¨¡å¼åŒ¹é…
        error_patterns = {
            r"No top level modules": {
                "type": "ç¼ºå°‘é¡¶å±‚æ¨¡å—",
                "category": "dependency_issue",
                "priority": "high"
            },
            r"syntax error": {
                "type": "è¯­æ³•é”™è¯¯", 
                "category": "syntax_issue",
                "priority": "medium"
            },
            r"undeclared identifier": {
                "type": "æœªå£°æ˜çš„æ ‡è¯†ç¬¦",
                "category": "declaration_issue", 
                "priority": "medium"
            },
            r"port.*not.*port|port.*not found": {
                "type": "ç«¯å£ä¸åŒ¹é…",
                "category": "interface_issue",
                "priority": "high"
            },
            r"module.*not found": {
                "type": "æ¨¡å—æœªæ‰¾åˆ°",
                "category": "dependency_issue",
                "priority": "high"
            }
        }
        
        # åˆ†æé”™è¯¯ç±»å‹
        detected_errors = []
        for pattern, error_info in error_patterns.items():
            if re.search(pattern, stderr, re.IGNORECASE):
                detected_errors.append(error_info)
                analysis["failure_reasons"].append(error_info["type"])
                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šåŒ¹é…åˆ°çš„é”™è¯¯æ¨¡å¼
                self.logger.info(f"ğŸ” DEBUG: åŒ¹é…é”™è¯¯æ¨¡å¼: {pattern} -> {error_info['type']}")
        
        # æ ¹æ®æ£€æµ‹åˆ°çš„é”™è¯¯ç¡®å®šç±»åˆ«
        if detected_errors:
            # æŒ‰ä¼˜å…ˆçº§æ’åºï¼Œé€‰æ‹©æœ€é‡è¦çš„é”™è¯¯ç±»åˆ«
            detected_errors.sort(key=lambda x: x["priority"] == "high", reverse=True)
            analysis["error_category"] = detected_errors[0]["category"]
        
        # ç”Ÿæˆæ™ºèƒ½å»ºè®®
        analysis["suggestions"] = self._generate_intelligent_suggestions(
            analysis["failure_reasons"], 
            analysis["error_category"],
            stderr
        )
        
        # è¯¦ç»†åˆ†æ
        analysis["detailed_analysis"] = self._perform_detailed_error_analysis(stderr)
        
        return analysis
    
    def _generate_intelligent_suggestions(self, failure_reasons: List[str], 
                                        error_category: str, stderr: str) -> List[str]:
        """ç”Ÿæˆæ™ºèƒ½ä¿®å¤å»ºè®®"""
        suggestions = []
        
        if "ç¼ºå°‘é¡¶å±‚æ¨¡å—" in failure_reasons:
            suggestions.extend([
                "ğŸ” æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å­æ¨¡å—å®šä¹‰ï¼ˆå¦‚full_adderç­‰ï¼‰",
                "ğŸ”§ ç¡®ä¿æ‰€æœ‰è¢«å®ä¾‹åŒ–çš„æ¨¡å—éƒ½æœ‰å¯¹åº”çš„æ¨¡å—å®šä¹‰",
                "ğŸ“ éªŒè¯æ‰€æœ‰ä¾èµ–æ–‡ä»¶éƒ½å·²åŒ…å«åœ¨ç¼–è¯‘å‘½ä»¤ä¸­",
                "ğŸ¯ ä½¿ç”¨iverilogçš„-sé€‰é¡¹æ˜ç¡®æŒ‡å®šé¡¶å±‚æ¨¡å—"
            ])
            
            # ä»stderrä¸­æå–å¯èƒ½çš„æ¨¡å—å
            module_matches = re.findall(r'(\w+)\s+\w+\s*\([^)]*\)\s*;', stderr)
            if module_matches:
                unique_modules = list(set(module_matches))
                suggestions.append(f"ğŸ’¡ å¯èƒ½ç¼ºå°‘çš„æ¨¡å—å®šä¹‰: {', '.join(unique_modules[:3])}")
        
        if "è¯­æ³•é”™è¯¯" in failure_reasons:
            suggestions.extend([
                "ğŸ“ æ£€æŸ¥Verilogè¯­æ³•ï¼šåˆ†å·ã€æ‹¬å·ã€å…³é”®å­—æ‹¼å†™ç­‰",
                "ğŸ”¤ éªŒè¯æ ‡è¯†ç¬¦å‘½åè§„åˆ™å’Œä¿ç•™å­—ä½¿ç”¨"
            ])
        
        if "æœªå£°æ˜çš„æ ‡è¯†ç¬¦" in failure_reasons:
            suggestions.extend([
                "ğŸ“‹ æ£€æŸ¥ä¿¡å·å£°æ˜ï¼šç¡®ä¿æ‰€æœ‰ä½¿ç”¨çš„ä¿¡å·éƒ½å·²å£°æ˜",
                "ğŸ” éªŒè¯å˜é‡ä½œç”¨åŸŸå’Œå¯è§æ€§"
            ])
        
        if "ç«¯å£ä¸åŒ¹é…" in failure_reasons:
            suggestions.extend([
                "ğŸ”Œ æ£€æŸ¥æ¨¡å—å®ä¾‹åŒ–ï¼šç¡®ä¿ç«¯å£åç§°å’Œæ•°é‡åŒ¹é…",
                "ğŸ“Š éªŒè¯ç«¯å£ç±»å‹å’Œä½å®½å…¼å®¹æ€§"
            ])
        
        if "æ¨¡å—æœªæ‰¾åˆ°" in failure_reasons:
            suggestions.extend([
                "ğŸ“‚ æ£€æŸ¥æ¨¡å—åç§°ï¼šç¡®ä¿è®¾è®¡æ–‡ä»¶ä¸­çš„æ¨¡å—åä¸æµ‹è¯•å°ä¸­ä¸€è‡´",
                "ğŸ”— éªŒè¯æ¨¡å—æ–‡ä»¶è·¯å¾„å’ŒåŒ…å«å…³ç³»"
            ])
        
        # åŸºäºé”™è¯¯ç±»åˆ«çš„å»ºè®®
        if error_category == "dependency_issue":
            suggestions.append("ğŸ” å»ºè®®è¿è¡Œä¾èµ–åˆ†æä»¥è¯†åˆ«ç¼ºå¤±çš„æ¨¡å—æ–‡ä»¶")
        
        return suggestions
    
    def _extract_condensed_error_info(self, stderr: str) -> Dict[str, Any]:
        """æå–å¹¶ç²¾ç®€é”™è¯¯ä¿¡æ¯"""
        condensed = {
            "key_errors": [],
            "error_count_by_type": {},
            "critical_files": [],
            "summary": ""
        }
        
        if not stderr:
            return condensed
        
        # æŒ‰è¡Œåˆ†å‰²é”™è¯¯ä¿¡æ¯
        error_lines = [line.strip() for line in stderr.split('\n') if line.strip()]
        
        # æå–å…³é”®é”™è¯¯ï¼ˆå‰10ä¸ªæœ€é‡è¦çš„ï¼‰
        key_errors = []
        error_types = {}
        critical_files = set()
        
        for line in error_lines:
            # è·³è¿‡é‡å¤çš„é”™è¯¯ä¿¡æ¯
            if any(skip in line.lower() for skip in ['it was declared here', 'error: malformed statement']):
                continue
            
            # æå–æ–‡ä»¶åå’Œé”™è¯¯ç±»å‹
            file_match = re.search(r'([^\s]+\.s?v):(\d+):', line)
            if file_match:
                file_path, line_num = file_match.groups()
                critical_files.add(Path(file_path).name)
            
            # åˆ†ç±»é”™è¯¯ç±»å‹
            if 'syntax error' in line.lower():
                error_types['è¯­æ³•é”™è¯¯'] = error_types.get('è¯­æ³•é”™è¯¯', 0) + 1
                if len(key_errors) < 5:  # åªä¿ç•™å‰5ä¸ªè¯­æ³•é”™è¯¯
                    key_errors.append(line)
            elif 'undeclared' in line.lower():
                error_types['æœªå£°æ˜æ ‡è¯†ç¬¦'] = error_types.get('æœªå£°æ˜æ ‡è¯†ç¬¦', 0) + 1
                if len(key_errors) < 8:
                    key_errors.append(line)
            elif 'port' in line.lower() and 'not' in line.lower():
                error_types['ç«¯å£é”™è¯¯'] = error_types.get('ç«¯å£é”™è¯¯', 0) + 1
                if len(key_errors) < 10:
                    key_errors.append(line)
        
        condensed["key_errors"] = key_errors[:10]  # æœ€å¤š10ä¸ªå…³é”®é”™è¯¯
        condensed["error_count_by_type"] = error_types
        condensed["critical_files"] = list(critical_files)[:5]  # æœ€å¤š5ä¸ªæ–‡ä»¶
        
        # ç”Ÿæˆæ‘˜è¦
        if error_types:
            summary_parts = []
            for error_type, count in error_types.items():
                summary_parts.append(f"{error_type}({count}ä¸ª)")
            condensed["summary"] = f"ä¸»è¦é”™è¯¯: {', '.join(summary_parts)}"
        
        return condensed
    
    def _generate_focused_suggestions(self, failure_reasons: List[str], 
                                    error_category: str, 
                                    condensed_errors: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆç²¾å‡†çš„ä¿®å¤å»ºè®®"""
        suggestions = []
        
        # åŸºäºé”™è¯¯ç±»å‹çš„å…·ä½“å»ºè®®
        error_counts = condensed_errors.get("error_count_by_type", {})
        
        if "è¯­æ³•é”™è¯¯" in error_counts:
            count = error_counts["è¯­æ³•é”™è¯¯"]
            suggestions.append(f"ğŸ”§ ä¿®å¤{count}ä¸ªè¯­æ³•é”™è¯¯ï¼šæ£€æŸ¥åˆ†å·ã€æ‹¬å·åŒ¹é…ã€å…³é”®å­—æ‹¼å†™")
            
            # ä»å…³é”®é”™è¯¯ä¸­æå–å…·ä½“çš„è¡Œå·ä¿¡æ¯
            syntax_errors = [e for e in condensed_errors.get("key_errors", []) 
                           if "syntax error" in e.lower()]
            if syntax_errors:
                first_error = syntax_errors[0]
                line_match = re.search(r':(\d+):', first_error)
                if line_match:
                    line_num = line_match.group(1)
                    suggestions.append(f"ğŸ“ ä»ç¬¬{line_num}è¡Œå¼€å§‹æ£€æŸ¥è¯­æ³•é—®é¢˜")
        
        if "ç«¯å£é”™è¯¯" in error_counts:
            count = error_counts["ç«¯å£é”™è¯¯"]
            suggestions.append(f"ğŸ”Œ ä¿®å¤{count}ä¸ªç«¯å£è¿æ¥é”™è¯¯ï¼šæ£€æŸ¥æ¨¡å—å®ä¾‹åŒ–å’Œç«¯å£åç§°")
        
        if "æœªå£°æ˜æ ‡è¯†ç¬¦" in error_counts:
            count = error_counts["æœªå£°æ˜æ ‡è¯†ç¬¦"]
            suggestions.append(f"ğŸ“‹ ä¿®å¤{count}ä¸ªæœªå£°æ˜å˜é‡ï¼šæ·»åŠ ä¿¡å·å£°æ˜è¯­å¥")
        
        # åŸºäºé”™è¯¯ç±»åˆ«çš„ç­–ç•¥å»ºè®®
        if error_category == "dependency_issue":
            suggestions.append("ğŸ” æ£€æŸ¥æ¨¡å—ä¾èµ–ï¼šç¡®ä¿æ‰€æœ‰å­æ¨¡å—éƒ½å·²å®šä¹‰")
        elif error_category == "syntax_issue":
            suggestions.append("ğŸ“ æ¨èï¼šä½¿ç”¨Verilogè¯­æ³•æ£€æŸ¥å™¨éªŒè¯ä»£ç ")
        elif error_category == "interface_issue":
            suggestions.append("ğŸ”Œ æ¨èï¼šæ£€æŸ¥æ¨¡å—ç«¯å£å®šä¹‰ä¸æµ‹è¯•å°å®ä¾‹åŒ–æ˜¯å¦åŒ¹é…")
        
        # åŸºäºæ¶‰åŠçš„æ–‡ä»¶æ•°é‡ç»™å‡ºå»ºè®®
        critical_files = condensed_errors.get("critical_files", [])
        if len(critical_files) > 1:
            file_names = ", ".join(critical_files[:3])
            suggestions.append(f"ğŸ“‚ æ¶‰åŠå¤šä¸ªæ–‡ä»¶çš„é”™è¯¯ï¼Œé‡ç‚¹æ£€æŸ¥: {file_names}")
        
        return suggestions[:5]  # é™åˆ¶å»ºè®®æ•°é‡ä¸º5ä¸ª
    
    def _perform_detailed_error_analysis(self, stderr: str) -> Dict[str, Any]:
        """æ‰§è¡Œè¯¦ç»†çš„é”™è¯¯åˆ†æ"""
        analysis = {
            "error_lines": [],
            "module_references": [],
            "file_references": [],
            "suggestions_context": {}
        }
        
        # æå–é”™è¯¯è¡Œ
        error_lines = [line.strip() for line in stderr.split('\n') if line.strip()]
        analysis["error_lines"] = error_lines[:10]  # ä¿ç•™å‰10è¡Œé”™è¯¯
        
        # æå–æ¨¡å—å¼•ç”¨
        module_pattern = r'(\w+)\s+(\w+)\s*\([^)]*\)\s*;'
        modules = re.findall(module_pattern, stderr)
        analysis["module_references"] = list(set([m[0] for m in modules]))
        
        # æå–æ–‡ä»¶å¼•ç”¨
        file_pattern = r'([^\s]+\.s?v):'
        files = re.findall(file_pattern, stderr)
        analysis["file_references"] = list(set(files))
        
        return analysis
    
    def _analyze_timeout_error(self, sim_result: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æè¶…æ—¶é”™è¯¯"""
        return {
            "test_summary": "â° ä»¿çœŸè¶…æ—¶",
            "failure_reasons": ["ä»¿çœŸæœªæ­£å¸¸ç»“æŸ"],
            "suggestions": [
                "åœ¨æµ‹è¯•å°ä¸­æ·»åŠ $finishè¯­å¥",
                "æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ— é™å¾ªç¯",
                "å‡å°‘ä»¿çœŸæ—¶é—´æˆ–å¢åŠ è¶…æ—¶é™åˆ¶"
            ]
        }
    
    def _analyze_runtime_errors(self, sim_result: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æè¿è¡Œæ—¶é”™è¯¯"""
        stderr = sim_result.get("simulation_stderr", "")
        
        return {
            "test_summary": "âŒ è¿è¡Œæ—¶é”™è¯¯",
            "failure_reasons": ["ä»¿çœŸæ‰§è¡Œå¤±è´¥"],
            "suggestions": [
                "æ£€æŸ¥æµ‹è¯•å°é€»è¾‘",
                "æŸ¥çœ‹é”™è¯¯è¾“å‡ºè·å–è¯¦ç»†ä¿¡æ¯",
                "ç¡®ä¿æ‰€æœ‰ä¿¡å·éƒ½æœ‰åˆå§‹å€¼"
            ],
            "error_details": stderr
        }
    
    def _analyze_successful_simulation(self, sim_result: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææˆåŠŸçš„ä»¿çœŸ"""
        stdout = sim_result.get("simulation_stdout", "")
        
        # æŸ¥æ‰¾æµ‹è¯•ç»“æœæŒ‡ç¤ºå™¨
        success_indicators = ["test passed", "all tests passed", "success", "pass"]
        failure_indicators = ["test failed", "fail", "error", "mismatch"]
        
        stdout_lower = stdout.lower()
        
        has_success = any(indicator in stdout_lower for indicator in success_indicators)
        has_failure = any(indicator in stdout_lower for indicator in failure_indicators)
        
        if has_success and not has_failure:
            return {
                "all_tests_passed": True,
                "test_summary": "âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡",
                "detailed_analysis": {"output_analysis": "å‘ç°æˆåŠŸæŒ‡ç¤ºå™¨"}
            }
        elif has_failure:
            return {
                "all_tests_passed": False,
                "test_summary": "âš ï¸ æµ‹è¯•å¤±è´¥",
                "failure_reasons": ["æµ‹è¯•ç”¨ä¾‹å¤±è´¥"],
                "suggestions": ["æ£€æŸ¥è®¾è®¡é€»è¾‘", "åˆ†ææµ‹è¯•å°è¾“å‡º"]
            }
        else:
            # æ²¡æœ‰æ˜ç¡®çš„æˆåŠŸ/å¤±è´¥æŒ‡ç¤ºå™¨ï¼Œéœ€è¦æ›´è¯¦ç»†åˆ†æ
            return {
                "all_tests_passed": True,  # å‡è®¾æˆåŠŸ
                "test_summary": "âœ… ä»¿çœŸå®Œæˆï¼ˆéœ€äººå·¥ç¡®è®¤ï¼‰",
                "detailed_analysis": {"output_analysis": "æœªå‘ç°æ˜ç¡®çš„æµ‹è¯•ç»“æœæŒ‡ç¤ºå™¨"},
                "suggestions": ["äººå·¥æ£€æŸ¥ä»¿çœŸè¾“å‡º"]
            }
    
    async def analyze_test_failures(self, test_results: Dict[str, Any],
                                  enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†ææµ‹è¯•å¤±è´¥å¹¶ç”Ÿæˆæ”¹è¿›å»ºè®® - å¢å¼ºé”™è¯¯å¤„ç†"""
        suggestions = []
        
        # æ£€æŸ¥æµ‹è¯•æ˜¯å¦æˆåŠŸæ‰§è¡Œ
        if not test_results.get("success", False):
            error_msg = test_results.get("error", "")
            
            # åˆ†æå…·ä½“çš„å¤±è´¥åŸå› 
            if "æ²¡æœ‰æ‰¾åˆ°è®¾è®¡æ–‡ä»¶" in error_msg:
                suggestions.append("ç¡®ä¿Verilogè®¾è®¡æ–‡ä»¶å·²æ­£ç¡®ç”Ÿæˆå¹¶ä¿å­˜")
                suggestions.append("æ£€æŸ¥æ–‡ä»¶å†™å…¥æ“ä½œæ˜¯å¦æˆåŠŸå®Œæˆ")
                suggestions.append("éªŒè¯è®¾è®¡æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            elif "ä»¿çœŸç¼–è¯‘å¤±è´¥" in error_msg or "ç¼–è¯‘é”™è¯¯" in error_msg:
                # æ£€æŸ¥å…·ä½“çš„ç¼–è¯‘é”™è¯¯ä¿¡æ¯
                compile_stderr = test_results.get("compile_stderr", "")
                if "rst_n" in compile_stderr and "not a port" in compile_stderr:
                    suggestions.append("âŒ å…³é”®é”™è¯¯ï¼šæ¨¡å—æ¥å£å®šä¹‰é”™è¯¯ - rst_nç«¯å£ä¸å­˜åœ¨")
                    suggestions.append("ğŸ”§ ä¿®å¤æ–¹æ¡ˆï¼šå°†æ¨¡å—ä¸­çš„'rst'ç«¯å£æ”¹ä¸º'rst_n'ï¼ˆè´Ÿç”µå¹³å¼‚æ­¥å¤ä½ï¼‰")
                    suggestions.append("âš ï¸ ç¡®ä¿å¤ä½é€»è¾‘ä½¿ç”¨negedge rst_nå’Œ!rst_næ¡ä»¶")
                elif "port" in compile_stderr and "not a port" in compile_stderr:
                    suggestions.append("âŒ ç«¯å£ä¸åŒ¹é…é”™è¯¯ï¼šæ£€æŸ¥æ¨¡å—ç«¯å£å®šä¹‰ä¸æµ‹è¯•å°å®ä¾‹åŒ–")
                    suggestions.append("ğŸ”§ ä»”ç»†æ¯”å¯¹æ¨¡å—å£°æ˜å’Œæµ‹è¯•å°è¿æ¥çš„ç«¯å£åç§°")
                else:
                    suggestions.append("ä¿®å¤Verilogä»£ç ä¸­çš„è¯­æ³•é”™è¯¯")
                    suggestions.append("æ£€æŸ¥æ¨¡å—ç«¯å£å®šä¹‰æ˜¯å¦ä¸æµ‹è¯•å°åŒ¹é…")
                    suggestions.append("ç¡®ä¿æ‰€æœ‰ä¿¡å·éƒ½å·²æ­£ç¡®å£°æ˜")
            elif "ä»¿çœŸæ‰§è¡Œå¤±è´¥" in error_msg:
                suggestions.append("æ£€æŸ¥æµ‹è¯•å°ä¸è®¾è®¡æ¨¡å—çš„è¿æ¥")
                suggestions.append("éªŒè¯æ—¶é’Ÿå’Œå¤ä½ä¿¡å·çš„æ­£ç¡®æ€§")
                suggestions.append("ç¡®ä¿æµ‹è¯•æ¿€åŠ±çš„å®Œæ•´æ€§")
            elif "æµ‹è¯•æ‰§è¡Œå¼‚å¸¸" in error_msg:
                suggestions.append("æ£€æŸ¥ç³»ç»Ÿç¯å¢ƒå’Œä»¿çœŸå·¥å…·é…ç½®")
                suggestions.append("ç¡®ä¿æ‰€æœ‰ä¾èµ–æ–‡ä»¶éƒ½å­˜åœ¨")
            else:
                # é€šç”¨å¤±è´¥å¤„ç†
                suggestions.append("æ£€æŸ¥ä¸Šä¸€é˜¶æ®µçš„å·¥å…·æ‰§è¡Œç»“æœ")
                suggestions.append("ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„æ–‡ä»¶éƒ½å·²æ­£ç¡®ç”Ÿæˆ")
                suggestions.append("éªŒè¯è®¾è®¡ä¸æµ‹è¯•å°çš„å…¼å®¹æ€§")
        
        # åŸºäºå…·ä½“å¤±è´¥åŸå› ç”Ÿæˆå»ºè®®
        failure_reasons = test_results.get("failure_reasons", [])
        for reason in failure_reasons:
            if "è¯­æ³•é”™è¯¯" in reason:
                suggestions.append("ä¿®å¤Verilogè¯­æ³•é”™è¯¯")
            elif "ç«¯å£ä¸åŒ¹é…" in reason:
                suggestions.append("ğŸ”§ æ£€æŸ¥å¹¶ä¿®æ­£æ¨¡å—ç«¯å£å®šä¹‰")
                suggestions.append("ğŸ“‹ ç¡®ä¿æ‰€æœ‰ç«¯å£åç§°ä¸æµ‹è¯•å°å®Œå…¨ä¸€è‡´")
            elif "æœªå£°æ˜çš„æ ‡è¯†ç¬¦" in reason:
                suggestions.append("æ·»åŠ ç¼ºå¤±çš„ä¿¡å·å£°æ˜")
            elif "æµ‹è¯•ç”¨ä¾‹å¤±è´¥" in reason:
                suggestions.append("æ£€æŸ¥è®¾è®¡é€»è¾‘ï¼Œç¡®ä¿æ»¡è¶³æµ‹è¯•å°è¦æ±‚")
        
        # åªåœ¨æµ‹è¯•å®é™…è¿è¡ŒæˆåŠŸä½†æœ‰å¤±è´¥æ—¶ï¼Œæ‰åŸºäºæµ‹è¯•å°ä¿¡æ¯ç”Ÿæˆå»ºè®®
        if (test_results.get("success", False) and 
            not test_results.get("all_tests_passed", False) and
            enhanced_analysis.get("testbench_validation", {}).get("module_info")):
            
            module_info = enhanced_analysis["testbench_validation"]["module_info"] 
            if module_info.get("dut_instances"):
                dut_info = module_info["dut_instances"][0]
                # åªæœ‰å½“æ¨¡å—åæ˜¯æœ‰æ•ˆçš„æ ‡è¯†ç¬¦æ—¶æ‰æ·»åŠ å»ºè®®
                module_name = dut_info.get('module', '')
                if module_name and module_name.isidentifier() and not module_name.startswith('_'):
                    suggestions.append(f"ç¡®ä¿è®¾è®¡æ¨¡å—åä¸º: {module_name}")
        
        # å»é‡å¹¶è¿‡æ»¤æ— æ•ˆå»ºè®®
        suggestions = list(dict.fromkeys(suggestions))  # å»é‡
        suggestions = [s for s in suggestions if s and len(s.strip()) > 5]  # è¿‡æ»¤æ— æ•ˆå»ºè®®
        
        result = {
            "suggestions": suggestions,
            "analysis_timestamp": asyncio.get_event_loop().time(),
            "failure_category": self._categorize_failures(failure_reasons),
            "has_actionable_suggestions": len(suggestions) > 0,
            "test_execution_success": test_results.get("success", False)
        }
        
        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ”¹è¿›å»ºè®®åˆ†æç»“æœ
        self.logger.info(f"ğŸ” DEBUG: åˆ†ææµ‹è¯•å¤±è´¥ï¼Œç”Ÿæˆæ”¹è¿›å»ºè®®")
        self.logger.info(f"ğŸ” DEBUG: å»ºè®®æ•°é‡: {len(suggestions)}")
        self.logger.info(f"ğŸ” DEBUG: å¤±è´¥ç±»åˆ«: {result['failure_category']}")
        for i, suggestion in enumerate(suggestions[:3]):
            self.logger.info(f"ğŸ” DEBUG: å»ºè®®{i+1}: {suggestion[:100]}...")
        
        return result
    
    def _categorize_failures(self, failure_reasons: List[str]) -> str:
        """å¯¹å¤±è´¥åŸå› è¿›è¡Œåˆ†ç±»"""
        if any("è¯­æ³•" in reason for reason in failure_reasons):
            return "syntax_error"
        elif any("ç«¯å£" in reason for reason in failure_reasons):
            return "interface_mismatch"
        elif any("æµ‹è¯•" in reason for reason in failure_reasons):
            return "logic_error"
        else:
            return "unknown"
    
    def _clean_design_files(self, file_paths: List[str]) -> List[str]:
        """æ¸…ç†è®¾è®¡æ–‡ä»¶ä¸­çš„æ ¼å¼é—®é¢˜ï¼Œä¿®å¤log-16.logä¸­å‘ç°çš„æ ¹æœ¬ç¼ºé™·"""
        cleaned_paths = []
        
        for original_path in file_paths:
            try:
                path_obj = Path(original_path)
                if not path_obj.exists():
                    self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡æ¸…ç†: {original_path}")
                    cleaned_paths.append(original_path)
                    continue
                
                # è¯»å–åŸå§‹æ–‡ä»¶å†…å®¹
                with open(path_obj, 'r', encoding='utf-8', errors='ignore') as f:
                    original_content = f.read()
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
                if self._needs_cleaning(original_content):
                    self.logger.info(f"ğŸ§¹ å‘ç°æ ¼å¼é—®é¢˜ï¼Œæ¸…ç†æ–‡ä»¶: {path_obj.name}")
                    
                    # æ‰§è¡Œæ¸…ç†
                    cleaned_content = self._clean_verilog_content(original_content)
                    
                    # åˆ›å»ºæ¸…ç†åçš„æ–‡ä»¶
                    cleaned_path = self._create_cleaned_file(path_obj, cleaned_content)
                    
                    if cleaned_path:
                        cleaned_paths.append(str(cleaned_path))
                        self.logger.info(f"âœ… æ–‡ä»¶æ¸…ç†å®Œæˆ: {cleaned_path}")
                    else:
                        cleaned_paths.append(original_path)
                else:
                    # æ–‡ä»¶æ— éœ€æ¸…ç†
                    cleaned_paths.append(original_path)
                    
            except Exception as e:
                self.logger.error(f"âŒ æ¸…ç†æ–‡ä»¶å¤±è´¥: {original_path}, é”™è¯¯: {e}")
                cleaned_paths.append(original_path)  # ä½¿ç”¨åŸå§‹æ–‡ä»¶
        
        return cleaned_paths
    
    def _needs_cleaning(self, content: str) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦éœ€è¦æ¸…ç†"""
        # æ£€æŸ¥æ˜¯å¦åŒ…å«Markdownä»£ç å—æ ‡è®°
        if "```verilog" in content or "```" in content:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«éVerilogçš„è¯´æ˜æ€§æ–‡å­—
        problem_patterns = [
            r"ä»¥ä¸‹æ˜¯.*çš„.*ä»£ç ",
            r"ç¬¦åˆ.*æ ‡å‡†",
            r"### è¯´æ˜ï¼š",
            r"### æ³¨æ„äº‹é¡¹ï¼š",
            r"æ¨¡å—åç§°.*ï¼š",
            r"è¾“å…¥ç«¯å£.*ï¼š",
            r"è¾“å‡ºç«¯å£.*ï¼š",
            r"å®ç°æ–¹å¼.*ï¼š",
        ]
        
        for pattern in problem_patterns:
            if re.search(pattern, content):
                return True
        
        return False
    
    def _clean_verilog_content(self, content: str) -> str:
        """æ¸…ç†Verilogå†…å®¹ï¼Œç§»é™¤éVerilogè¯­æ³•"""
        lines = content.split('\n')
        cleaned_lines = []
        in_verilog_block = False
        
        for line in lines:
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œ
            if not line:
                if in_verilog_block:
                    cleaned_lines.append('')
                continue
            
            # æ£€æµ‹Verilogä»£ç å—å¼€å§‹
            if line.startswith('```verilog'):
                in_verilog_block = True
                continue
            
            # æ£€æµ‹ä»£ç å—ç»“æŸ
            if line.startswith('```'):
                in_verilog_block = False
                continue
            
            # å¦‚æœåœ¨Verilogä»£ç å—ä¸­ï¼Œæˆ–è€…æ˜¯æœ‰æ•ˆçš„Verilogè¯­æ³•ï¼Œåˆ™ä¿ç•™
            if in_verilog_block or self._is_valid_verilog_line(line):
                cleaned_lines.append(line)
            else:
                # è·³è¿‡è¯´æ˜æ€§æ–‡å­—
                self.logger.debug(f"è·³è¿‡éVerilogè¡Œ: {line[:50]}...")
        
        return '\n'.join(cleaned_lines)
    
    def _is_valid_verilog_line(self, line: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆçš„Verilogä»£ç è¡Œ"""
        line = line.strip()
        
        # ç©ºè¡Œæˆ–æ³¨é‡Šè¡Œ
        if not line or line.startswith('//'):
            return True
        
        # Verilogå…³é”®å­—å¼€å¤´çš„è¡Œ
        verilog_keywords = [
            'module', 'endmodule', 'input', 'output', 'wire', 'reg',
            'always', 'initial', 'assign', 'if', 'else', 'begin', 'end',
            'for', 'while', 'case', 'endcase', 'function', 'endfunction',
            'task', 'endtask', 'generate', 'endgenerate', 'genvar',
            'parameter', 'localparam', 'integer'
        ]
        
        for keyword in verilog_keywords:
            if line.startswith(keyword):
                return True
        
        # èµ‹å€¼è¯­å¥æˆ–å®ä¾‹åŒ–
        if any(op in line for op in ['=', '<=', '(', ')', ';']):
            return True
        
        # é¢„å¤„ç†æŒ‡ä»¤
        if line.startswith('`'):
            return True
        
        return False
    
    def _create_cleaned_file(self, original_path: Path, cleaned_content: str) -> Optional[Path]:
        """åˆ›å»ºæ¸…ç†åçš„æ–‡ä»¶"""
        try:
            # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
            stem = original_path.stem
            suffix = original_path.suffix
            new_name = f"{stem}_cleaned{suffix}"
            cleaned_path = original_path.parent / new_name
            
            # å†™å…¥æ¸…ç†åçš„å†…å®¹
            with open(cleaned_path, 'w', encoding='utf-8') as f:
                f.write(cleaned_content)
            
            # éªŒè¯æ¸…ç†åçš„æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
            if self._validate_cleaned_file(cleaned_path):
                return cleaned_path
            else:
                self.logger.warning(f"âš ï¸ æ¸…ç†åçš„æ–‡ä»¶éªŒè¯å¤±è´¥: {cleaned_path}")
                cleaned_path.unlink()  # åˆ é™¤æ— æ•ˆæ–‡ä»¶
                return None
                
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºæ¸…ç†æ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _validate_cleaned_file(self, file_path: Path) -> bool:
        """éªŒè¯æ¸…ç†åçš„æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŸºæœ¬æ£€æŸ¥ï¼šå¿…é¡»åŒ…å«moduleå’Œendmodule
            if 'module ' not in content or 'endmodule' not in content:
                return False
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰Markdownæ®‹ç•™
            if '```' in content or '###' in content:
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰åŸºæœ¬çš„Verilogç»“æ„
            lines = [line.strip() for line in content.split('\n') if line.strip()]
            if len(lines) < 3:  # è‡³å°‘è¦æœ‰moduleå£°æ˜ã€ä¸€äº›å†…å®¹ã€endmodule
                return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ éªŒè¯æ–‡ä»¶å¤±è´¥: {e}")
            return False
    
    async def _check_design_files_separately(self, design_files: List[str]) -> Dict[str, Any]:
        """ç‹¬ç«‹æ£€æŸ¥è®¾è®¡æ–‡ä»¶"""
        self.logger.info(f"ğŸ” ç‹¬ç«‹æ£€æŸ¥è®¾è®¡æ–‡ä»¶ ({len(design_files)} ä¸ª)...")
        
        check_result = {
            "valid": True,
            "files_checked": len(design_files),
            "syntax_errors": [],
            "modules_found": [],
            "compilation_errors": [],
            "critical_issues": []
        }
        
        try:
            for design_file in design_files:
                self.logger.info(f"  ğŸ” æ£€æŸ¥è®¾è®¡æ–‡ä»¶: {Path(design_file).name}")
                
                # åŸºæœ¬è¯­æ³•æ£€æŸ¥
                syntax_check = await self._basic_syntax_check_file(design_file)
                if not syntax_check["valid"]:
                    check_result["syntax_errors"].extend(syntax_check["errors"])
                    check_result["valid"] = False
                
                # æ¨¡å—æå–
                modules = self._extract_modules_from_file(design_file)
                check_result["modules_found"].extend(modules)
                
                # ç‹¬ç«‹ç¼–è¯‘æ£€æŸ¥
                compile_check = await self._compile_single_file(design_file)
                if not compile_check["success"]:
                    check_result["compilation_errors"].extend(compile_check["errors"])
                    if compile_check.get("critical", False):
                        check_result["critical_issues"].extend(compile_check["errors"])
                        check_result["valid"] = False
            
            self.logger.info(f"  ğŸ“Š è®¾è®¡æ–‡ä»¶æ£€æŸ¥å®Œæˆ: æœ‰æ•ˆ={check_result['valid']}, æ¨¡å—æ•°={len(check_result['modules_found'])}")
            return check_result
            
        except Exception as e:
            self.logger.error(f"âŒ è®¾è®¡æ–‡ä»¶æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            check_result["valid"] = False
            check_result["critical_issues"].append(f"æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return check_result
    
    async def _check_testbench_file_separately(self, testbench_path: str) -> Dict[str, Any]:
        """ç‹¬ç«‹æ£€æŸ¥æµ‹è¯•å°æ–‡ä»¶"""
        self.logger.info(f"ğŸ” ç‹¬ç«‹æ£€æŸ¥æµ‹è¯•å°æ–‡ä»¶: {Path(testbench_path).name}")
        
        check_result = {
            "valid": True,
            "syntax_errors": [],
            "modules_found": [],
            "dut_instances": [],
            "compilation_errors": [],
            "critical_issues": []
        }
        
        try:
            # åŸºæœ¬è¯­æ³•æ£€æŸ¥
            syntax_check = await self._basic_syntax_check_file(testbench_path)
            if not syntax_check["valid"]:
                check_result["syntax_errors"].extend(syntax_check["errors"])
                check_result["valid"] = False
            
            # æ¨¡å—å’ŒDUTå®ä¾‹æå–
            modules = self._extract_modules_from_file(testbench_path)
            check_result["modules_found"].extend(modules)
            
            dut_instances = self._extract_dut_instances_from_file(testbench_path)
            check_result["dut_instances"].extend(dut_instances)
            
            # æµ‹è¯•å°ç‹¬ç«‹ç¼–è¯‘æ£€æŸ¥ï¼ˆå¿½ç•¥å¤–éƒ¨æ¨¡å—å¼•ç”¨ï¼‰
            compile_check = await self._compile_testbench_only(testbench_path)
            if not compile_check["success"]:
                # è¿‡æ»¤æ‰å¤–éƒ¨æ¨¡å—å¼•ç”¨é”™è¯¯
                filtered_errors = self._filter_testbench_errors(compile_check["errors"])
                check_result["compilation_errors"].extend(filtered_errors)
                
                # åªæœ‰ä¸¥é‡çš„è¯­æ³•é”™è¯¯æ‰æ ‡è®°ä¸ºæ— æ•ˆ
                critical_errors = [e for e in filtered_errors if "syntax" in e.lower()]
                if critical_errors:
                    check_result["critical_issues"].extend(critical_errors)
                    check_result["valid"] = False
            
            self.logger.info(f"  ğŸ“Š æµ‹è¯•å°æ£€æŸ¥å®Œæˆ: æœ‰æ•ˆ={check_result['valid']}, DUTå®ä¾‹æ•°={len(check_result['dut_instances'])}")
            return check_result
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•å°æ–‡ä»¶æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            check_result["valid"] = False
            check_result["critical_issues"].append(f"æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return check_result
    
    async def _basic_syntax_check_file(self, file_path: str) -> Dict[str, Any]:
        """å¯¹å•ä¸ªæ–‡ä»¶è¿›è¡ŒåŸºæœ¬è¯­æ³•æ£€æŸ¥"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            errors = []
            
            # æ£€æŸ¥åŸºæœ¬ç»“æ„
            if not re.search(r'module\s+\w+', content):
                errors.append("ç¼ºå°‘moduleå£°æ˜")
            
            if "endmodule" not in content:
                errors.append("ç¼ºå°‘endmodule")
            
            # æ£€æŸ¥æ‹¬å·åŒ¹é…
            if content.count('(') != content.count(')'):
                errors.append("æ‹¬å·ä¸åŒ¹é…")
            
            # æ£€æŸ¥begin/endåŒ¹é…
            begin_count = len(re.findall(r'\bbegin\b', content))
            end_count = len(re.findall(r'\bend\b', content))
            if begin_count != end_count:
                errors.append(f"begin/endä¸åŒ¹é… (begin: {begin_count}, end: {end_count})")
            
            return {
                "valid": len(errors) == 0,
                "errors": errors
            }
            
        except Exception as e:
            return {
                "valid": False,
                "errors": [f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}"]
            }
    
    def _extract_modules_from_file(self, file_path: str) -> List[str]:
        """ä»æ–‡ä»¶ä¸­æå–æ¨¡å—åç§°"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            modules = []
            module_matches = re.findall(r'module\s+(\w+)', content)
            modules.extend(module_matches)
            
            return modules
            
        except Exception as e:
            self.logger.error(f"æå–æ¨¡å—åç§°å¤±è´¥: {e}")
            return []
    
    def _extract_dut_instances_from_file(self, file_path: str) -> List[Dict[str, str]]:
        """ä»æµ‹è¯•å°æ–‡ä»¶ä¸­æå–DUTå®ä¾‹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            instances = []
            # åŒ¹é…æ¨¡å—å®ä¾‹åŒ–ï¼šmodule_name instance_name (port_connections);
            instance_pattern = r'(\w+)\s+(\w+)\s*\([^)]*\)\s*;'
            matches = re.findall(instance_pattern, content)
            
            for module_name, instance_name in matches:
                # æ’é™¤æµ‹è¯•å°æ¨¡å—è‡ªèº«
                if not any(tb_keyword in module_name.lower() 
                          for tb_keyword in ['tb_', 'test', 'bench']):
                    instances.append({
                        "module": module_name,
                        "instance": instance_name
                    })
            
            return instances
            
        except Exception as e:
            self.logger.error(f"æå–DUTå®ä¾‹å¤±è´¥: {e}")
            return []
    
    async def _compile_single_file(self, file_path: str) -> Dict[str, Any]:
        """ç‹¬ç«‹ç¼–è¯‘å•ä¸ªè®¾è®¡æ–‡ä»¶"""
        try:
            timestamp = int(asyncio.get_event_loop().time())
            output_file = self.temp_dir / f"design_check_{timestamp}"
            
            # ä½¿ç”¨iverilogè¿›è¡Œè¯­æ³•æ£€æŸ¥ï¼Œä¸ç”Ÿæˆå¯æ‰§è¡Œæ–‡ä»¶
            cmd = ["iverilog", "-t", "null", file_path]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            stderr_str = stderr.decode('utf-8', errors='ignore')
            
            errors = []
            critical = False
            
            if process.returncode != 0:
                error_lines = [line.strip() for line in stderr_str.split('\n') if line.strip()]
                errors.extend(error_lines)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ä¸¥é‡é”™è¯¯
                for error in error_lines:
                    if any(critical_keyword in error.lower() 
                          for critical_keyword in ['syntax error', 'parse error', 'malformed']):
                        critical = True
                        break
            
            return {
                "success": process.returncode == 0,
                "errors": errors,
                "critical": critical
            }
            
        except Exception as e:
            return {
                "success": False,
                "errors": [f"ç¼–è¯‘æ£€æŸ¥å¼‚å¸¸: {str(e)}"],
                "critical": True
            }
    
    async def _compile_testbench_only(self, testbench_path: str) -> Dict[str, Any]:
        """ä»…ç¼–è¯‘æµ‹è¯•å°æ–‡ä»¶ï¼ˆå¿½ç•¥å¤–éƒ¨æ¨¡å—å¼•ç”¨ï¼‰"""
        try:
            # å¯¹äºæµ‹è¯•å°ï¼Œæˆ‘ä»¬ä¸»è¦å…³æ³¨è¯­æ³•é”™è¯¯ï¼Œè€Œä¸æ˜¯æ¨¡å—å¼•ç”¨é”™è¯¯
            timestamp = int(asyncio.get_event_loop().time())
            
            # ä½¿ç”¨iverilogè¿›è¡Œè¯­æ³•æ£€æŸ¥
            cmd = ["iverilog", "-t", "null", testbench_path]
            
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            stderr_str = stderr.decode('utf-8', errors='ignore')
            
            errors = []
            if process.returncode != 0:
                error_lines = [line.strip() for line in stderr_str.split('\n') if line.strip()]
                errors.extend(error_lines)
            
            return {
                "success": process.returncode == 0,
                "errors": errors
            }
            
        except Exception as e:
            return {
                "success": False,
                "errors": [f"æµ‹è¯•å°ç¼–è¯‘æ£€æŸ¥å¼‚å¸¸: {str(e)}"]
            }
    
    def _filter_testbench_errors(self, errors: List[str]) -> List[str]:
        """è¿‡æ»¤æµ‹è¯•å°é”™è¯¯ï¼Œç§»é™¤å¤–éƒ¨æ¨¡å—å¼•ç”¨é”™è¯¯"""
        filtered = []
        
        for error in errors:
            # è·³è¿‡å¤–éƒ¨æ¨¡å—æœªæ‰¾åˆ°çš„é”™è¯¯
            if any(skip_keyword in error.lower() 
                  for skip_keyword in ['module', 'not found', 'undeclared']):
                continue
            
            # ä¿ç•™è¯­æ³•é”™è¯¯å’Œå…¶ä»–ä¸¥é‡é”™è¯¯
            if any(keep_keyword in error.lower() 
                  for keep_keyword in ['syntax', 'malformed', 'parse error']):
                filtered.append(error)
        
        return filtered
    
    async def _check_interface_compatibility(self, design_files: List[str], 
                                           testbench_path: str,
                                           design_check: Dict[str, Any],
                                           testbench_check: Dict[str, Any]) -> Dict[str, Any]:
        """æ£€æŸ¥æ¥å£å…¼å®¹æ€§"""
        self.logger.info("ğŸ” æ£€æŸ¥æ¥å£å…¼å®¹æ€§...")
        
        compatibility_result = {
            "compatible": True,
            "issues": [],
            "design_modules": design_check.get("modules_found", []),
            "testbench_modules": testbench_check.get("modules_found", []),
            "dut_instances": testbench_check.get("dut_instances", []),
            "module_matching": {}
        }
        
        try:
            design_modules = design_check.get("modules_found", [])
            dut_instances = testbench_check.get("dut_instances", [])
            
            # æ£€æŸ¥DUTå®ä¾‹æ˜¯å¦èƒ½æ‰¾åˆ°å¯¹åº”çš„è®¾è®¡æ¨¡å—
            for dut in dut_instances:
                dut_module = dut.get("module", "")
                if dut_module in design_modules:
                    compatibility_result["module_matching"][dut_module] = "found"
                else:
                    compatibility_result["module_matching"][dut_module] = "missing"
                    compatibility_result["issues"].append(
                        f"æµ‹è¯•å°ä¸­çš„æ¨¡å— '{dut_module}' åœ¨è®¾è®¡æ–‡ä»¶ä¸­æœªæ‰¾åˆ°"
                    )
                    compatibility_result["compatible"] = False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è®¾è®¡æ¨¡å—ä½†æ²¡æœ‰å¯¹åº”çš„æµ‹è¯•å°å®ä¾‹
            used_modules = [dut.get("module", "") for dut in dut_instances]
            for design_module in design_modules:
                if design_module not in used_modules:
                    compatibility_result["issues"].append(
                        f"è®¾è®¡æ¨¡å— '{design_module}' åœ¨æµ‹è¯•å°ä¸­æœªè¢«å®ä¾‹åŒ–"
                    )
            
            self.logger.info(f"  ğŸ“Š å…¼å®¹æ€§æ£€æŸ¥å®Œæˆ: å…¼å®¹={compatibility_result['compatible']}, é—®é¢˜æ•°={len(compatibility_result['issues'])}")
            return compatibility_result
            
        except Exception as e:
            self.logger.error(f"âŒ æ¥å£å…¼å®¹æ€§æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            compatibility_result["compatible"] = False
            compatibility_result["issues"].append(f"å…¼å®¹æ€§æ£€æŸ¥å¼‚å¸¸: {str(e)}")
            return compatibility_result
    
    def _generate_diagnosis_summary(self, design_check: Dict[str, Any], 
                                  testbench_check: Dict[str, Any],
                                  interface_check: Dict[str, Any]) -> Tuple[str, List[str], bool]:
        """ç”Ÿæˆè¯Šæ–­æ‘˜è¦å’Œå»ºè®®"""
        summary_parts = []
        suggestions = []
        should_proceed = True
        
        # è®¾è®¡æ–‡ä»¶è¯Šæ–­
        if not design_check.get("valid", True):
            summary_parts.append(f"âŒ è®¾è®¡æ–‡ä»¶å­˜åœ¨{len(design_check.get('critical_issues', []))}ä¸ªä¸¥é‡é—®é¢˜")
            suggestions.extend([
                "ğŸ”§ ä¼˜å…ˆä¿®å¤è®¾è®¡æ–‡ä»¶ä¸­çš„è¯­æ³•é”™è¯¯",
                "ğŸ“ æ£€æŸ¥æ¨¡å—å®šä¹‰å’ŒendmoduleåŒ¹é…"
            ])
            should_proceed = False
        else:
            summary_parts.append(f"âœ… è®¾è®¡æ–‡ä»¶è¯­æ³•æ£€æŸ¥é€šè¿‡ï¼ˆ{len(design_check.get('modules_found', []))}ä¸ªæ¨¡å—ï¼‰")
        
        # æµ‹è¯•å°æ–‡ä»¶è¯Šæ–­
        if not testbench_check.get("valid", True):
            summary_parts.append(f"âŒ æµ‹è¯•å°æ–‡ä»¶å­˜åœ¨{len(testbench_check.get('critical_issues', []))}ä¸ªä¸¥é‡é—®é¢˜")
            suggestions.extend([
                "ğŸ”§ ä¿®å¤æµ‹è¯•å°æ–‡ä»¶ä¸­çš„è¯­æ³•é”™è¯¯",
                "ğŸ” æ£€æŸ¥æµ‹è¯•å°ç»“æ„å’ŒDUTå®ä¾‹åŒ–"
            ])
            should_proceed = False
        else:
            summary_parts.append(f"âœ… æµ‹è¯•å°æ–‡ä»¶è¯­æ³•æ£€æŸ¥é€šè¿‡ï¼ˆ{len(testbench_check.get('dut_instances', []))}ä¸ªDUTå®ä¾‹ï¼‰")
        
        # æ¥å£å…¼å®¹æ€§è¯Šæ–­
        if interface_check and not interface_check.get("compatible", True):
            issue_count = len(interface_check.get("issues", []))
            summary_parts.append(f"âš ï¸ æ¥å£å…¼å®¹æ€§å­˜åœ¨{issue_count}ä¸ªé—®é¢˜")
            suggestions.extend([
                "ğŸ”Œ æ£€æŸ¥æ¨¡å—åç§°åŒ¹é…",
                "ğŸ“‹ éªŒè¯ç«¯å£è¿æ¥æ­£ç¡®æ€§"
            ])
            # æ¥å£é—®é¢˜ä¸é˜»æ­¢æ‰§è¡Œï¼Œä½†éœ€è¦ä¿®å¤
        elif interface_check:
            summary_parts.append("âœ… æ¥å£å…¼å®¹æ€§æ£€æŸ¥é€šè¿‡")
        
        # ç”Ÿæˆå…·ä½“å»ºè®®
        if design_check.get("critical_issues"):
            for issue in design_check["critical_issues"][:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                suggestions.append(f"ğŸ”§ è®¾è®¡æ–‡ä»¶: {issue}")
        
        if testbench_check.get("critical_issues"):
            for issue in testbench_check["critical_issues"][:2]:  # åªæ˜¾ç¤ºå‰2ä¸ª
                suggestions.append(f"ğŸ”§ æµ‹è¯•å°æ–‡ä»¶: {issue}")
        
        summary = " | ".join(summary_parts)
        
        return summary, suggestions[:5], should_proceed  # é™åˆ¶å»ºè®®æ•°é‡
    
    def _extract_failure_reasons(self, design_check: Dict[str, Any], 
                               testbench_check: Dict[str, Any]) -> List[str]:
        """ä»è¯Šæ–­ç»“æœä¸­æå–å¤±è´¥åŸå› """
        reasons = []
        
        if design_check.get("syntax_errors"):
            reasons.append("è®¾è®¡æ–‡ä»¶è¯­æ³•é”™è¯¯")
        
        if testbench_check.get("syntax_errors"):
            reasons.append("æµ‹è¯•å°è¯­æ³•é”™è¯¯")
        
        if design_check.get("critical_issues"):
            reasons.append("è®¾è®¡æ–‡ä»¶ä¸¥é‡é—®é¢˜")
        
        if testbench_check.get("critical_issues"):
            reasons.append("æµ‹è¯•å°ä¸¥é‡é—®é¢˜")
        
        return reasons
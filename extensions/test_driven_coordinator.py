#!/usr/bin/env python3
"""
æµ‹è¯•é©±åŠ¨åè°ƒå™¨ - å®Œå…¨ç‹¬ç«‹çš„æ‰©å±•åŠŸèƒ½

è¿™æ˜¯ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„æ‰©å±•æ¨¡å—ï¼Œä¸ä¿®æ”¹ä»»ä½•ç°æœ‰ä»£ç 
"""

import asyncio
import json
import re
import time
import logging
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass

# å¯¼å…¥ç°æœ‰æ¡†æ¶ç»„ä»¶ - åªè¯»å–ï¼Œä¸ä¿®æ”¹
from core.centralized_coordinator import CentralizedCoordinator
from core.enums import AgentCapability, AgentStatus
from config.config import FrameworkConfig
from core.context_manager import get_context_manager, FullContextManager
from core.base_agent import TaskMessage


@dataclass
class TestDrivenConfig:
    """æµ‹è¯•é©±åŠ¨é…ç½®"""
    max_iterations: int = 5
    enable_deep_analysis: bool = True
    auto_fix_suggestions: bool = True
    save_iteration_logs: bool = True
    timeout_per_iteration: int = 300  # 5åˆ†é’Ÿ


class TestDrivenCoordinator:
    """
    æµ‹è¯•é©±åŠ¨åè°ƒå™¨ - æ‰©å±•åŠŸèƒ½
    
    è¿™æ˜¯ä¸€ä¸ªè£…é¥°å™¨æ¨¡å¼çš„å®ç°ï¼ŒåŒ…è£…ç°æœ‰çš„CentralizedCoordinator
    è€Œä¸æ˜¯ç»§æ‰¿æˆ–ä¿®æ”¹å®ƒ
    """
    
    def __init__(self, base_coordinator: CentralizedCoordinator, 
                 config: TestDrivenConfig = None):
        """
        åˆå§‹åŒ–æµ‹è¯•é©±åŠ¨åè°ƒå™¨
        
        Args:
            base_coordinator: ç°æœ‰çš„åè°ƒå™¨å®ä¾‹ï¼ˆä¸ä¼šè¢«ä¿®æ”¹ï¼‰
            config: æµ‹è¯•é©±åŠ¨é…ç½®
        """
        self.base_coordinator = base_coordinator
        self.config = config or TestDrivenConfig()
        self.logger = logging.getLogger(f"{__name__}.TestDrivenCoordinator")
        
        # æ‰©å±•åŠŸèƒ½çŠ¶æ€
        self.test_driven_sessions = {}
        self.iteration_history = {}
        
        # ğŸ”— æŒç»­å¯¹è¯æœºåˆ¶ï¼šæ¯ä¸ªTDDä¼šè¯ä½¿ç”¨åŒä¸€ä¸ªå¯¹è¯ID
        self.persistent_conversation_id = None
        self.current_session_agents = {}  # è®°å½•æ¯ä¸ªä¼šè¯ä¸­ä½¿ç”¨çš„æ™ºèƒ½ä½“
        
        # ğŸ§  å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        self.context_manager: Optional[FullContextManager] = None
        
        # å¯¼å…¥æ‰©å±•è§£æå™¨
        from .enhanced_task_parser import EnhancedTaskParser
        from .test_analyzer import TestAnalyzer
        
        self.task_parser = EnhancedTaskParser()
        self.test_analyzer = TestAnalyzer()
        
        self.logger.info("ğŸ§ª æµ‹è¯•é©±åŠ¨åè°ƒå™¨æ‰©å±•å·²åˆå§‹åŒ–")
    
    # ==========================================
    # ğŸ¯ æ–°å¢çš„æµ‹è¯•é©±åŠ¨åŠŸèƒ½ï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰
    # ==========================================
    
    async def execute_test_driven_task(self, task_description: str,
                                     testbench_path: str = None,
                                     context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œæµ‹è¯•é©±åŠ¨ä»»åŠ¡ - æ–°å¢åŠŸèƒ½å…¥å£
        
        è¿™æ˜¯å®Œå…¨æ–°çš„åŠŸèƒ½ï¼Œä¸ä¼šå½±å“ç°æœ‰çš„coordinate_task_execution
        """
        session_id = f"tdd_{int(time.time())}"
        self.logger.info(f"ğŸš€ å¼€å§‹æµ‹è¯•é©±åŠ¨ä»»åŠ¡: {session_id}")
        
        # ğŸ§  åˆå§‹åŒ–å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        self.context_manager = get_context_manager(session_id)
        self.context_manager.global_context.update({
            "task_description": task_description,
            "testbench_path": testbench_path,
            "design_requirements": task_description
        })
        
        try:
            # 1. è§£æå¢å¼ºä»»åŠ¡éœ€æ±‚ï¼ˆå¼ºåˆ¶ä½œä¸ºTDDä»»åŠ¡ï¼‰
            enhanced_analysis = await self._parse_test_driven_requirements(
                task_description, testbench_path, context, force_tdd=True
            )
            
            if not enhanced_analysis["is_test_driven"]:
                # å¦‚æœä¸æ˜¯æµ‹è¯•é©±åŠ¨ä»»åŠ¡ï¼Œå›é€€åˆ°æ ‡å‡†æµç¨‹
                self.logger.info("ğŸ“‹ éæµ‹è¯•é©±åŠ¨ä»»åŠ¡ï¼Œä½¿ç”¨æ ‡å‡†æµç¨‹")
                return await self.base_coordinator.coordinate_task_execution(
                    task_description, context
                )
            
            # 2. éªŒè¯æµ‹è¯•å°ï¼ˆå¦‚æœæä¾›ï¼‰
            if enhanced_analysis.get("testbench_path"):
                validation = await self._validate_testbench(
                    enhanced_analysis["testbench_path"]
                )
                if not validation["valid"]:
                    return {
                        "success": False,
                        "error": f"æµ‹è¯•å°éªŒè¯å¤±è´¥: {validation['error']}",
                        "session_id": session_id
                    }
                enhanced_analysis["testbench_validation"] = validation
            
            # 3. æ‰§è¡Œæµ‹è¯•é©±åŠ¨å¾ªç¯
            result = await self._execute_tdd_loop(session_id, enhanced_analysis)
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•é©±åŠ¨ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id,
                "fallback_suggested": True
            }
    
    async def _parse_test_driven_requirements(self, task_description: str,
                                            testbench_path: str = None,
                                            context: Dict[str, Any] = None,
                                            force_tdd: bool = False) -> Dict[str, Any]:
        """è§£ææµ‹è¯•é©±åŠ¨éœ€æ±‚"""
        return await self.task_parser.parse_enhanced_task(
            task_description, testbench_path, context, force_tdd
        )
    
    async def _validate_testbench(self, testbench_path: str) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•å°æ–‡ä»¶"""
        return await self.test_analyzer.validate_testbench_file(testbench_path)
    
    async def _execute_tdd_loop(self, session_id: str, 
                              enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæµ‹è¯•é©±åŠ¨å¼€å‘å¾ªç¯"""
        self.test_driven_sessions[session_id] = {
            "start_time": time.time(),
            "analysis": enhanced_analysis,
            "iterations": [],
            "status": "running"
        }
        
        max_iterations = self.config.max_iterations
        current_iteration = 0
        final_result = None
        
        self.logger.info(f"ğŸ”„ å¼€å§‹TDDå¾ªç¯ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
        
        while current_iteration < max_iterations:
            current_iteration += 1
            iteration_start = time.time()
            
            self.logger.info(f"ğŸ”„ ç¬¬ {current_iteration}/{max_iterations} æ¬¡è¿­ä»£")
            
            # ğŸ§  å¼€å§‹æ–°çš„è¿­ä»£ï¼Œåˆå§‹åŒ–ä¸Šä¸‹æ–‡
            if self.context_manager:
                iteration_id = self.context_manager.start_new_iteration(current_iteration)
                self.logger.info(f"ğŸ§  åˆå§‹åŒ–è¿­ä»£ä¸Šä¸‹æ–‡: {iteration_id}")
            
            # æ‰§è¡Œå•æ¬¡è¿­ä»£
            iteration_result = await self._execute_single_tdd_iteration(
                session_id, current_iteration, enhanced_analysis
            )
            
            # è®°å½•è¿­ä»£ç»“æœ
            self.test_driven_sessions[session_id]["iterations"].append({
                "iteration": current_iteration,
                "start_time": iteration_start,
                "duration": time.time() - iteration_start,
                "result": iteration_result
            })
            
            # ğŸ¯ æ–°å¢ï¼šä»æ¯æ¬¡è¿­ä»£ä¸­æå–ç»éªŒæ•™è®­ï¼ˆæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼‰
            if self.context_manager:
                # ä»ç¼–è¯‘é”™è¯¯ä¸­å­¦ä¹ 
                test_results = iteration_result.get("test_results", {})
                if test_results.get("compile_stderr"):
                    # è§£æç¼–è¯‘é”™è¯¯å¹¶æå–æ•™è®­
                    compilation_errors = self._parse_compilation_errors(test_results["compile_stderr"])
                    self.context_manager.add_compilation_errors(compilation_errors)
                    self.logger.info(f"ğŸ¯ ä»è¿­ä»£{current_iteration}æå–äº†{len(compilation_errors)}ä¸ªç¼–è¯‘é”™è¯¯æ•™è®­")
                
                # å¦‚æœæˆåŠŸï¼Œæå–æˆåŠŸæ¨¡å¼
                if iteration_result.get("all_tests_passed", False):
                    self.context_manager.extract_success_patterns(iteration_result)
                    self.logger.info(f"ğŸ¯ ä»è¿­ä»£{current_iteration}æå–äº†æˆåŠŸæ¨¡å¼")
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            if iteration_result.get("all_tests_passed", False):
                self.logger.info(f"âœ… ç¬¬ {current_iteration} æ¬¡è¿­ä»£æˆåŠŸï¼")
                
                # ğŸ¯ æ–°å¢ï¼šæå–æˆåŠŸç»éªŒ
                if self.context_manager:
                    self.context_manager.extract_success_patterns(iteration_result)
                    self.logger.info("ğŸ¯ æˆåŠŸç»éªŒå·²æå–å¹¶ç´¯ç§¯")
                
                final_result = {
                    "success": True,
                    "session_id": session_id,
                    "total_iterations": current_iteration,
                    "final_design": iteration_result.get("design_files", []),
                    "test_results": iteration_result.get("test_results", {}),
                    "completion_reason": "tests_passed"
                }
                break
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡è¿­ä»£ï¼Œå‡†å¤‡æ”¹è¿›å»ºè®®
            if current_iteration < max_iterations:
                improvement_analysis = await self._analyze_for_improvement(
                    iteration_result, enhanced_analysis
                )
                enhanced_analysis["improvement_suggestions"] = improvement_analysis.get("suggestions", [])
                
                # ä¿å­˜å…·ä½“çš„é”™è¯¯ä¿¡æ¯ä»¥ä¼ é€’ç»™ä¸‹æ¬¡è¿­ä»£
                test_results = iteration_result.get("test_results", {})
                if not test_results.get("all_tests_passed", False):
                    # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šåˆ†ææµ‹è¯•ç»“æœå†…å®¹
                    self.logger.info(f"ğŸ” DEBUG: æµ‹è¯•å¤±è´¥ï¼Œåˆ†æé”™è¯¯ä¿¡æ¯ä¼ é€’")
                    self.logger.info(f"ğŸ” test_results keys: {list(test_results.keys())}")
                    
                    # ä¿å­˜ç¼–è¯‘é”™è¯¯ä¿¡æ¯
                    if "compile_stderr" in test_results:
                        stderr_content = test_results["compile_stderr"]
                        enhanced_analysis["last_compilation_errors"] = stderr_content
                        self.logger.info(f"ğŸ” DEBUG: ä¿å­˜ç¼–è¯‘é”™è¯¯ä¿¡æ¯: {stderr_content[:200]}...")
                        
                        # ğŸ§  è§£æå¹¶ä¿å­˜ç¼–è¯‘é”™è¯¯åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                        if self.context_manager:
                            compilation_errors = self._parse_compilation_errors(stderr_content)
                            self.context_manager.add_compilation_errors(compilation_errors)
                            self.logger.info(f"ğŸ§  ä¸Šä¸‹æ–‡ç®¡ç†å™¨: ä¿å­˜äº†{len(compilation_errors)}ä¸ªç¼–è¯‘é”™è¯¯")
                    
                    # ä¿å­˜å¤±è´¥åŸå› 
                    if "failure_reasons" in test_results:
                        failure_reasons = test_results["failure_reasons"]
                        enhanced_analysis["last_failure_reasons"] = failure_reasons
                        self.logger.info(f"ğŸ” DEBUG: ä¿å­˜å¤±è´¥åŸå› : {failure_reasons}")
                    
                    # ä¿å­˜é”™è¯¯ç±»åˆ«
                    if "error_category" in test_results:
                        error_category = test_results["error_category"]
                        enhanced_analysis["last_error_category"] = error_category
                        self.logger.info(f"ğŸ” DEBUG: ä¿å­˜é”™è¯¯ç±»åˆ«: {error_category}")
                    
                    # ğŸ§  ä¿å­˜æµ‹è¯•ç»“æœåˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                    if self.context_manager and self.context_manager.current_iteration:
                        self.context_manager.current_iteration.simulation_results = test_results
                        self.context_manager.current_iteration.compilation_success = test_results.get("compile_success", False)
                        self.context_manager.current_iteration.simulation_success = test_results.get("simulation_success", False)
                        self.context_manager.current_iteration.all_tests_passed = test_results.get("all_tests_passed", False)
                    
                    # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥improved_analysiså†…å®¹
                    self.logger.info(f"ğŸ” DEBUG: improvement_analysis keys: {list(improvement_analysis.keys())}")
                    if "suggestions" in improvement_analysis:
                        self.logger.info(f"ğŸ” DEBUG: æ”¹è¿›å»ºè®®æ•°é‡: {len(improvement_analysis['suggestions'])}")
                        for i, suggestion in enumerate(improvement_analysis["suggestions"][:3]):
                            self.logger.info(f"ğŸ” DEBUG: å»ºè®®{i+1}: {suggestion[:100]}...")
        
        # å¦‚æœå¾ªç¯ç»“æŸä»æœªæˆåŠŸ
        if final_result is None:
            self.logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}")
            
            # ä»æœ€åä¸€æ¬¡è¿­ä»£ä¸­è·å–è®¾è®¡æ–‡ä»¶
            last_iteration = self.test_driven_sessions[session_id]["iterations"][-1] if self.test_driven_sessions[session_id]["iterations"] else {}
            final_design_files = last_iteration.get("result", {}).get("design_files", [])
            
            final_result = {
                "success": False,
                "session_id": session_id,
                "total_iterations": max_iterations,
                "final_design": final_design_files,
                "completion_reason": "max_iterations_reached",
                "error": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä½†æµ‹è¯•ä»æœªå…¨éƒ¨é€šè¿‡",
                "partial_results": self.test_driven_sessions[session_id]["iterations"]
            }
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        self.test_driven_sessions[session_id]["status"] = "completed"
        self.test_driven_sessions[session_id]["final_result"] = final_result
        
        # ğŸ§  ä¿å­˜å®Œæ•´ä¸Šä¸‹æ–‡åˆ°æ–‡ä»¶
        if self.context_manager:
            context_file_path = f"tdd_context_{session_id}.json"
            try:
                self.context_manager.save_to_file(context_file_path)
                self.logger.info(f"ğŸ§  ä¿å­˜å®Œæ•´ä¸Šä¸‹æ–‡åˆ°: {context_file_path}")
                
                # å°†ä¸Šä¸‹æ–‡æ–‡ä»¶è·¯å¾„æ·»åŠ åˆ°æœ€ç»ˆç»“æœä¸­
                final_result["context_file"] = context_file_path
            except Exception as e:
                self.logger.error(f"âŒ ä¿å­˜ä¸Šä¸‹æ–‡æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        return final_result
    
    async def _execute_single_tdd_iteration(self, session_id: str, iteration: int,
                                          enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•æ¬¡TDDè¿­ä»£"""
        self.logger.info(f"ğŸ¯ æ‰§è¡Œç¬¬ {iteration} æ¬¡è¿­ä»£")
        
        try:
            # é˜¶æ®µ1: è®¾è®¡ç”Ÿæˆ/ä¿®æ”¹
            design_result = await self._execute_design_phase(
                session_id, iteration, enhanced_analysis
            )
            
            if not design_result.get("success", False):
                return {
                    "success": False,
                    "phase": "design",
                    "error": design_result.get("error", "è®¾è®¡é˜¶æ®µå¤±è´¥"),
                    "all_tests_passed": False
                }
            
            # ä»è®¾è®¡ç»“æœä¸­æå–æ–‡ä»¶å¼•ç”¨ï¼ˆå¢å¼ºç‰ˆï¼‰
            design_files = self._extract_file_references(design_result)
            
            # é˜¶æ®µ2: æµ‹è¯•æ‰§è¡Œ
            test_result = await self._execute_test_phase(
                session_id, iteration, design_result, enhanced_analysis, design_files
            )
            
            # åˆå¹¶ç»“æœ
            return {
                "success": True,
                "design_files": design_files,
                "test_results": test_result,
                "all_tests_passed": test_result.get("all_tests_passed", False),
                "iteration": iteration
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ç¬¬ {iteration} æ¬¡è¿­ä»£å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "all_tests_passed": False,
                "iteration": iteration
            }
    
    async def _execute_design_phase(self, session_id: str, iteration: int,
                                  enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè®¾è®¡é˜¶æ®µ - ä½¿ç”¨ç°æœ‰åè°ƒå™¨åŠŸèƒ½"""
        self.logger.info(f"ğŸ¨ è®¾è®¡é˜¶æ®µ - è¿­ä»£ {iteration}")
        
        # æ„å»ºè®¾è®¡ä»»åŠ¡
        design_task = await self._build_design_task(enhanced_analysis, iteration)
        
        # ğŸ”§ ä¿®å¤ï¼šåœ¨TDDåœºæ™¯ä¸­ï¼Œå¼ºåˆ¶æŒ‡å®šè¿™æ˜¯è®¾è®¡ä»»åŠ¡ï¼Œé¿å…è¢«è¯¯åˆ¤ä¸ºreviewä»»åŠ¡
        tdd_context = enhanced_analysis.get("context", {}).copy()
        tdd_context["force_task_type"] = "design"  # å¼ºåˆ¶æŒ‡å®šä¸ºè®¾è®¡ä»»åŠ¡
        tdd_context["preferred_agent_role"] = "verilog_designer"  # ä¼˜å…ˆé€‰æ‹©Verilogè®¾è®¡æ™ºèƒ½ä½“
        
        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å¼ºåˆ¶ä»»åŠ¡ç±»å‹
        self.logger.info(f"ğŸ”§ DEBUG: TDDè®¾è®¡é˜¶æ®µ - å¼ºåˆ¶ä»»åŠ¡ç±»å‹ä¸ºdesignï¼Œä¼˜å…ˆagent: verilog_designer")
        
        # ğŸ”— ä½¿ç”¨æŒç»­å¯¹è¯æœºåˆ¶
        if iteration == 1:
            # ç¬¬ä¸€æ¬¡è¿­ä»£ï¼šåˆ›å»ºæ–°çš„æŒç»­å¯¹è¯
            self.persistent_conversation_id = f"tdd_{session_id}_{int(time.time())}"
            self.logger.info(f"ğŸ”— åˆ›å»ºæŒç»­å¯¹è¯ID: {self.persistent_conversation_id}")
            
            # ä½¿ç”¨ç°æœ‰åè°ƒå™¨æ‰§è¡Œè®¾è®¡ä»»åŠ¡
            result = await self.base_coordinator.coordinate_task_execution(
                design_task, tdd_context
            )
            
            # è®°å½•æœ¬æ¬¡ä¼šè¯ä½¿ç”¨çš„æ™ºèƒ½ä½“ï¼Œç”¨äºåç»­è¿­ä»£
            if result.get("success", False):
                # ä»åè°ƒå™¨è·å–é€‰æ‹©çš„æ™ºèƒ½ä½“ä¿¡æ¯
                if hasattr(self.base_coordinator, 'current_conversation_participants'):
                    participants = self.base_coordinator.current_conversation_participants
                    self.current_session_agents = {
                        'verilog_designer': participants.get('primary_agent_id', 'enhanced_real_verilog_agent')
                    }
                    self.logger.info(f"ğŸ”— è®°å½•ä¼šè¯æ™ºèƒ½ä½“: {self.current_session_agents}")
                else:
                    # é»˜è®¤ä½¿ç”¨verilogè®¾è®¡æ™ºèƒ½ä½“
                    self.current_session_agents = {
                        'verilog_designer': 'enhanced_real_verilog_agent'
                    }
        else:
            # åç»­è¿­ä»£ï¼šç»§ç»­ç°æœ‰å¯¹è¯
            self.logger.info(f"ğŸ”— ç»§ç»­æŒç»­å¯¹è¯: {self.persistent_conversation_id}")
            
            # ç›´æ¥å‘å·²é€‰æ‹©çš„æ™ºèƒ½ä½“å‘é€ä»»åŠ¡ï¼Œè€Œä¸æ˜¯é‡æ–°é€‰æ‹©
            result = await self._continue_persistent_conversation(
                design_task, tdd_context, iteration
            )
        
        return result
    
    async def _execute_test_phase(self, session_id: str, iteration: int,
                                design_result: Dict[str, Any],
                                enhanced_analysis: Dict[str, Any],
                                design_files: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """æ‰§è¡Œæµ‹è¯•é˜¶æ®µ - å¢å¼ºç‰ˆï¼šä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        self.logger.info(f"ğŸ§ª æµ‹è¯•é˜¶æ®µ - è¿­ä»£ {iteration}")
        
        # æ™ºèƒ½é€‰æ‹©æµ‹è¯•æ‰§è¡Œæ–¹å¼
        user_testbench_path = enhanced_analysis.get("testbench_path")
        
        # ä»å½“å‰è¿­ä»£çš„æ–‡ä»¶ä¸­æŸ¥æ‰¾ç”Ÿæˆçš„æµ‹è¯•å°
        current_iteration_testbench = None
        if design_files:
            for file_ref in design_files:
                if (isinstance(file_ref, dict) and 
                    file_ref.get("file_type") == "testbench" and 
                    file_ref.get("file_path")):
                    current_iteration_testbench = file_ref["file_path"]
                    self.logger.info(f"ğŸ¯ æ‰¾åˆ°å½“å‰è¿­ä»£æµ‹è¯•å°: {current_iteration_testbench}")
                    break
        
        # ç»Ÿä¸€çš„æ™ºèƒ½testbenché€‰æ‹©ç­–ç•¥
        testbench_strategy = self._determine_testbench_strategy(
            iteration, user_testbench_path, current_iteration_testbench
        )
        
        testbench_to_use = testbench_strategy["selected_testbench"]
        self.logger.info(f"ğŸ¯ ç¬¬{iteration}æ¬¡è¿­ä»£ï¼Œtestbenchç­–ç•¥: {testbench_strategy['strategy']}")
        self.logger.info(f"ğŸ“ ç­–ç•¥è¯´æ˜: {testbench_strategy['reason']}")
        
        if testbench_to_use:
            # ä½¿ç”¨æŒ‡å®šçš„æµ‹è¯•å°ï¼ˆç”¨æˆ·æŒ‡å®šæˆ–å½“å‰è¿­ä»£ç”Ÿæˆï¼‰
            self.logger.info(f"ğŸ§ª ä½¿ç”¨æµ‹è¯•å°æ–‡ä»¶: {testbench_to_use}")
            
            # ä¸¥æ ¼å‡†å¤‡è®¾è®¡æ–‡ä»¶åˆ—è¡¨ï¼ˆæ’é™¤æµ‹è¯•å°æ–‡ä»¶ï¼Œç¡®ä¿æ–‡ä»¶å­˜åœ¨ï¼‰
            design_only_files = []
            if design_files is None:
                design_files = design_result.get("file_references", design_result.get("design_files", []))
            
            self.logger.info(f"ğŸ” å‡†å¤‡è®¾è®¡æ–‡ä»¶ï¼Œè¾“å…¥æ–‡ä»¶æ€»æ•°: {len(design_files) if design_files else 0}")
            
            for i, file_ref in enumerate(design_files):
                if isinstance(file_ref, dict):
                    file_path = file_ref.get("file_path")
                    file_type = file_ref.get("file_type")
                    filename = Path(file_path).name if file_path else "unknown"
                    
                    self.logger.info(f"  æ–‡ä»¶{i+1}: {filename} (ç±»å‹: {file_type}, è·¯å¾„: {file_path})")
                    
                    # éªŒè¯æ˜¯è®¾è®¡æ–‡ä»¶ï¼ˆéæµ‹è¯•å°ï¼‰ä¸”æ–‡ä»¶å­˜åœ¨
                    if (file_type == "verilog" and 
                        file_path and 
                        Path(file_path).exists() and
                        not any(keyword in filename.lower() for keyword in ['_tb.v', 'testbench', '_test'])):
                        
                        design_only_files.append(file_ref)
                        self.logger.info(f"  âœ… é€‰æ‹©è®¾è®¡æ–‡ä»¶: {filename}")
                        
                        # ğŸ§  å°†è®¾è®¡æ–‡ä»¶æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
                        if self.context_manager:
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    module_name = self._extract_module_name(content)
                                    self.context_manager.add_code_file(
                                        file_path=file_path,
                                        content=content,
                                        module_name=module_name or "unknown",
                                        file_type="design"
                                    )
                                    self.logger.info(f"ğŸ§  ä¸Šä¸‹æ–‡ç®¡ç†å™¨: æ·»åŠ è®¾è®¡æ–‡ä»¶ {file_path} (æ¨¡å—: {module_name})")
                            except Exception as e:
                                self.logger.error(f"âŒ è¯»å–è®¾è®¡æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
                    else:
                        reason = "æœªçŸ¥åŸå› "
                        if file_type != "verilog":
                            reason = f"æ–‡ä»¶ç±»å‹ä¸æ˜¯verilog ({file_type})"
                        elif not file_path:
                            reason = "æ–‡ä»¶è·¯å¾„ä¸ºç©º"
                        elif not Path(file_path).exists():
                            reason = "æ–‡ä»¶ä¸å­˜åœ¨"
                        elif any(keyword in filename.lower() for keyword in ['_tb.v', 'testbench', '_test']):
                            reason = "æ˜¯æµ‹è¯•å°æ–‡ä»¶"
                        self.logger.info(f"  â­ï¸ è·³è¿‡æ–‡ä»¶: {filename} ({reason})")
            
            self.logger.info(f"ğŸ¯ æœ€ç»ˆé€‰æ‹©çš„è®¾è®¡æ–‡ä»¶æ•°é‡: {len(design_only_files)}")
            
            # ğŸ§  ä¸ºæµ‹è¯•åˆ†æå™¨ä¼ é€’å®Œæ•´ä¸Šä¸‹æ–‡
            if self.context_manager:
                test_context = self.context_manager.get_full_context_for_agent(
                    "code_reviewer", 
                    "æµ‹è¯•éªŒè¯ä»»åŠ¡"
                )
                self.logger.info(f"ğŸ§  ä¸ºæµ‹è¯•åˆ†æå™¨ä¼ é€’å®Œæ•´ä¸Šä¸‹æ–‡: "
                               f"{len(test_context.get('complete_conversation_history', []))}è½®å¯¹è¯å†å²")
                
                # å°†ä¸Šä¸‹æ–‡æ·»åŠ åˆ°æµ‹è¯•åˆ†æå™¨çš„å‚æ•°ä¸­
                enhanced_analysis["full_test_context"] = test_context
            
            return await self.test_analyzer.run_with_user_testbench(
                design_only_files,
                testbench_to_use
            )
        else:
            # å›é€€åˆ°æ ‡å‡†æµ‹è¯•æµç¨‹ï¼ˆç”Ÿæˆæ–°çš„æµ‹è¯•å°ï¼‰
            self.logger.info("ğŸ”„ æœªæ‰¾åˆ°æµ‹è¯•å°æ–‡ä»¶ï¼Œä½¿ç”¨æ ‡å‡†æµ‹è¯•æµç¨‹ç”Ÿæˆæµ‹è¯•å°")
            test_task = self._build_test_task(design_result, enhanced_analysis)
            
            # ğŸ§  ä¸ºæµ‹è¯•Agentä¼ é€’å®Œæ•´ä¸Šä¸‹æ–‡
            test_context = enhanced_analysis.get("context", {}).copy()
            if self.context_manager:
                full_context = self.context_manager.get_full_context_for_agent(
                    "code_reviewer", 
                    "æµ‹è¯•éªŒè¯ä»»åŠ¡"
                )
                test_context["full_conversation_context"] = full_context
                self.logger.info(f"ğŸ§  ä¸ºæµ‹è¯•Agentä¼ é€’å®Œæ•´ä¸Šä¸‹æ–‡: "
                               f"{len(full_context.get('complete_conversation_history', []))}è½®å¯¹è¯å†å²")
            
            result = await self.base_coordinator.coordinate_task_execution(
                test_task, test_context
            )
            return result
    
    async def _analyze_for_improvement(self, iteration_result: Dict[str, Any],
                                     enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¹¶ç”Ÿæˆæ”¹è¿›å»ºè®® - å¢å¼ºç‰ˆï¼šä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        
        # ğŸ§  ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨æä¾›çš„å†å²ä¿¡æ¯è¿›è¡Œæ™ºèƒ½åˆ†æ
        if self.context_manager:
            full_context = self.context_manager.get_full_context_for_agent(
                "analyzer", 
                "é”™è¯¯åˆ†æä»»åŠ¡"
            )
            
            # å°†å®Œæ•´ä¸Šä¸‹æ–‡æ·»åŠ åˆ°åˆ†æå‚æ•°ä¸­
            enhanced_analysis["full_analysis_context"] = full_context
            
            # è®°å½•ä¸Šä¸‹æ–‡ä¿¡æ¯ç”¨äºåˆ†æ
            conversation_history = full_context.get("complete_conversation_history", [])
            previous_iterations = full_context.get("previous_iterations_summary", [])
            error_context = full_context.get("detailed_error_context", {})
            
            self.logger.info(f"ğŸ§  é”™è¯¯åˆ†æä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡: "
                           f"{len(conversation_history)}è½®å¯¹è¯å†å², "
                           f"{len(previous_iterations)}æ¬¡å†å²è¿­ä»£, "
                           f"{len(error_context.get('compilation_errors', []))}ä¸ªç¼–è¯‘é”™è¯¯")
            
            # åŸºäºå†å²æ¨¡å¼è¿›è¡Œæ™ºèƒ½åˆ†æ
            if previous_iterations:
                # åˆ†æå†å²å¤±è´¥æ¨¡å¼
                failure_patterns = self._analyze_failure_patterns(previous_iterations)
                enhanced_analysis["failure_patterns"] = failure_patterns
                self.logger.info(f"ğŸ§  è¯†åˆ«åˆ°å¤±è´¥æ¨¡å¼: {failure_patterns}")
            
            # åŸºäºå¯¹è¯å†å²åˆ†æAIè¡Œä¸ºæ¨¡å¼
            if conversation_history:
                behavior_patterns = self._analyze_ai_behavior_patterns(conversation_history)
                enhanced_analysis["behavior_patterns"] = behavior_patterns
                self.logger.info(f"ğŸ§  è¯†åˆ«åˆ°AIè¡Œä¸ºæ¨¡å¼: {behavior_patterns}")
        
        return await self.test_analyzer.analyze_test_failures(
            iteration_result.get("test_results", {}),
            enhanced_analysis
        )
    
    def _analyze_failure_patterns(self, previous_iterations: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æå†å²å¤±è´¥æ¨¡å¼"""
        patterns = {
            "repeated_errors": [],
            "error_evolution": [],
            "success_patterns": [],
            "common_fixes": []
        }
        
        for iteration in previous_iterations:
            failures = iteration.get("main_failures", [])
            lessons = iteration.get("lessons_learned", [])
            
            # è®°å½•é‡å¤é”™è¯¯
            for failure in failures:
                if failure not in patterns["repeated_errors"]:
                    patterns["repeated_errors"].append(failure)
            
            # è®°å½•é”™è¯¯æ¼”è¿›
            patterns["error_evolution"].append({
                "iteration": iteration["iteration_number"],
                "failures": failures,
                "lessons": lessons
            })
            
            # è®°å½•æˆåŠŸæ¨¡å¼
            if iteration.get("all_tests_passed", False):
                patterns["success_patterns"].append({
                    "iteration": iteration["iteration_number"],
                    "key_factors": lessons
                })
        
        return patterns
    
    def _analyze_ai_behavior_patterns(self, conversation_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†æAIè¡Œä¸ºæ¨¡å¼"""
        patterns = {
            "tool_usage_patterns": {},
            "decision_patterns": [],
            "error_response_patterns": [],
            "success_strategies": []
        }
        
        for turn in conversation_history:
            tool_calls = turn.get("tool_calls", [])
            ai_response = turn.get("ai_response", "")
            
            # åˆ†æå·¥å…·ä½¿ç”¨æ¨¡å¼
            for tool_call in tool_calls:
                tool_name = tool_call.get("tool_name", "unknown")
                if tool_name not in patterns["tool_usage_patterns"]:
                    patterns["tool_usage_patterns"][tool_name] = 0
                patterns["tool_usage_patterns"][tool_name] += 1
            
            # åˆ†æå†³ç­–æ¨¡å¼
            if any(keyword in ai_response for keyword in ["å†³å®š", "é€‰æ‹©", "é‡‡ç”¨", "ä¿®æ”¹"]):
                patterns["decision_patterns"].append({
                    "iteration": turn.get("iteration_number", 0),
                    "decision": ai_response[:200] + "..." if len(ai_response) > 200 else ai_response
                })
            
            # åˆ†æé”™è¯¯å“åº”æ¨¡å¼
            if not turn.get("success", True):
                patterns["error_response_patterns"].append({
                    "iteration": turn.get("iteration_number", 0),
                    "error_type": turn.get("error_info", {}).get("type", "unknown"),
                    "response": ai_response[:200] + "..." if len(ai_response) > 200 else ai_response
                })
        
        return patterns
    
    async def _build_design_task(self, enhanced_analysis: Dict[str, Any], iteration: int) -> str:
        """æ„å»ºè®¾è®¡ä»»åŠ¡æè¿° - ä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        base_requirements = enhanced_analysis.get("design_requirements", "")
        
        task = f"è®¾è®¡ä»»åŠ¡ (è¿­ä»£ {iteration}):\n\n{base_requirements}\n\n"
        
        # ğŸ¯ æ–°å¢ï¼šæ³¨å…¥æˆåŠŸç»éªŒæŒ‡å¯¼
        if self.context_manager and iteration > 1:
            success_context = self.context_manager.build_success_context_for_agent()
            task += success_context
        
        # ğŸ§  ä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨è·å–å…¨é‡ä¿¡æ¯
        if self.context_manager and iteration > 1:
            full_context = self.context_manager.get_full_context_for_agent(
                "verilog_designer", 
                f"è®¾è®¡ä»»åŠ¡è¿­ä»£{iteration}"
            )
            
            # 1. å®Œæ•´ä»£ç å†…å®¹ä¼ é€’
            code_content = full_context.get("complete_code_content", {})
            if code_content.get("design_files"):
                task += "ğŸ“„ **å®Œæ•´DUTä»£ç å†…å®¹** (åŒ…å«æ‰€æœ‰å†å²ç‰ˆæœ¬å’Œé”™è¯¯å®šä½):\n"
                for file_path, file_info in code_content["design_files"].items():
                    task += f"\n### æ–‡ä»¶: {file_path} (æ¨¡å—: {file_info['module_name']})\n"
                    task += f"```verilog\n{file_info['content_with_line_numbers']}\n```\n"
                    
                    # å¦‚æœæœ‰é”™è¯¯è¡Œï¼Œç‰¹åˆ«æ ‡æ³¨
                    if file_info.get("error_lines"):
                        task += "\nğŸš¨ **é”™è¯¯è¡Œæ ‡æ³¨**:\n"
                        for line_num, line_content in file_info["error_lines"].items():
                            task += f"  è¡Œ {line_num}: {line_content}\n"
                    task += "\n"
            
            # 2. å®Œæ•´å¯¹è¯å†å²ä¼ é€’
            conversation_history = full_context.get("complete_conversation_history", [])
            if conversation_history:
                task += "ğŸ—£ï¸ **å®Œæ•´å¯¹è¯å†å²** (åŒ…å«æ‰€æœ‰AIæ¨ç†è¿‡ç¨‹):\n"
                for turn in conversation_history[-3:]:  # åªæ˜¾ç¤ºæœ€è¿‘3è½®å¯¹è¯
                    task += f"\n#### è¿­ä»£{turn['iteration_number']} - {turn['agent_id']}:\n"
                    task += f"**AIå“åº”**: {turn['ai_response'][:300]}...\n"
                    if turn.get('reasoning_notes'):
                        task += f"**æ¨ç†ç¬”è®°**: {turn['reasoning_notes']}\n"
                    if turn.get('tool_calls'):
                        task += f"**å·¥å…·è°ƒç”¨**: {len(turn['tool_calls'])}ä¸ªå·¥å…·\n"
                task += "\n"
            
            # 3. è¯¦ç»†é”™è¯¯ä¸Šä¸‹æ–‡
            error_context = full_context.get("detailed_error_context", {})
            if error_context.get("compilation_errors"):
                task += "ğŸ” **è¯¦ç»†é”™è¯¯åˆ†æ** (åŒ…å«ä»£ç ä¸Šä¸‹æ–‡):\n"
                for error in error_context["compilation_errors"]:
                    task += f"\n- é”™è¯¯: {error.get('message', 'Unknown')}\n"
                    task += f"  æ–‡ä»¶: {error.get('file', 'Unknown')}, è¡Œ: {error.get('line', 'Unknown')}\n"
                    if error.get('error_line_content'):
                        task += f"  é”™è¯¯è¡Œå†…å®¹: {error['error_line_content']}\n"
                    if error.get('error_context'):
                        task += f"  ä¸Šä¸‹æ–‡:\n{error['error_context']}\n"
                task += "\n"
            
            # 4. å¤šagentåä½œå†å²
            collaboration_history = full_context.get("agent_collaboration_history", {})
            if collaboration_history.get("agent_interactions"):
                task += "ğŸ¤ **Agentåä½œå†å²**:\n"
                for interaction in collaboration_history["agent_interactions"]:
                    task += f"- è¿­ä»£{interaction['iteration_number']}: {', '.join(interaction['agents'])}\n"
                    task += f"  ç»“æœ: {interaction['context']['outcome']}\n"
                task += "\n"
            
            # 5. å†å²è¿­ä»£ç»éªŒæ•™è®­
            previous_iterations = full_context.get("previous_iterations_summary", [])
            if previous_iterations:
                task += "ğŸ“š **å†å²è¿­ä»£ç»éªŒæ•™è®­**:\n"
                for prev_iter in previous_iterations[-2:]:  # æœ€è¿‘2æ¬¡è¿­ä»£
                    task += f"\n### è¿­ä»£{prev_iter['iteration_number']}:\n"
                    task += f"- ç¼–è¯‘æˆåŠŸ: {prev_iter['compilation_success']}\n"
                    task += f"- ä¸»è¦å¤±è´¥åŸå› : {', '.join(prev_iter.get('main_failures', []))}\n"
                    task += f"- ç»éªŒæ•™è®­: {'; '.join(prev_iter.get('lessons_learned', []))}\n"
                task += "\n"
            
            # 6. ğŸ§  åŸºäºå†å²æ¨¡å¼çš„æ™ºèƒ½å»ºè®®
            failure_patterns = enhanced_analysis.get("failure_patterns", {})
            behavior_patterns = enhanced_analysis.get("behavior_patterns", {})
            
            if failure_patterns:
                task += "ğŸ¯ **åŸºäºå†å²æ¨¡å¼çš„æ™ºèƒ½å»ºè®®**:\n"
                
                # é‡å¤é”™è¯¯è­¦å‘Š
                repeated_errors = failure_patterns.get("repeated_errors", [])
                if repeated_errors:
                    task += f"\nâš ï¸ **é‡å¤é”™è¯¯è­¦å‘Š**: ä»¥ä¸‹é”™è¯¯åœ¨å†å²è¿­ä»£ä¸­é‡å¤å‡ºç°:\n"
                    for error in repeated_errors:
                        task += f"   - {error}\n"
                    task += "   è¯·ç‰¹åˆ«æ³¨æ„é¿å…è¿™äº›é”™è¯¯ï¼\n"
                
                # æˆåŠŸæ¨¡å¼å»ºè®®
                success_patterns = failure_patterns.get("success_patterns", [])
                if success_patterns:
                    task += f"\nâœ… **æˆåŠŸæ¨¡å¼å»ºè®®**: å‚è€ƒä»¥ä¸‹æˆåŠŸç­–ç•¥:\n"
                    for pattern in success_patterns:
                        task += f"   - è¿­ä»£{pattern['iteration']}: {', '.join(pattern.get('key_factors', []))}\n"
            
            if behavior_patterns:
                task += "\nğŸ¤– **AIè¡Œä¸ºæ¨¡å¼åˆ†æ**:\n"
                
                # å·¥å…·ä½¿ç”¨æ¨¡å¼
                tool_patterns = behavior_patterns.get("tool_usage_patterns", {})
                if tool_patterns:
                    task += f"- å¸¸ç”¨å·¥å…·: {', '.join([f'{tool}({count})' for tool, count in tool_patterns.items()])}\n"
                
                # å†³ç­–æ¨¡å¼
                decision_patterns = behavior_patterns.get("decision_patterns", [])
                if decision_patterns:
                    task += f"- å†å²å†³ç­–æ•°é‡: {len(decision_patterns)}\n"
                    for decision in decision_patterns[-2:]:  # æœ€è¿‘2ä¸ªå†³ç­–
                        task += f"  - è¿­ä»£{decision['iteration']}: {decision['decision']}\n"
            
            self.logger.info(f"ğŸ§  å®Œæ•´ä¸Šä¸‹æ–‡ä¼ é€’: åŒ…å«{len(conversation_history)}è½®å¯¹è¯ï¼Œ{len(code_content.get('design_files', {}))}ä¸ªä»£ç æ–‡ä»¶")
        
        else:
            # ç¬¬ä¸€æ¬¡è¿­ä»£ï¼Œæ·»åŠ åŸºç¡€æŒ‡å¯¼
            task += "âœ¨ **é¦–æ¬¡è®¾è®¡æŒ‡å¯¼**:\n"
            task += "- è¯·ä»”ç»†åˆ†æéœ€æ±‚ï¼Œè®¾è®¡ç¬¦åˆæ¥å£è§„èŒƒçš„ä»£ç \n"
            task += "- æ³¨æ„ä½¿ç”¨æ­£ç¡®çš„Verilogè¯­æ³•ï¼Œé¿å…SystemVerilogç‰¹æ€§\n"
            task += "- ç¡®ä¿æ‰€æœ‰ç«¯å£å®šä¹‰æ­£ç¡®åŒ¹é…\n\n"
        
        if iteration > 1:
            # ğŸ”§ å¢å¼ºé”™è¯¯ä¿®å¤æŒ‡å¯¼ï¼šä»£ç éªŒè¯ + æ·±åº¦åˆ†æ
            task += "\n\nğŸ”§ **ä¸¥æ ¼ä»£ç éªŒè¯è¦æ±‚**:\n"
            task += "1. **ç¼–è¯‘å™¨å…¼å®¹æ€§ (iverilog - Verilog-2001æ ‡å‡†)**:\n"
            task += "   âŒ ç¦æ­¢ï¼šlogicç±»å‹ã€interfaceã€generateå†…å¤æ‚é€»è¾‘ã€assertè¯­å¥\n"
            task += "   âœ… åªç”¨ï¼šwireã€regã€assignã€always@(*)\n"
            task += "2. **çº¯ç»„åˆé€»è¾‘éªŒè¯**:\n"
            task += "   âŒ ä¸¥ç¦ï¼šclkã€rstã€@(posedge)ã€output regé…åˆalways@(posedge)\n"
            task += "   âœ… å¿…é¡»ï¼šoutput wireé…åˆassignï¼Œæˆ–output regé…åˆalways@(*)\n"
            task += "3. **æ¥å£ä¸¥æ ¼åŒ¹é…**:\n"
            task += f"   - æ¨¡å—åå¿…é¡»å®Œå…¨åŒ¹é…æµ‹è¯•å°å®ä¾‹åŒ–\n"
            task += f"   - ç«¯å£åå¿…é¡»ä¸æµ‹è¯•å°è¿æ¥ä¸€è‡´\n\n"
                
            # æ·»åŠ æ·±åº¦åˆ†æçš„é”™è¯¯åé¦ˆä¿¡æ¯
            last_errors = enhanced_analysis.get("last_compilation_errors", "")
            last_test_results = enhanced_analysis.get("last_test_results", "")
            
            if last_errors:
                # æ˜¾ç¤ºåŸå§‹é”™è¯¯ä¿¡æ¯ï¼ˆä¿æŒå®Œæ•´ä¸Šä¸‹æ–‡ï¼‰
                task += "ğŸš¨ **ä¸Šæ¬¡ç¼–è¯‘é”™è¯¯è¯¦æƒ…**:\n"
                task += f"```\n{last_errors}\n```\n\n"
            
            if last_test_results:
                # æ˜¾ç¤ºæµ‹è¯•å¤±è´¥è¯¦æƒ…
                task += "ğŸ§ª **ä¸Šæ¬¡æµ‹è¯•å¤±è´¥è¯¦æƒ…**:\n"
                task += f"```\n{last_test_results}\n```\n\n"
            
            # æ·»åŠ æ”¹è¿›å»ºè®®
            improvement_suggestions = enhanced_analysis.get("improvement_suggestions", [])
            if improvement_suggestions:
                task += "ğŸ’¡ **æ”¹è¿›å»ºè®®**:\n"
                for i, suggestion in enumerate(improvement_suggestions, 1):
                    task += f"{i}. {suggestion}\n"
                task += "\n"
        
        return task
    
    def _build_test_task(self, design_result: Dict[str, Any],
                        enhanced_analysis: Dict[str, Any]) -> str:
        """æ„å»ºæµ‹è¯•ä»»åŠ¡æè¿°"""
        design_files = design_result.get("design_files", [])
        testbench_path = enhanced_analysis.get("testbench_path")
        
        task = "æµ‹è¯•éªŒè¯ä»»åŠ¡:\n\n"
        task += f"è®¾è®¡æ–‡ä»¶: {[f.get('file_path', str(f)) for f in design_files]}\n"
        
        if testbench_path:
            task += f"ä½¿ç”¨æŒ‡å®šæµ‹è¯•å°: {testbench_path}\n"
        else:
            task += "ç”Ÿæˆé€‚å½“çš„æµ‹è¯•å°å¹¶è¿›è¡ŒéªŒè¯\n"
        
        task += "\nè¯·è¿è¡Œæµ‹è¯•å¹¶æŠ¥å‘Šç»“æœã€‚"
        
        return task
    
    # ==========================================
    # ğŸ” ä¼šè¯ç®¡ç†å’ŒæŸ¥è¯¢åŠŸèƒ½
    # ==========================================
    
    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–æµ‹è¯•é©±åŠ¨ä¼šè¯ä¿¡æ¯"""
        return self.test_driven_sessions.get(session_id)
    
    def list_active_sessions(self) -> List[str]:
        """åˆ—å‡ºæ´»è·ƒçš„æµ‹è¯•é©±åŠ¨ä¼šè¯"""
        return [sid for sid, info in self.test_driven_sessions.items() 
                if info.get("status") == "running"]
    
    def get_iteration_history(self, session_id: str) -> List[Dict[str, Any]]:
        """è·å–è¿­ä»£å†å²"""
        return self.test_driven_sessions.get(session_id, {}).get("iterations", [])
    
    def load_context_from_file(self, context_file_path: str) -> bool:
        """ä»æ–‡ä»¶åŠ è½½ä¸Šä¸‹æ–‡"""
        try:
            if self.context_manager:
                self.context_manager.load_from_file(context_file_path)
                self.logger.info(f"ğŸ§  æˆåŠŸåŠ è½½ä¸Šä¸‹æ–‡æ–‡ä»¶: {context_file_path}")
                return True
            else:
                self.logger.error("âŒ ä¸Šä¸‹æ–‡ç®¡ç†å™¨æœªåˆå§‹åŒ–")
                return False
        except Exception as e:
            self.logger.error(f"âŒ åŠ è½½ä¸Šä¸‹æ–‡æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False
    
    def get_context_statistics(self, session_id: str) -> Dict[str, Any]:
        """è·å–ä¸Šä¸‹æ–‡ç»Ÿè®¡ä¿¡æ¯"""
        if not self.context_manager:
            return {"error": "ä¸Šä¸‹æ–‡ç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        
        stats = {
            "session_id": session_id,
            "total_iterations": len(self.context_manager.iterations),
            "current_iteration": self.context_manager.current_iteration.iteration_number if self.context_manager.current_iteration else 0,
            "total_conversation_turns": 0,
            "total_code_files": 0,
            "total_testbench_files": 0,
            "compilation_errors_count": 0,
            "successful_iterations": 0,
            "failed_iterations": 0
        }
        
        # ç»Ÿè®¡æ‰€æœ‰è¿­ä»£çš„ä¿¡æ¯
        for iteration_id, iteration in self.context_manager.iterations.items():
            stats["total_conversation_turns"] += len(iteration.conversation_turns)
            stats["total_code_files"] += len(iteration.code_files)
            stats["total_testbench_files"] += len(iteration.testbench_files)
            
            if iteration.compilation_errors:
                stats["compilation_errors_count"] += len(iteration.compilation_errors)
            
            if iteration.all_tests_passed:
                stats["successful_iterations"] += 1
            else:
                stats["failed_iterations"] += 1
        
        return stats
    
    def export_context_summary(self, session_id: str) -> Dict[str, Any]:
        """å¯¼å‡ºä¸Šä¸‹æ–‡æ‘˜è¦"""
        if not self.context_manager:
            return {"error": "ä¸Šä¸‹æ–‡ç®¡ç†å™¨æœªåˆå§‹åŒ–"}
        
        summary = {
            "session_id": session_id,
            "statistics": self.get_context_statistics(session_id),
            "key_insights": [],
            "recommendations": []
        }
        
        # åˆ†æå…³é”®æ´å¯Ÿ
        if self.context_manager.current_iteration:
            current_iter = self.context_manager.current_iteration
            
            # åˆ†æå¤±è´¥æ¨¡å¼
            if current_iter.compilation_errors:
                error_types = set()
                for error in current_iter.compilation_errors:
                    if 'type' in error:
                        error_types.add(error['type'])
                
                if error_types:
                    summary["key_insights"].append({
                        "type": "compilation_errors",
                        "message": f"ä¸»è¦é”™è¯¯ç±»å‹: {', '.join(error_types)}",
                        "count": len(current_iter.compilation_errors)
                    })
            
            # åˆ†æå¯¹è¯æ¨¡å¼
            if current_iter.conversation_turns:
                agents_used = set(turn.agent_id for turn in current_iter.conversation_turns)
                summary["key_insights"].append({
                    "type": "agent_collaboration",
                    "message": f"ä½¿ç”¨çš„æ™ºèƒ½ä½“: {', '.join(agents_used)}",
                    "turn_count": len(current_iter.conversation_turns)
                })
        
        # ç”Ÿæˆå»ºè®®
        stats = summary["statistics"]
        if stats["failed_iterations"] > stats["successful_iterations"]:
            summary["recommendations"].append({
                "priority": "high",
                "message": "å¤±è´¥è¿­ä»£è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥é”™è¯¯æ¨¡å¼å’Œä¿®å¤ç­–ç•¥"
            })
        
        if stats["compilation_errors_count"] > 0:
            summary["recommendations"].append({
                "priority": "medium",
                "message": f"å­˜åœ¨{stats['compilation_errors_count']}ä¸ªç¼–è¯‘é”™è¯¯ï¼Œéœ€è¦è¯­æ³•æ£€æŸ¥"
            })
        
        return summary
    
    # ==========================================
    # ğŸ­ ä»£ç†æ–¹æ³• - ä¿æŒä¸ç°æœ‰åè°ƒå™¨çš„å®Œå…¨å…¼å®¹
    # ==========================================
    
    async def coordinate_task_execution(self, initial_task: str,
                                      context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ä»£ç†åŸæœ‰çš„coordinate_task_executionæ–¹æ³•
        
        ä¿æŒå®Œå…¨å‘åå…¼å®¹ï¼Œç°æœ‰ä»£ç æ— éœ€ä»»ä½•ä¿®æ”¹
        """
        return await self.base_coordinator.coordinate_task_execution(initial_task, context)
    
    def register_agent(self, agent):
        """ä»£ç†æ™ºèƒ½ä½“æ³¨å†Œ"""
        return self.base_coordinator.register_agent(agent)
    
    def get_registered_agents(self):
        """ä»£ç†è·å–å·²æ³¨å†Œæ™ºèƒ½ä½“"""
        return self.base_coordinator.get_registered_agents()
    
    # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šä»£ç†æ–¹æ³•...
    
    def _extract_file_references(self, agent_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»æ™ºèƒ½ä½“ç»“æœä¸­æå–æ–‡ä»¶å¼•ç”¨ï¼ˆç»Ÿä¸€ç­–ç•¥ç‰ˆï¼‰"""
        file_references = []
        
        # ğŸ¯ ç­–ç•¥1ï¼šä¼˜å…ˆä»å·¥å…·è°ƒç”¨ç»“æœä¸­æå–æ–‡ä»¶å¼•ç”¨ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if "tool_results" in agent_result:
            for tool_result in agent_result["tool_results"]:
                if isinstance(tool_result, dict) and tool_result.get("success"):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ä»¶å¼•ç”¨ä¿¡æ¯
                    if "file_reference" in tool_result:
                        file_references.append(tool_result["file_reference"])
                        self.logger.info(f"âœ… ä»å·¥å…·ç»“æœæå–æ–‡ä»¶å¼•ç”¨: {tool_result['file_reference'].get('file_path', 'unknown')}")
                    elif "file_path" in tool_result and tool_result.get("file_path"):
                        # æ„å»ºå®Œæ•´çš„æ–‡ä»¶å¼•ç”¨æ ¼å¼
                        file_ref = {
                            "file_path": tool_result["file_path"],
                            "file_type": tool_result.get("file_type", "verilog"),
                            "file_id": tool_result.get("file_id"),
                            "created_by": tool_result.get("created_by"),
                            "created_at": tool_result.get("created_at"),
                            "description": tool_result.get("description", "")
                        }
                        file_references.append(file_ref)
                        self.logger.info(f"âœ… æ„å»ºæ–‡ä»¶å¼•ç”¨: {file_ref['file_path']} (ç±»å‹: {file_ref['file_type']})")
        
        # ğŸ¯ ç­–ç•¥2ï¼šä»ä¼ ç»Ÿæ ¼å¼ä¸­æå–ï¼ˆä¸­ç­‰ä¼˜å…ˆçº§ï¼‰
        legacy_formats = ["file_references", "design_files"]
        for format_key in legacy_formats:
            if format_key in agent_result and agent_result[format_key]:
                file_references.extend(agent_result[format_key])
                self.logger.info(f"âœ… ä»{format_key}æå– {len(agent_result[format_key])} ä¸ªæ–‡ä»¶å¼•ç”¨")
        
        # ğŸ¯ ç­–ç•¥3ï¼šæ™ºèƒ½ä»ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨è·å–ï¼ˆä»…åœ¨å‰ä¸¤ç§ç­–ç•¥éƒ½å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        if not file_references:
            self.logger.warning("âš ï¸ å·¥å…·ç»“æœä¸­æœªæ‰¾åˆ°æ–‡ä»¶å¼•ç”¨ï¼Œå°è¯•ä»ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨è·å–")
            file_references = self._intelligent_file_retrieval_from_manager()
        
        # ğŸ¯ ç­–ç•¥4ï¼šæ–‡ä»¶å¼•ç”¨å»é‡å’ŒéªŒè¯
        validated_references = self._validate_and_deduplicate_file_references(file_references)
        
        # ğŸ§  å°†è®¾è®¡æ–‡ä»¶æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ç®¡ç†å™¨
        if self.context_manager:
            for file_ref in validated_references:
                if isinstance(file_ref, dict) and 'file_path' in file_ref:
                    file_path = file_ref['file_path']
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            module_name = self._extract_module_name(content)
                            self.context_manager.add_code_file(
                                file_path=file_path,
                                content=content,
                                module_name=module_name or "unknown",
                                file_type="design"
                            )
                            self.logger.info(f"ğŸ§  ä¸Šä¸‹æ–‡ç®¡ç†å™¨: æ·»åŠ è®¾è®¡æ–‡ä»¶ {file_path} (æ¨¡å—: {module_name})")
                    except Exception as e:
                        self.logger.error(f"âŒ è¯»å–è®¾è®¡æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
        
        self.logger.info(f"ğŸ“„ æœ€ç»ˆæå–åˆ° {len(validated_references)} ä¸ªæœ‰æ•ˆæ–‡ä»¶å¼•ç”¨")
        return validated_references
    
    def _intelligent_file_retrieval_from_manager(self) -> List[Dict[str, Any]]:
        """æ™ºèƒ½ä»ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨è·å–æ–‡ä»¶ï¼ˆå¤‡ç”¨ç­–ç•¥ï¼‰"""
        file_references = []
        
        try:
            from core.file_manager import get_file_manager
            file_manager = get_file_manager()
            
            # ğŸ¯ ç²¾ç¡®ç­–ç•¥ï¼šåªè·å–æœ€è¿‘5åˆ†é’Ÿå†…åˆ›å»ºçš„æ–‡ä»¶ï¼Œé¿å…å†å²æ±¡æŸ“
            import datetime
            recent_cutoff = (datetime.datetime.now() - datetime.timedelta(minutes=5)).isoformat()
            
            # ğŸ¯ é‡ç‚¹å…³æ³¨å½“å‰TDDè¿­ä»£ç›¸å…³çš„æ™ºèƒ½ä½“
            priority_agents = ["enhanced_real_verilog_agent", "real_verilog_agent"]
            current_iteration_files = []
            
            for agent_id in priority_agents:
                try:
                    agent_files = file_manager.get_files_by_creator(agent_id)
                    # åªå–æœ€è¿‘5åˆ†é’Ÿçš„æ–‡ä»¶
                    recent_files = [f for f in agent_files if f.created_at > recent_cutoff]
                    current_iteration_files.extend(recent_files)
                    self.logger.debug(f"ä» {agent_id} è·å–åˆ° {len(recent_files)} ä¸ªæœ€è¿‘æ–‡ä»¶")
                except Exception as e:
                    self.logger.debug(f"è·å– {agent_id} æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
            current_iteration_files.sort(key=lambda x: x.created_at, reverse=True)
            
            # ğŸ¯ ä¸¥æ ¼é€‰æ‹©ï¼šæ¯ç§ç±»å‹åªé€‰æ‹©1ä¸ªæœ€æ–°çš„ã€æ–‡ä»¶åä¸é‡å¤çš„æ–‡ä»¶
            selected_designs = {}  # module_name -> file_ref
            selected_testbenches = {}  # module_name -> file_ref
            
            for file_ref in current_iteration_files:
                filename = Path(file_ref.file_path).name
                module_name = Path(file_ref.file_path).stem
                
                # ç§»é™¤å¸¸è§çš„åç¼€æ¥è·å–æ ¸å¿ƒæ¨¡å—å
                for suffix in ['_tb', '_test', '_testbench']:
                    if module_name.endswith(suffix):
                        module_name = module_name[:-len(suffix)]
                        break
                
                # åˆ†ç±»å¤„ç†
                is_testbench = any(keyword in filename.lower() for keyword in ['_tb.v', 'testbench', '_test'])
                
                if not is_testbench and file_ref.file_type == "verilog":
                    # è®¾è®¡æ–‡ä»¶ï¼šæ¯ä¸ªæ¨¡å—åªä¿ç•™æœ€æ–°çš„
                    if module_name not in selected_designs:
                        selected_designs[module_name] = file_ref
                        self.logger.info(f"ğŸ¯ é€‰æ‹©è®¾è®¡æ–‡ä»¶: {filename} (æ¨¡å—: {module_name})")
                elif is_testbench and file_ref.file_type in ["verilog", "testbench"]:
                    # æµ‹è¯•å°æ–‡ä»¶ï¼šæ¯ä¸ªæ¨¡å—åªä¿ç•™æœ€æ–°çš„
                    if module_name not in selected_testbenches:
                        selected_testbenches[module_name] = file_ref
                        self.logger.info(f"ğŸ¯ é€‰æ‹©æµ‹è¯•å°æ–‡ä»¶: {filename} (æ¨¡å—: {module_name})")
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            for file_ref in list(selected_designs.values()) + list(selected_testbenches.values()):
                file_references.append({
                    "file_id": file_ref.file_id,
                    "file_path": file_ref.file_path,
                    "file_type": file_ref.file_type,
                    "created_by": file_ref.created_by,
                    "created_at": file_ref.created_at,
                    "description": file_ref.description
                })
            
            self.logger.info(f"ğŸ” æ™ºèƒ½é€‰æ‹©: {len(selected_designs)} ä¸ªè®¾è®¡æ–‡ä»¶, {len(selected_testbenches)} ä¸ªæµ‹è¯•å°æ–‡ä»¶")
            
        except Exception as e:
            self.logger.error(f"âŒ ä»ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨è·å–æ–‡ä»¶å¤±è´¥: {e}")
        
        return file_references
    
    def _validate_and_deduplicate_file_references(self, file_references: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """éªŒè¯å¹¶å»é‡æ–‡ä»¶å¼•ç”¨ï¼Œæ™ºèƒ½é€‰æ‹©æœ€æ–°ç‰ˆæœ¬"""
        validated_refs = []
        seen_paths = set()
        seen_file_ids = set()
        
        # ğŸ¯ æŒ‰æ¨¡å—ååˆ†ç»„ï¼Œæ¯ä¸ªæ¨¡å—åªä¿ç•™æœ€æ–°çš„è®¾è®¡æ–‡ä»¶
        module_files = {}  # module_name -> [file_refs]
        
        for file_ref in file_references:
            if not isinstance(file_ref, dict):
                continue
                
            file_path = file_ref.get("file_path")
            file_id = file_ref.get("file_id")
            
            # è·³è¿‡æ— æ•ˆçš„æ–‡ä»¶å¼•ç”¨
            if not file_path:
                self.logger.warning("âš ï¸ è·³è¿‡æ— æ•ˆæ–‡ä»¶å¼•ç”¨ï¼ˆç¼ºå°‘file_pathï¼‰")
                continue
            
            # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
            if not Path(file_path).exists():
                self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
                continue
            
            # æå–æ¨¡å—å
            filename = Path(file_path).name
            module_name = Path(file_path).stem
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è®¾è®¡æ–‡ä»¶ï¼ˆéæµ‹è¯•å°ï¼‰
            is_testbench = any(keyword in filename.lower() for keyword in ['_tb.v', 'testbench', '_test'])
            
            if not is_testbench and file_ref.get("file_type") == "verilog":
                # è®¾è®¡æ–‡ä»¶ï¼šæŒ‰æ¨¡å—ååˆ†ç»„
                base_module_name = module_name.split('_')[0]  # å»é™¤ç‰ˆæœ¬åç¼€ï¼Œå¦‚ counter_8bit_2 -> counter
                
                if base_module_name not in module_files:
                    module_files[base_module_name] = []
                module_files[base_module_name].append(file_ref)
            else:
                # æµ‹è¯•å°æ–‡ä»¶å’Œå…¶ä»–æ–‡ä»¶ç›´æ¥æ·»åŠ ï¼ˆä¸éœ€è¦ç‰ˆæœ¬æ§åˆ¶ï¼‰
                if file_path not in seen_paths and (not file_id or file_id not in seen_file_ids):
                    validated_refs.append(file_ref)
                    seen_paths.add(file_path)
                    if file_id:
                        seen_file_ids.add(file_id)
                    self.logger.debug(f"âœ… éªŒè¯é€šè¿‡ï¼ˆæµ‹è¯•å°/å…¶ä»–ï¼‰: {filename}")
        
        # ğŸ¯ å¯¹æ¯ä¸ªæ¨¡å—ï¼Œåªé€‰æ‹©æœ€æ–°çš„è®¾è®¡æ–‡ä»¶
        for module_name, files in module_files.items():
            if not files:
                continue
            
            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
            files_sorted = sorted(files, key=lambda x: x.get("created_at", ""), reverse=True)
            latest_file = files_sorted[0]
            
            file_path = latest_file.get("file_path")
            file_id = latest_file.get("file_id")
            
            # é¿å…é‡å¤
            if file_path not in seen_paths and (not file_id or file_id not in seen_file_ids):
                validated_refs.append(latest_file)
                seen_paths.add(file_path)
                if file_id:
                    seen_file_ids.add(file_id)
                
                self.logger.info(f"ğŸ¯ é€‰æ‹©æœ€æ–°è®¾è®¡æ–‡ä»¶: {Path(file_path).name} (æ¨¡å—: {module_name})")
                
                # è®°å½•è¢«è·³è¿‡çš„æ—§ç‰ˆæœ¬
                if len(files) > 1:
                    skipped_files = [Path(f.get("file_path", "")).name for f in files_sorted[1:]]
                    self.logger.debug(f"â­ï¸ è·³è¿‡æ—§ç‰ˆæœ¬: {', '.join(skipped_files)}")
        
        return validated_refs
    
    def _determine_testbench_strategy(self, iteration: int, user_testbench_path: str, 
                                     current_iteration_testbench: str) -> Dict[str, str]:
        """ç»Ÿä¸€çš„testbenché€‰æ‹©ç­–ç•¥"""
        strategy_info = {
            "selected_testbench": None,
            "strategy": "æœªå®šä¹‰",
            "reason": "æ— å¯ç”¨æµ‹è¯•å°"
        }
        
        # æ£€æŸ¥å¯ç”¨çš„testbenché€‰é¡¹
        has_user_testbench = user_testbench_path and Path(user_testbench_path).exists()
        has_generated_testbench = current_iteration_testbench and Path(current_iteration_testbench).exists()
        
        self.logger.debug(f"testbenchå¯ç”¨æ€§: ç”¨æˆ·æä¾›={has_user_testbench}, æ™ºèƒ½ä½“ç”Ÿæˆ={has_generated_testbench}")
        
        if iteration == 1:
            # ç¬¬ä¸€æ¬¡è¿­ä»£ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„ï¼Œå»ºç«‹åŸºå‡†
            if has_user_testbench:
                strategy_info.update({
                    "selected_testbench": user_testbench_path,
                    "strategy": "ç”¨æˆ·åŸºå‡†",
                    "reason": "ç¬¬1æ¬¡è¿­ä»£ä½¿ç”¨ç”¨æˆ·æä¾›çš„æµ‹è¯•å°ä½œä¸ºåŠŸèƒ½åŸºå‡†"
                })
            elif has_generated_testbench:
                strategy_info.update({
                    "selected_testbench": current_iteration_testbench,
                    "strategy": "æ™ºèƒ½ä½“ç”Ÿæˆ",
                    "reason": "ç”¨æˆ·æœªæä¾›æµ‹è¯•å°ï¼Œä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æµ‹è¯•å°"
                })
        else:
            # åç»­è¿­ä»£ï¼šğŸ¯ ä¼˜å…ˆä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æµ‹è¯•å°
            if has_generated_testbench:
                # âœ¨ æ™ºèƒ½ä½“ç”Ÿæˆäº†æµ‹è¯•å°ï¼Œä¼˜å…ˆä½¿ç”¨ï¼ˆæ¨åŠ¨TDDå¾ªç¯ï¼‰
                strategy_info.update({
                    "selected_testbench": current_iteration_testbench,
                    "strategy": "æ™ºèƒ½ä½“ä¼˜åŒ–",
                    "reason": f"ç¬¬{iteration}æ¬¡è¿­ä»£ï¼Œä¼˜å…ˆä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æœ€æ–°æµ‹è¯•å°æ¨åŠ¨TDDå¾ªç¯"
                })
            elif has_user_testbench:
                # åªæœ‰ç”¨æˆ·æµ‹è¯•å°å¯ç”¨æ—¶æ‰ä½¿ç”¨
                strategy_info.update({
                    "selected_testbench": user_testbench_path,
                    "strategy": "ç”¨æˆ·å¤‡ç”¨",
                    "reason": f"ç¬¬{iteration}æ¬¡è¿­ä»£ï¼Œæ™ºèƒ½ä½“æœªç”Ÿæˆæµ‹è¯•å°ï¼Œä½¿ç”¨ç”¨æˆ·æµ‹è¯•å°"
                })
        
        return strategy_info
    
    def _should_use_generated_testbench(self, iteration: int) -> bool:
        """å†³å®šæ˜¯å¦åº”è¯¥ä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æµ‹è¯•å°"""
        # âœ¨ ç§¯æç­–ç•¥ï¼šä»ç¬¬2æ¬¡è¿­ä»£å¼€å§‹ï¼Œä¼˜å…ˆä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æµ‹è¯•å°
        # è¿™ç¡®ä¿äº† TDD å¾ªç¯ä¸­æµ‹è¯•å°å¯ä»¥éšç€è®¾è®¡ä¸€èµ·è¿­ä»£æ”¹è¿›
        # ç¬¬1æ¬¡è¿­ä»£å»ºç«‹åŸºå‡†ï¼Œç¬¬2æ¬¡åŠä»¥åè¿­ä»£ä¼˜åŒ–
        return iteration >= 2
    
    def _analyze_code_violations(self, error_text: str, enhanced_analysis: Dict[str, Any]) -> str:
        """åˆ†æä»£ç è¿è§„é—®é¢˜"""
        analysis = ""
        
        # æ£€æŸ¥SystemVerilogè¯­æ³•è¿è§„
        if "logic" in error_text.lower():
            analysis += "ğŸš¨ **SystemVerilogè¯­æ³•è¿è§„**:\n"
            analysis += "- æ£€æµ‹åˆ° `logic` ç±»å‹ï¼Œiverilogä¸æ”¯æŒ\n"
            analysis += "- å¿…é¡»æ”¹ç”¨ `wire` æˆ– `reg`\n\n"
        
        # æ£€æŸ¥æ—¶åºé€»è¾‘è¿è§„
        last_code = enhanced_analysis.get("last_generated_code", "")
        if last_code:
            if "posedge" in last_code and ("clk" in last_code or "rst" in last_code):
                analysis += "ğŸš¨ **æ—¶åºé€»è¾‘è¿è§„**:\n"
                analysis += "- æ£€æµ‹åˆ°æ—¶é’Ÿ/å¤ä½ä¿¡å·ï¼Œè¿åçº¯ç»„åˆé€»è¾‘è¦æ±‚\n"
                analysis += "- å¿…é¡»ç§»é™¤ clkã€rst ä¿¡å·\n"
                analysis += "- å°† always @(posedge clk) æ”¹ä¸º always @(*)\n\n"
        
        # æ£€æŸ¥ç«¯å£åŒ¹é…é—®é¢˜
        if "not a port" in error_text:
            import re
            port_match = re.search(r"port\s+[`'\"]*(\w+)[`'\"]*\s+is not a port", error_text)
            if port_match:
                missing_port = port_match.group(1)
                analysis += f"ğŸš¨ **ç«¯å£åŒ¹é…é”™è¯¯**:\n"
                analysis += f"- æµ‹è¯•å°æœŸæœ›ç«¯å£: `{missing_port}`\n"
                analysis += f"- å½“å‰æ¨¡å—ç¼ºå°‘æ­¤ç«¯å£\n"
                analysis += f"- **ç«‹å³ä¿®å¤**: åœ¨æ¨¡å—ä¸­æ·»åŠ  `{missing_port}` ç«¯å£\n\n"
        
        return analysis
    
    def _analyze_test_failures(self, test_results: str, enhanced_analysis: Dict[str, Any]) -> str:
        """æ·±åº¦åˆ†ææµ‹è¯•å¤±è´¥åŸå› """
        analysis = ""
        
        # è§£ææµ‹è¯•ç»“æœ
        import re
        
        # æŸ¥æ‰¾å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹
        test_cases = re.findall(r"Test Case (\d+).*?Failed.*?Expected.*?got\s+(.*?)(?=\n|$)", test_results, re.DOTALL)
        
        for case_num, details in test_cases:
            analysis += f"ğŸ“Š **æµ‹è¯•ç”¨ä¾‹ {case_num} å¤±è´¥åˆ†æ**:\n"
            
            # æå–å…·ä½“æ•°å€¼
            values = re.findall(r"(\w+)=([0-9a-fA-F]+)", details)
            if values:
                analysis += "- å®é™…ç»“æœ: " + ", ".join([f"{k}={v}" for k, v in values]) + "\n"
            
            # ç‰¹å®šé”™è¯¯æ¨¡å¼åˆ†æ
            if "overflow" in details and "overflow=0" in details:
                analysis += "ğŸ” **æº¢å‡ºæ£€æµ‹é€»è¾‘é”™è¯¯**:\n"
                analysis += "- æº¢å‡ºæ£€æµ‹è¾“å‡ºä¸º0ï¼Œä½†åº”è¯¥ä¸º1\n"
                analysis += "- æ£€æŸ¥å…¬å¼: `overflow = (a[15] == b[15]) && (a[15] != sum[15])`\n"
                analysis += "- éªŒè¯: ä¸¤ä¸ªåŒå·æ•°ç›¸åŠ ç»“æœå˜å·æ—¶åº”è¯¥æº¢å‡º\n\n"
            
            if "cout" in details:
                analysis += "ğŸ” **è¿›ä½é€»è¾‘æ£€æŸ¥**:\n"
                analysis += "- éªŒè¯è¿›ä½è®¡ç®—: æœ€é«˜ä½æ˜¯å¦æ­£ç¡®ä¼ æ’­\n"
                analysis += "- æ£€æŸ¥: `cout = (a[15] & b[15]) | ((a[15] ^ b[15]) & carry[14])`\n\n"
        
        return analysis
    
    async def _llm_analyze_failures(self, error_text: str, enhanced_analysis: Dict[str, Any], iteration: int) -> str:
        """ä½¿ç”¨LLMæ™ºèƒ½åˆ†æç¼–è¯‘å¤±è´¥åŸå› """
        if not error_text.strip():
            return ""
        
        # å‡†å¤‡LLMåˆ†æçš„context
        last_code = enhanced_analysis.get("last_generated_code", "")
        design_requirements = enhanced_analysis.get("design_requirements", "")
        
        analysis_prompt = f"""ä½œä¸ºVerilogä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹ç¼–è¯‘é”™è¯¯å¹¶æä¾›ç²¾å‡†çš„ä¿®å¤æŒ‡å¯¼ï¼š

ğŸ¯ **è®¾è®¡è¦æ±‚**:
{design_requirements}

ğŸ“„ **ç”Ÿæˆçš„ä»£ç **:
```verilog
{last_code[:1000] if last_code else "ä»£ç ä¸å¯ç”¨"}
```

âŒ **ç¼–è¯‘é”™è¯¯**:
```
{error_text}
```

ğŸ” **è¿­ä»£ä¿¡æ¯**: ç¬¬{iteration}æ¬¡è¿­ä»£

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. **æ ¹æœ¬åŸå› **: é”™è¯¯çš„æœ¬è´¨æ˜¯ä»€ä¹ˆï¼Ÿ
2. **è¿åçš„çº¦æŸ**: è¿åäº†å“ªäº›è®¾è®¡è¦æ±‚ï¼Ÿ
3. **å…·ä½“ä¿®å¤**: æä¾›3-5ä¸ªå…·ä½“çš„ä¿®å¤æ­¥éª¤
4. **éªŒè¯æ–¹æ³•**: å¦‚ä½•éªŒè¯ä¿®å¤æ˜¯å¦æ­£ç¡®ï¼Ÿ

æ ¼å¼è¦æ±‚ï¼š
- ä½¿ç”¨markdownæ ¼å¼
- é‡ç‚¹å†…å®¹ç”¨**åŠ ç²—**
- ä¿®å¤æ­¥éª¤è¦å…·ä½“å¯æ“ä½œ
- é¿å…ä¸€èˆ¬æ€§å»ºè®®ï¼Œè¦é’ˆå¯¹å…·ä½“é”™è¯¯"""

        try:
            # è°ƒç”¨LLMè¿›è¡Œåˆ†æ
            from core.llm_integration.enhanced_llm_client import EnhancedLLMClient
            from config.config import FrameworkConfig
            
            config = FrameworkConfig.from_env()
            llm_client = EnhancedLLMClient(config.llm)
            
            analysis_result = await llm_client.send_prompt(
                prompt=analysis_prompt,
                system_prompt="ä½ æ˜¯èµ„æ·±çš„Verilogè®¾è®¡ä¸“å®¶ï¼Œä¸“é—¨åˆ†æå’Œä¿®å¤ç¡¬ä»¶æè¿°è¯­è¨€çš„é—®é¢˜ã€‚",
                temperature=0.1,  # ä½æ¸©åº¦ç¡®ä¿åˆ†æå‡†ç¡®æ€§
                max_tokens=1000
            )
            
            return f"ğŸ¤– **LLMæ™ºèƒ½å¤±è´¥åˆ†æ**:\n{analysis_result}\n\n"
            
        except Exception as e:
            self.logger.error(f"âŒ LLMå¤±è´¥åˆ†æå¼‚å¸¸: {str(e)}")
            # é™çº§åˆ°ç®€åŒ–çš„è§„åˆ™åˆ†æ
            return self._analyze_code_violations(error_text, enhanced_analysis)
    
    async def _llm_analyze_test_failures(self, test_results: str, enhanced_analysis: Dict[str, Any], iteration: int) -> str:
        """ä½¿ç”¨LLMæ™ºèƒ½åˆ†ææµ‹è¯•å¤±è´¥åŸå› """
        if not test_results.strip():
            return ""
        
        last_code = enhanced_analysis.get("last_generated_code", "")
        design_requirements = enhanced_analysis.get("design_requirements", "")
        
        analysis_prompt = f"""ä½œä¸ºæ•°å­—ç”µè·¯éªŒè¯ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹æµ‹è¯•å¤±è´¥åŸå› ï¼š

ğŸ¯ **è®¾è®¡è¦æ±‚**:
{design_requirements}

ğŸ“„ **è¢«æµ‹ä»£ç **:
```verilog
{last_code[:1000] if last_code else "ä»£ç ä¸å¯ç”¨"}
```

ğŸ§ª **æµ‹è¯•ç»“æœ**:
```
{test_results}
```

ğŸ” **è¿­ä»£ä¿¡æ¯**: ç¬¬{iteration}æ¬¡è¿­ä»£

è¯·æä¾›ä»¥ä¸‹åˆ†æï¼š
1. **å¤±è´¥æ¨¡å¼**: æµ‹è¯•å¤±è´¥çš„å…·ä½“æ¨¡å¼æ˜¯ä»€ä¹ˆï¼Ÿ
2. **æ•°å­¦åˆ†æ**: ä»æ•°å­¦è§’åº¦åˆ†æä¸ºä»€ä¹ˆä¼šå¤±è´¥ï¼Ÿ
3. **é€»è¾‘é”™è¯¯**: æŒ‡å‡ºå…·ä½“çš„é€»è¾‘å®ç°é”™è¯¯
4. **ä¿®å¤å»ºè®®**: æä¾›å…·ä½“çš„ä»£ç ä¿®æ”¹å»ºè®®
5. **éªŒè¯ç­–ç•¥**: å¦‚ä½•éªŒè¯ä¿®å¤åçš„æ­£ç¡®æ€§ï¼Ÿ

ç‰¹åˆ«å…³æ³¨ï¼š
- æº¢å‡ºæ£€æµ‹é€»è¾‘çš„æ•°å­¦æ­£ç¡®æ€§
- è¿›ä½ä¼ æ’­çš„å®ç°æ–¹å¼
- è¾¹ç•Œæ¡ä»¶çš„å¤„ç†

æ ¼å¼è¦æ±‚ï¼š
- ä½¿ç”¨markdownæ ¼å¼
- åŒ…å«å…·ä½“çš„æ•°å€¼ä¾‹å­
- æä¾›å¯æ“ä½œçš„ä¿®å¤ä»£ç ç‰‡æ®µ"""

        try:
            from core.llm_integration.enhanced_llm_client import EnhancedLLMClient
            from config.config import FrameworkConfig
            
            config = FrameworkConfig.from_env()
            llm_client = EnhancedLLMClient(config.llm)
            
            analysis_result = await llm_client.send_prompt(
                prompt=analysis_prompt,
                system_prompt="ä½ æ˜¯èµ„æ·±çš„æ•°å­—ç”µè·¯éªŒè¯ä¸“å®¶ï¼Œä¸“é—¨åˆ†ææµ‹è¯•å¤±è´¥åŸå› å¹¶æä¾›ç²¾ç¡®çš„ä¿®å¤æ–¹æ¡ˆã€‚",
                temperature=0.1,
                max_tokens=1000
            )
            
            return f"ğŸ¤– **LLMæ™ºèƒ½æµ‹è¯•åˆ†æ**:\n{analysis_result}\n\n"
            
        except Exception as e:
            self.logger.error(f"âŒ LLMæµ‹è¯•åˆ†æå¼‚å¸¸: {str(e)}")
            # é™çº§åˆ°ç®€åŒ–çš„è§„åˆ™åˆ†æ
            return self._analyze_test_failures(test_results, enhanced_analysis)
    
    async def _build_detailed_error_context(self, error_text: str, enhanced_analysis: Dict[str, Any]) -> str:
        """æ„å»ºè¯¦ç»†çš„é”™è¯¯ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context = "ğŸ” **è¯¦ç»†é”™è¯¯ä¸Šä¸‹æ–‡åˆ†æ**:\n"
        
        # è§£æé”™è¯¯ä¿¡æ¯ï¼Œæå–æ–‡ä»¶åå’Œè¡Œå·
        import re
        error_matches = re.findall(r'([^:\s]+\.s?v):(\d+):\s*(.+)', error_text)
        
        last_code = enhanced_analysis.get("last_generated_code", "")
        
        for file_path, line_num, error_msg in error_matches:
            context += f"\nğŸ“ **é”™è¯¯ä½ç½®**: {file_path}:{line_num}\n"
            context += f"ğŸ“ **é”™è¯¯æè¿°**: {error_msg}\n"
            
            if last_code:
                try:
                    lines = last_code.split('\n')
                    line_idx = int(line_num) - 1
                    
                    if 0 <= line_idx < len(lines):
                        # æ˜¾ç¤ºé”™è¯¯è¡ŒåŠå…¶ä¸Šä¸‹æ–‡
                        context += f"\nğŸ’¡ **é”™è¯¯ä»£ç ä¸Šä¸‹æ–‡**:\n```verilog\n"
                        
                        # æ˜¾ç¤ºå‰å3è¡Œä»£ç 
                        start = max(0, line_idx - 3)
                        end = min(len(lines), line_idx + 4)
                        
                        for i in range(start, end):
                            marker = ">>> " if i == line_idx else "    "
                            context += f"{marker}{i+1:3d}: {lines[i]}\n"
                        
                        context += "```\n"
                        
                        # åˆ†æå…·ä½“é”™è¯¯
                        error_line = lines[line_idx].strip()
                        context += f"\nğŸ” **é—®é¢˜ä»£ç **: `{error_line}`\n"
                        
                        # åŸºäºé”™è¯¯ç±»å‹æä¾›å…·ä½“åˆ†æ
                        if "syntax error" in error_msg.lower():
                            context += await self._analyze_syntax_error(error_line, error_msg)
                        elif "not a port" in error_msg.lower():
                            context += await self._analyze_port_error(error_line, error_msg, last_code)
                        
                except Exception as e:
                    self.logger.error(f"âŒ æ„å»ºé”™è¯¯ä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
        
        return context + "\n"
    
    async def _analyze_syntax_error(self, error_line: str, error_msg: str) -> str:
        """åˆ†æè¯­æ³•é”™è¯¯"""
        analysis = "\nğŸš¨ **è¯­æ³•é”™è¯¯åˆ†æ**:\n"
        
        # æ£€æŸ¥å¸¸è§è¯­æ³•é—®é¢˜
        if "for (" in error_line and "int " in error_line:
            analysis += "- æ£€æµ‹åˆ°SystemVerilog `for (int i...)` è¯­æ³•\n"
            analysis += "- iverilogä¸æ”¯æŒæ­¤è¯­æ³•ï¼Œéœ€è¦æ”¹ä¸ºVerilog-2001è¯­æ³•\n"
            analysis += "- **ä¿®å¤å»ºè®®**: åœ¨æ¨¡å—é¡¶éƒ¨å£°æ˜ `integer i;`ï¼Œç„¶åä½¿ç”¨ `for (i = 0; ...)`\n"
        elif "logic" in error_line:
            analysis += "- æ£€æµ‹åˆ°SystemVerilog `logic` ç±»å‹\n"
            analysis += "- iverilogä¸æ”¯æŒæ­¤ç±»å‹ï¼Œéœ€è¦æ”¹ä¸º `wire` æˆ– `reg`\n"
            analysis += "- **ä¿®å¤å»ºè®®**: å°† `logic` æ”¹ä¸º `wire`ï¼ˆç»„åˆé€»è¾‘ï¼‰æˆ– `reg`ï¼ˆæ—¶åºé€»è¾‘ï¼‰\n"
        elif "assert" in error_line:
            analysis += "- æ£€æµ‹åˆ°SystemVerilog `assert` è¯­å¥\n"
            analysis += "- iverilogä¸æ”¯æŒæ­¤åŠŸèƒ½ï¼Œéœ€è¦åˆ é™¤æˆ–æ”¹ä¸ºæ™®é€šéªŒè¯\n"
            analysis += "- **ä¿®å¤å»ºè®®**: åˆ é™¤assertè¯­å¥æˆ–æ”¹ä¸ºifè¯­å¥è¿›è¡Œæ£€æŸ¥\n"
        else:
            analysis += f"- è¯­æ³•é”™è¯¯: {error_msg}\n"
            analysis += "- **å»ºè®®**: æ£€æŸ¥æ‹¬å·åŒ¹é…ã€åˆ†å·ã€å…³é”®å­—æ‹¼å†™\n"
        
        return analysis
    
    async def _analyze_port_error(self, error_line: str, error_msg: str, full_code: str) -> str:
        """åˆ†æç«¯å£åŒ¹é…é”™è¯¯"""
        analysis = "\nğŸ”Œ **ç«¯å£åŒ¹é…é”™è¯¯åˆ†æ**:\n"
        
        # æå–é”™è¯¯çš„ç«¯å£å
        import re
        port_match = re.search(r"port\s+[`'\"]*(\w+)[`'\"]*\s+is not a port", error_msg)
        
        if port_match:
            missing_port = port_match.group(1)
            analysis += f"- æµ‹è¯•å°æœŸæœ›ç«¯å£: `{missing_port}`\n"
            
            # åˆ†ææ¨¡å—å®é™…ç«¯å£
            module_match = re.search(r'module\s+\w+\s*\([^)]*\)', full_code, re.DOTALL)
            if module_match:
                module_ports = module_match.group(0)
                analysis += f"- å½“å‰æ¨¡å—ç«¯å£: {module_ports}\n"
            
            analysis += f"- **ä¿®å¤å»ºè®®**: åœ¨æ¨¡å—ç«¯å£åˆ—è¡¨ä¸­æ·»åŠ  `{missing_port}` ç«¯å£\n"
            
            # åˆ†æå¯èƒ½çš„åŸå› 
            if missing_port in ["clk", "rst", "rst_n"]:
                analysis += f"- **é—®é¢˜åŸå› **: è®¾è®¡è¦æ±‚çº¯ç»„åˆé€»è¾‘ï¼Œä½†æ¨¡å—ä»åŒ…å«æ—¶é’Ÿ/å¤ä½ä¿¡å·\n"
                analysis += f"- **è§£å†³æ–¹æ¡ˆ**: å®Œå…¨ç§»é™¤æ—¶é’Ÿå’Œå¤ä½ç›¸å…³çš„ç«¯å£å’Œé€»è¾‘\n"
        
        return analysis
    
    async def _build_test_failure_context(self, test_results: str, enhanced_analysis: Dict[str, Any]) -> str:
        """æ„å»ºè¯¦ç»†çš„æµ‹è¯•å¤±è´¥ä¸Šä¸‹æ–‡"""
        context = "ğŸ§ª **è¯¦ç»†æµ‹è¯•å¤±è´¥ä¸Šä¸‹æ–‡**:\n"
        
        # è§£ææµ‹è¯•ç»“æœï¼Œæå–å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹
        import re
        
        # æŸ¥æ‰¾å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹
        test_case_matches = re.findall(r'Test[^\n]*?failed[^\n]*', test_results, re.IGNORECASE)
        
        if test_case_matches:
            context += f"\nğŸ“Š **å¤±è´¥çš„æµ‹è¯•ç”¨ä¾‹** ({len(test_case_matches)}ä¸ª):\n"
            
            for i, test_case in enumerate(test_case_matches, 1):
                context += f"\nğŸ” **å¤±è´¥ç”¨ä¾‹ {i}**: {test_case}\n"
                
                # æå–å…·ä½“çš„è¾“å…¥è¾“å‡ºå€¼
                values = re.findall(r'(\w+)=([0-9a-fA-FxX]+)', test_case)
                if values:
                    context += "ğŸ“‹ **å®é™…ç»“æœ**:\n"
                    for var, val in values:
                        context += f"  - {var} = {val}\n"
        
        # æŸ¥æ‰¾æœŸæœ›å€¼ä¿¡æ¯
        expected_matches = re.findall(r'Expected[^\n]*', test_results, re.IGNORECASE)
        if expected_matches:
            context += f"\nâœ… **æœŸæœ›ç»“æœ**:\n"
            for expected in expected_matches:
                context += f"  - {expected}\n"
        
        # åˆ†æå…·ä½“çš„æ•°å€¼å·®å¼‚
        last_code = enhanced_analysis.get("last_generated_code", "")
        if last_code:
            context += await self._analyze_test_value_differences(test_results, last_code)
        
        return context + "\n"
    
    async def _analyze_test_value_differences(self, test_results: str, dut_code: str) -> str:
        """åˆ†ææµ‹è¯•å€¼å·®å¼‚"""
        analysis = "\nğŸ” **æ•°å€¼å·®å¼‚åˆ†æ**:\n"
        
        # ç‰¹å®šæµ‹è¯•ç”¨ä¾‹çš„æ·±åº¦åˆ†æ
        if "overflow=0" in test_results and "expected" in test_results.lower():
            analysis += "\nğŸš¨ **æº¢å‡ºæ£€æµ‹é”™è¯¯åˆ†æ**:\n"
            
            # æå–æº¢å‡ºæ£€æµ‹é€»è¾‘
            overflow_match = re.search(r'(assign\s+overflow[^;]+;)', dut_code, re.IGNORECASE)
            if overflow_match:
                overflow_logic = overflow_match.group(1)
                analysis += f"ğŸ“‹ **å½“å‰æº¢å‡ºé€»è¾‘**: `{overflow_logic}`\n"
                
                # åˆ†æå¸¸è§çš„æº¢å‡ºæ£€æµ‹é”™è¯¯
                if "(a[15] == b[15]) && (a[15] != sum[15])" in overflow_logic:
                    analysis += "âœ… æº¢å‡ºæ£€æµ‹å…¬å¼æ­£ç¡®\n"
                    analysis += "âš ï¸ å¯èƒ½é—®é¢˜ï¼šsumçš„è®¡ç®—æ—¶åºæˆ–ä½ç½®\n"
                    analysis += "ğŸ” **å»ºè®®æ£€æŸ¥**: sumè®¡ç®—æ˜¯å¦åœ¨overflowæ£€æµ‹ä¹‹å‰å®Œæˆ\n"
                else:
                    analysis += "âŒ æº¢å‡ºæ£€æµ‹å…¬å¼å¯èƒ½æœ‰è¯¯\n"
                    analysis += "âœ… **æ­£ç¡®å…¬å¼**: `overflow = (a[15] == b[15]) && (a[15] != sum[15])`\n"
        
        # è¿›ä½é€»è¾‘åˆ†æ
        if "cout=" in test_results:
            analysis += "\nğŸ”— **è¿›ä½é€»è¾‘åˆ†æ**:\n"
            cout_match = re.search(r'(assign\s+cout[^;]+;)', dut_code, re.IGNORECASE)
            if cout_match:
                cout_logic = cout_match.group(1)
                analysis += f"ğŸ“‹ **å½“å‰è¿›ä½é€»è¾‘**: `{cout_logic}`\n"
        
        return analysis
    
    def _parse_compilation_errors(self, stderr_content: str) -> List[Dict[str, Any]]:
        """è§£æç¼–è¯‘é”™è¯¯ä¿¡æ¯"""
        errors = []
        if not stderr_content:
            return errors
        
        # å¸¸è§çš„ç¼–è¯‘é”™è¯¯æ¨¡å¼
        error_patterns = [
            r'(.+?):(\d+):\s*error:\s*(.+)',  # file:line: error: message
            r'(.+?):(\d+):\s*(.+error.+)',   # file:line: error message
            r'Error.*?in\s+(.+?)\s+at\s+line\s+(\d+)',  # Error in file at line
        ]
        
        lines = stderr_content.split('\n')
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            for pattern in error_patterns:
                match = re.search(pattern, line, re.IGNORECASE)
                if match:
                    if len(match.groups()) >= 3:
                        file_path = match.group(1).strip()
                        line_number = match.group(2).strip()
                        message = match.group(3).strip()
                    else:
                        file_path = match.group(1).strip() if len(match.groups()) >= 1 else "unknown"
                        line_number = match.group(2).strip() if len(match.groups()) >= 2 else "0"
                        message = line
                    
                    errors.append({
                        "file": file_path,
                        "line": line_number,
                        "message": message,
                        "type": "compilation_error",
                        "raw_line": line
                    })
                    break
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ç‰¹å®šæ¨¡å¼ï¼Œä½†åŒ…å«é”™è¯¯å…³é”®è¯ï¼Œæ·»åŠ ä¸ºé€šç”¨é”™è¯¯
        if not errors and any(keyword in stderr_content.lower() for keyword in ['error', 'failed', 'cannot']):
            errors.append({
                "file": "unknown",
                "line": "0",
                "message": stderr_content.strip(),
                "type": "general_error",
                "raw_line": stderr_content.strip()
            })
        
        return errors
    
    def _extract_module_name(self, verilog_content: str) -> Optional[str]:
        """ä»Verilogä»£ç ä¸­æå–æ¨¡å—å"""
        if not verilog_content:
            return None
        
        # æŸ¥æ‰¾ module å£°æ˜
        module_pattern = r'module\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*[#(]'
        match = re.search(module_pattern, verilog_content)
        if match:
            return match.group(1)
        
        # ç®€åŒ–ç‰ˆæ¨¡å¼
        simple_pattern = r'module\s+([a-zA-Z_][a-zA-Z0-9_]*)'
        match = re.search(simple_pattern, verilog_content)
        if match:
            return match.group(1)
        
        return None

    async def _continue_persistent_conversation(self, task: str, context: Dict[str, Any], iteration: int) -> Dict[str, Any]:
        """ç»§ç»­æŒç»­å¯¹è¯ï¼Œä¸é‡æ–°é€‰æ‹©æ™ºèƒ½ä½“ - ä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        try:
            # è·å–ä¹‹å‰ä½¿ç”¨çš„æ™ºèƒ½ä½“
            if not hasattr(self, 'current_session_agents') or 'verilog_designer' not in self.current_session_agents:
                # å¦‚æœæ²¡æœ‰è®°å½•ï¼Œå›é€€åˆ°æ ‡å‡†æµç¨‹
                self.logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æŒç»­å¯¹è¯çš„æ™ºèƒ½ä½“ï¼Œå›é€€åˆ°æ ‡å‡†æµç¨‹")
                return await self.base_coordinator.coordinate_task_execution(task, context)
            
            design_agent_id = self.current_session_agents['verilog_designer']
            self.logger.info(f"ğŸ”— å‘æŒç»­å¯¹è¯æ™ºèƒ½ä½“å‘é€ä»»åŠ¡: {design_agent_id}")
            
            # ç›´æ¥å‘æ™ºèƒ½ä½“å‘é€ä»»åŠ¡ï¼Œä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡
            design_agent = self.base_coordinator.agent_instances.get(design_agent_id)
            if not design_agent:
                self.logger.error(f"âŒ æ™ºèƒ½ä½“ä¸å­˜åœ¨: {design_agent_id}")
                return {"success": False, "error": f"æ™ºèƒ½ä½“ä¸å­˜åœ¨: {design_agent_id}"}
            
            # ğŸ§  ä½¿ç”¨å®Œæ•´ä¸Šä¸‹æ–‡ç®¡ç†å™¨æ„å»ºå…¨é‡ä¸Šä¸‹æ–‡
            enhanced_context = context.copy()
            if self.context_manager:
                full_context = self.context_manager.get_full_context_for_agent(design_agent_id, task)
                enhanced_context["full_conversation_context"] = full_context
                self.logger.info(f"ğŸ§  ä¼ é€’å®Œæ•´ä¸Šä¸‹æ–‡ç»™{design_agent_id}: "
                               f"{len(full_context.get('complete_conversation_history', []))}è½®å¯¹è¯å†å²")
            
            # ğŸ§  è®°å½•å¯¹è¯å¼€å§‹ï¼ˆAIæ¥æ”¶åˆ°çš„promptï¼‰
            if self.context_manager:
                self.context_manager.add_conversation_turn(
                    agent_id=design_agent_id,
                    user_prompt=task,
                    system_prompt="TDDè¿­ä»£è®¾è®¡ä»»åŠ¡",
                    ai_response="",  # ç¨åæ›´æ–°
                    reasoning_notes=f"è¿­ä»£{iteration}çš„æŒç»­å¯¹è¯"
                )
            
            # åˆ›å»ºä»»åŠ¡æ¶ˆæ¯
            task_message = TaskMessage(
                task_id=f"{self.persistent_conversation_id}_iter_{iteration}",
                sender_id="test_driven_coordinator",
                receiver_id=design_agent_id,
                message_type="task_execution",
                content=task,
                metadata=enhanced_context
            )
            
            # ç›´æ¥è°ƒç”¨æ™ºèƒ½ä½“çš„å¢å¼ºä»»åŠ¡æ‰§è¡Œæ–¹æ³•
            result = await design_agent.execute_enhanced_task(task, task_message, {})
            
            # ğŸ§  è®°å½•å¯¹è¯ç»“æœï¼ˆAIçš„å®Œæ•´å“åº”ï¼‰
            if self.context_manager and self.context_manager.current_iteration:
                # æ›´æ–°æœ€åä¸€ä¸ªå¯¹è¯è½®æ¬¡çš„AIå“åº”
                last_turn = self.context_manager.current_iteration.conversation_turns[-1]
                last_turn.ai_response = str(result.get("content", ""))
                last_turn.success = result.get("success", False)
                last_turn.error_info = result.get("error") if not result.get("success") else None
                last_turn.tool_calls = result.get("tool_calls", [])
                last_turn.tool_results = result.get("tool_results", [])
            
            # è®°å½•æœ¬æ¬¡è¿­ä»£çš„ç»“æœ
            if result.get("success", False):
                self.logger.info(f"âœ… æŒç»­å¯¹è¯ä»»åŠ¡å®Œæˆ: è¿­ä»£ {iteration}")
            else:
                self.logger.error(f"âŒ æŒç»­å¯¹è¯ä»»åŠ¡å¤±è´¥: {result.get('error', 'Unknown error')}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æŒç»­å¯¹è¯å¼‚å¸¸: {str(e)}")
            # å‡ºé”™æ—¶å›é€€åˆ°æ ‡å‡†æµç¨‹
            return await self.base_coordinator.coordinate_task_execution(task, context)
    


# ==========================================
# ğŸ­ å·¥å‚å‡½æ•° - ä¾¿äºé›†æˆ
# ==========================================

def create_test_driven_coordinator(base_coordinator: CentralizedCoordinator,
                                 config: TestDrivenConfig = None) -> TestDrivenCoordinator:
    """
    åˆ›å»ºæµ‹è¯•é©±åŠ¨åè°ƒå™¨çš„å·¥å‚å‡½æ•°
    
    Usage:
        # ç°æœ‰ä»£ç 
        coordinator = CentralizedCoordinator(config)
        
        # å‡çº§ä¸ºæµ‹è¯•é©±åŠ¨åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰
        enhanced_coordinator = create_test_driven_coordinator(coordinator)
        
        # ç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å˜
        result = await enhanced_coordinator.coordinate_task_execution(task)
        
        # æ–°å¢æµ‹è¯•é©±åŠ¨åŠŸèƒ½
        tdd_result = await enhanced_coordinator.execute_test_driven_task(task, testbench_path)
    """
    return TestDrivenCoordinator(base_coordinator, config)
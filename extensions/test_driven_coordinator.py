#!/usr/bin/env python3
"""
æµ‹è¯•é©±åŠ¨åè°ƒå™¨ - å®Œå…¨ç‹¬ç«‹çš„æ‰©å±•åŠŸèƒ½

è¿™æ˜¯ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„æ‰©å±•æ¨¡å—ï¼Œä¸ä¿®æ”¹ä»»ä½•ç°æœ‰ä»£ç 
"""

import asyncio
import json
import time
import logging
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass

# å¯¼å…¥ç°æœ‰æ¡†æ¶ç»„ä»¶ - åªè¯»å–ï¼Œä¸ä¿®æ”¹
from core.centralized_coordinator import CentralizedCoordinator
from core.enums import AgentCapability, AgentStatus
from config.config import FrameworkConfig


@dataclass
class TestDrivenConfig:
    """æµ‹è¯•é©±åŠ¨é…ç½®"""
    max_iterations: int = 5
    enable_deep_analysis: bool = True
    auto_fix_suggestions: bool = True
    save_iteration_logs: bool = True
    timeout_per_iteration: int = 300  # 5åˆ†é’Ÿ


class TestDrivenCoordinator:
    """
    æµ‹è¯•é©±åŠ¨åè°ƒå™¨ - æ‰©å±•åŠŸèƒ½
    
    è¿™æ˜¯ä¸€ä¸ªè£…é¥°å™¨æ¨¡å¼çš„å®ç°ï¼ŒåŒ…è£…ç°æœ‰çš„CentralizedCoordinator
    è€Œä¸æ˜¯ç»§æ‰¿æˆ–ä¿®æ”¹å®ƒ
    """
    
    def __init__(self, base_coordinator: CentralizedCoordinator, 
                 config: TestDrivenConfig = None):
        """
        åˆå§‹åŒ–æµ‹è¯•é©±åŠ¨åè°ƒå™¨
        
        Args:
            base_coordinator: ç°æœ‰çš„åè°ƒå™¨å®ä¾‹ï¼ˆä¸ä¼šè¢«ä¿®æ”¹ï¼‰
            config: æµ‹è¯•é©±åŠ¨é…ç½®
        """
        self.base_coordinator = base_coordinator
        self.config = config or TestDrivenConfig()
        self.logger = logging.getLogger(f"{__name__}.TestDrivenCoordinator")
        
        # æ‰©å±•åŠŸèƒ½çŠ¶æ€
        self.test_driven_sessions = {}
        self.iteration_history = {}
        
        # å¯¼å…¥æ‰©å±•è§£æå™¨
        from .enhanced_task_parser import EnhancedTaskParser
        from .test_analyzer import TestAnalyzer
        
        self.task_parser = EnhancedTaskParser()
        self.test_analyzer = TestAnalyzer()
        
        self.logger.info("ğŸ§ª æµ‹è¯•é©±åŠ¨åè°ƒå™¨æ‰©å±•å·²åˆå§‹åŒ–")
    
    # ==========================================
    # ğŸ¯ æ–°å¢çš„æµ‹è¯•é©±åŠ¨åŠŸèƒ½ï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰
    # ==========================================
    
    async def execute_test_driven_task(self, task_description: str,
                                     testbench_path: str = None,
                                     context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œæµ‹è¯•é©±åŠ¨ä»»åŠ¡ - æ–°å¢åŠŸèƒ½å…¥å£
        
        è¿™æ˜¯å®Œå…¨æ–°çš„åŠŸèƒ½ï¼Œä¸ä¼šå½±å“ç°æœ‰çš„coordinate_task_execution
        """
        session_id = f"tdd_{int(time.time())}"
        self.logger.info(f"ğŸš€ å¼€å§‹æµ‹è¯•é©±åŠ¨ä»»åŠ¡: {session_id}")
        
        try:
            # 1. è§£æå¢å¼ºä»»åŠ¡éœ€æ±‚
            enhanced_analysis = await self._parse_test_driven_requirements(
                task_description, testbench_path, context
            )
            
            if not enhanced_analysis["is_test_driven"]:
                # å¦‚æœä¸æ˜¯æµ‹è¯•é©±åŠ¨ä»»åŠ¡ï¼Œå›é€€åˆ°æ ‡å‡†æµç¨‹
                self.logger.info("ğŸ“‹ éæµ‹è¯•é©±åŠ¨ä»»åŠ¡ï¼Œä½¿ç”¨æ ‡å‡†æµç¨‹")
                return await self.base_coordinator.coordinate_task_execution(
                    task_description, context
                )
            
            # 2. éªŒè¯æµ‹è¯•å°ï¼ˆå¦‚æœæä¾›ï¼‰
            if enhanced_analysis.get("testbench_path"):
                validation = await self._validate_testbench(
                    enhanced_analysis["testbench_path"]
                )
                if not validation["valid"]:
                    return {
                        "success": False,
                        "error": f"æµ‹è¯•å°éªŒè¯å¤±è´¥: {validation['error']}",
                        "session_id": session_id
                    }
                enhanced_analysis["testbench_validation"] = validation
            
            # 3. æ‰§è¡Œæµ‹è¯•é©±åŠ¨å¾ªç¯
            result = await self._execute_tdd_loop(session_id, enhanced_analysis)
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•é©±åŠ¨ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id,
                "fallback_suggested": True
            }
    
    async def _parse_test_driven_requirements(self, task_description: str,
                                            testbench_path: str = None,
                                            context: Dict[str, Any] = None) -> Dict[str, Any]:
        """è§£ææµ‹è¯•é©±åŠ¨éœ€æ±‚"""
        return await self.task_parser.parse_enhanced_task(
            task_description, testbench_path, context
        )
    
    async def _validate_testbench(self, testbench_path: str) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•å°æ–‡ä»¶"""
        return await self.test_analyzer.validate_testbench_file(testbench_path)
    
    async def _execute_tdd_loop(self, session_id: str, 
                              enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæµ‹è¯•é©±åŠ¨å¼€å‘å¾ªç¯"""
        self.test_driven_sessions[session_id] = {
            "start_time": time.time(),
            "analysis": enhanced_analysis,
            "iterations": [],
            "status": "running"
        }
        
        max_iterations = self.config.max_iterations
        current_iteration = 0
        final_result = None
        
        self.logger.info(f"ğŸ”„ å¼€å§‹TDDå¾ªç¯ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
        
        while current_iteration < max_iterations:
            current_iteration += 1
            iteration_start = time.time()
            
            self.logger.info(f"ğŸ”„ ç¬¬ {current_iteration}/{max_iterations} æ¬¡è¿­ä»£")
            
            # æ‰§è¡Œå•æ¬¡è¿­ä»£
            iteration_result = await self._execute_single_tdd_iteration(
                session_id, current_iteration, enhanced_analysis
            )
            
            # è®°å½•è¿­ä»£ç»“æœ
            self.test_driven_sessions[session_id]["iterations"].append({
                "iteration": current_iteration,
                "start_time": iteration_start,
                "duration": time.time() - iteration_start,
                "result": iteration_result
            })
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            if iteration_result.get("all_tests_passed", False):
                self.logger.info(f"âœ… ç¬¬ {current_iteration} æ¬¡è¿­ä»£æˆåŠŸï¼")
                final_result = {
                    "success": True,
                    "session_id": session_id,
                    "total_iterations": current_iteration,
                    "final_design": iteration_result.get("design_files", []),
                    "test_results": iteration_result.get("test_results", {}),
                    "completion_reason": "tests_passed"
                }
                break
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡è¿­ä»£ï¼Œå‡†å¤‡æ”¹è¿›å»ºè®®
            if current_iteration < max_iterations:
                improvement_analysis = await self._analyze_for_improvement(
                    iteration_result, enhanced_analysis
                )
                enhanced_analysis["improvement_suggestions"] = improvement_analysis.get("suggestions", [])
        
        # å¦‚æœå¾ªç¯ç»“æŸä»æœªæˆåŠŸ
        if final_result is None:
            self.logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}")
            
            # ä»æœ€åä¸€æ¬¡è¿­ä»£ä¸­è·å–è®¾è®¡æ–‡ä»¶
            last_iteration = self.test_driven_sessions[session_id]["iterations"][-1] if self.test_driven_sessions[session_id]["iterations"] else {}
            final_design_files = last_iteration.get("result", {}).get("design_files", [])
            
            final_result = {
                "success": False,
                "session_id": session_id,
                "total_iterations": max_iterations,
                "final_design": final_design_files,
                "completion_reason": "max_iterations_reached",
                "error": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä½†æµ‹è¯•ä»æœªå…¨éƒ¨é€šè¿‡",
                "partial_results": self.test_driven_sessions[session_id]["iterations"]
            }
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        self.test_driven_sessions[session_id]["status"] = "completed"
        self.test_driven_sessions[session_id]["final_result"] = final_result
        
        return final_result
    
    async def _execute_single_tdd_iteration(self, session_id: str, iteration: int,
                                          enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•æ¬¡TDDè¿­ä»£"""
        self.logger.info(f"ğŸ¯ æ‰§è¡Œç¬¬ {iteration} æ¬¡è¿­ä»£")
        
        try:
            # é˜¶æ®µ1: è®¾è®¡ç”Ÿæˆ/ä¿®æ”¹
            design_result = await self._execute_design_phase(
                session_id, iteration, enhanced_analysis
            )
            
            if not design_result.get("success", False):
                return {
                    "success": False,
                    "phase": "design",
                    "error": design_result.get("error", "è®¾è®¡é˜¶æ®µå¤±è´¥"),
                    "all_tests_passed": False
                }
            
            # é˜¶æ®µ2: æµ‹è¯•æ‰§è¡Œ
            test_result = await self._execute_test_phase(
                session_id, iteration, design_result, enhanced_analysis
            )
            
            # ä»è®¾è®¡ç»“æœä¸­æå–æ–‡ä»¶å¼•ç”¨
            design_files = design_result.get("file_references", design_result.get("design_files", []))
            
            # åˆå¹¶ç»“æœ
            return {
                "success": True,
                "design_files": design_files,
                "test_results": test_result,
                "all_tests_passed": test_result.get("all_tests_passed", False),
                "iteration": iteration
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ç¬¬ {iteration} æ¬¡è¿­ä»£å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "all_tests_passed": False,
                "iteration": iteration
            }
    
    async def _execute_design_phase(self, session_id: str, iteration: int,
                                  enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè®¾è®¡é˜¶æ®µ - ä½¿ç”¨ç°æœ‰åè°ƒå™¨åŠŸèƒ½"""
        self.logger.info(f"ğŸ¨ è®¾è®¡é˜¶æ®µ - è¿­ä»£ {iteration}")
        
        # æ„å»ºè®¾è®¡ä»»åŠ¡
        design_task = self._build_design_task(enhanced_analysis, iteration)
        
        # ä½¿ç”¨ç°æœ‰åè°ƒå™¨æ‰§è¡Œè®¾è®¡ä»»åŠ¡ï¼ˆä¸ä¿®æ”¹ç°æœ‰åŠŸèƒ½ï¼‰
        result = await self.base_coordinator.coordinate_task_execution(
            design_task, enhanced_analysis.get("context", {})
        )
        
        return result
    
    async def _execute_test_phase(self, session_id: str, iteration: int,
                                design_result: Dict[str, Any],
                                enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæµ‹è¯•é˜¶æ®µ"""
        self.logger.info(f"ğŸ§ª æµ‹è¯•é˜¶æ®µ - è¿­ä»£ {iteration}")
        
        # å¦‚æœæœ‰ç”¨æˆ·æŒ‡å®šçš„æµ‹è¯•å°ï¼Œä½¿ç”¨æ‰©å±•æµ‹è¯•åŠŸèƒ½
        if enhanced_analysis.get("testbench_path"):
            # æå–è®¾è®¡æ–‡ä»¶å¼•ç”¨
            design_files = design_result.get("file_references", design_result.get("design_files", []))
            
            return await self.test_analyzer.run_with_user_testbench(
                design_files,
                enhanced_analysis["testbench_path"]
            )
        else:
            # ä½¿ç”¨æ ‡å‡†æµ‹è¯•æµç¨‹
            test_task = self._build_test_task(design_result, enhanced_analysis)
            result = await self.base_coordinator.coordinate_task_execution(
                test_task, enhanced_analysis.get("context", {})
            )
            return result
    
    async def _analyze_for_improvement(self, iteration_result: Dict[str, Any],
                                     enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¹¶ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        return await self.test_analyzer.analyze_test_failures(
            iteration_result.get("test_results", {}),
            enhanced_analysis
        )
    
    def _build_design_task(self, enhanced_analysis: Dict[str, Any], iteration: int) -> str:
        """æ„å»ºè®¾è®¡ä»»åŠ¡æè¿°"""
        base_requirements = enhanced_analysis.get("design_requirements", "")
        
        task = f"è®¾è®¡ä»»åŠ¡ (è¿­ä»£ {iteration}):\n\n{base_requirements}\n\n"
        
        if iteration > 1:
            suggestions = enhanced_analysis.get("improvement_suggestions", [])
            if suggestions:
                task += "æ”¹è¿›å»ºè®®:\n"
                for i, suggestion in enumerate(suggestions, 1):
                    task += f"{i}. {suggestion}\n"
        
        return task
    
    def _build_test_task(self, design_result: Dict[str, Any],
                        enhanced_analysis: Dict[str, Any]) -> str:
        """æ„å»ºæµ‹è¯•ä»»åŠ¡æè¿°"""
        design_files = design_result.get("design_files", [])
        testbench_path = enhanced_analysis.get("testbench_path")
        
        task = "æµ‹è¯•éªŒè¯ä»»åŠ¡:\n\n"
        task += f"è®¾è®¡æ–‡ä»¶: {[f.get('file_path', str(f)) for f in design_files]}\n"
        
        if testbench_path:
            task += f"ä½¿ç”¨æŒ‡å®šæµ‹è¯•å°: {testbench_path}\n"
        else:
            task += "ç”Ÿæˆé€‚å½“çš„æµ‹è¯•å°å¹¶è¿›è¡ŒéªŒè¯\n"
        
        task += "\nè¯·è¿è¡Œæµ‹è¯•å¹¶æŠ¥å‘Šç»“æœã€‚"
        
        return task
    
    # ==========================================
    # ğŸ” ä¼šè¯ç®¡ç†å’ŒæŸ¥è¯¢åŠŸèƒ½
    # ==========================================
    
    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–æµ‹è¯•é©±åŠ¨ä¼šè¯ä¿¡æ¯"""
        return self.test_driven_sessions.get(session_id)
    
    def list_active_sessions(self) -> List[str]:
        """åˆ—å‡ºæ´»è·ƒçš„æµ‹è¯•é©±åŠ¨ä¼šè¯"""
        return [sid for sid, info in self.test_driven_sessions.items() 
                if info.get("status") == "running"]
    
    def get_iteration_history(self, session_id: str) -> List[Dict[str, Any]]:
        """è·å–è¿­ä»£å†å²"""
        session = self.test_driven_sessions.get(session_id)
        return session.get("iterations", []) if session else []
    
    # ==========================================
    # ğŸ­ ä»£ç†æ–¹æ³• - ä¿æŒä¸ç°æœ‰åè°ƒå™¨çš„å®Œå…¨å…¼å®¹
    # ==========================================
    
    async def coordinate_task_execution(self, initial_task: str,
                                      context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ä»£ç†åŸæœ‰çš„coordinate_task_executionæ–¹æ³•
        
        ä¿æŒå®Œå…¨å‘åå…¼å®¹ï¼Œç°æœ‰ä»£ç æ— éœ€ä»»ä½•ä¿®æ”¹
        """
        return await self.base_coordinator.coordinate_task_execution(initial_task, context)
    
    def register_agent(self, agent):
        """ä»£ç†æ™ºèƒ½ä½“æ³¨å†Œ"""
        return self.base_coordinator.register_agent(agent)
    
    def get_registered_agents(self):
        """ä»£ç†è·å–å·²æ³¨å†Œæ™ºèƒ½ä½“"""
        return self.base_coordinator.get_registered_agents()
    
    # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šä»£ç†æ–¹æ³•...


# ==========================================
# ğŸ­ å·¥å‚å‡½æ•° - ä¾¿äºé›†æˆ
# ==========================================

def create_test_driven_coordinator(base_coordinator: CentralizedCoordinator,
                                 config: TestDrivenConfig = None) -> TestDrivenCoordinator:
    """
    åˆ›å»ºæµ‹è¯•é©±åŠ¨åè°ƒå™¨çš„å·¥å‚å‡½æ•°
    
    Usage:
        # ç°æœ‰ä»£ç 
        coordinator = CentralizedCoordinator(config)
        
        # å‡çº§ä¸ºæµ‹è¯•é©±åŠ¨åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰
        enhanced_coordinator = create_test_driven_coordinator(coordinator)
        
        # ç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å˜
        result = await enhanced_coordinator.coordinate_task_execution(task)
        
        # æ–°å¢æµ‹è¯•é©±åŠ¨åŠŸèƒ½
        tdd_result = await enhanced_coordinator.execute_test_driven_task(task, testbench_path)
    """
    return TestDrivenCoordinator(base_coordinator, config)
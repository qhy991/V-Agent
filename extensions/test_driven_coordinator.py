#!/usr/bin/env python3
"""
æµ‹è¯•é©±åŠ¨åè°ƒå™¨ - å®Œå…¨ç‹¬ç«‹çš„æ‰©å±•åŠŸèƒ½

è¿™æ˜¯ä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„æ‰©å±•æ¨¡å—ï¼Œä¸ä¿®æ”¹ä»»ä½•ç°æœ‰ä»£ç 
"""

import asyncio
import json
import time
import logging
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path
from dataclasses import dataclass

# å¯¼å…¥ç°æœ‰æ¡†æ¶ç»„ä»¶ - åªè¯»å–ï¼Œä¸ä¿®æ”¹
from core.centralized_coordinator import CentralizedCoordinator
from core.enums import AgentCapability, AgentStatus
from config.config import FrameworkConfig


@dataclass
class TestDrivenConfig:
    """æµ‹è¯•é©±åŠ¨é…ç½®"""
    max_iterations: int = 5
    enable_deep_analysis: bool = True
    auto_fix_suggestions: bool = True
    save_iteration_logs: bool = True
    timeout_per_iteration: int = 300  # 5åˆ†é’Ÿ


class TestDrivenCoordinator:
    """
    æµ‹è¯•é©±åŠ¨åè°ƒå™¨ - æ‰©å±•åŠŸèƒ½
    
    è¿™æ˜¯ä¸€ä¸ªè£…é¥°å™¨æ¨¡å¼çš„å®ç°ï¼ŒåŒ…è£…ç°æœ‰çš„CentralizedCoordinator
    è€Œä¸æ˜¯ç»§æ‰¿æˆ–ä¿®æ”¹å®ƒ
    """
    
    def __init__(self, base_coordinator: CentralizedCoordinator, 
                 config: TestDrivenConfig = None):
        """
        åˆå§‹åŒ–æµ‹è¯•é©±åŠ¨åè°ƒå™¨
        
        Args:
            base_coordinator: ç°æœ‰çš„åè°ƒå™¨å®ä¾‹ï¼ˆä¸ä¼šè¢«ä¿®æ”¹ï¼‰
            config: æµ‹è¯•é©±åŠ¨é…ç½®
        """
        self.base_coordinator = base_coordinator
        self.config = config or TestDrivenConfig()
        self.logger = logging.getLogger(f"{__name__}.TestDrivenCoordinator")
        
        # æ‰©å±•åŠŸèƒ½çŠ¶æ€
        self.test_driven_sessions = {}
        self.iteration_history = {}
        
        # å¯¼å…¥æ‰©å±•è§£æå™¨
        from .enhanced_task_parser import EnhancedTaskParser
        from .test_analyzer import TestAnalyzer
        
        self.task_parser = EnhancedTaskParser()
        self.test_analyzer = TestAnalyzer()
        
        self.logger.info("ğŸ§ª æµ‹è¯•é©±åŠ¨åè°ƒå™¨æ‰©å±•å·²åˆå§‹åŒ–")
    
    # ==========================================
    # ğŸ¯ æ–°å¢çš„æµ‹è¯•é©±åŠ¨åŠŸèƒ½ï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰
    # ==========================================
    
    async def execute_test_driven_task(self, task_description: str,
                                     testbench_path: str = None,
                                     context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ‰§è¡Œæµ‹è¯•é©±åŠ¨ä»»åŠ¡ - æ–°å¢åŠŸèƒ½å…¥å£
        
        è¿™æ˜¯å®Œå…¨æ–°çš„åŠŸèƒ½ï¼Œä¸ä¼šå½±å“ç°æœ‰çš„coordinate_task_execution
        """
        session_id = f"tdd_{int(time.time())}"
        self.logger.info(f"ğŸš€ å¼€å§‹æµ‹è¯•é©±åŠ¨ä»»åŠ¡: {session_id}")
        
        try:
            # 1. è§£æå¢å¼ºä»»åŠ¡éœ€æ±‚
            enhanced_analysis = await self._parse_test_driven_requirements(
                task_description, testbench_path, context
            )
            
            if not enhanced_analysis["is_test_driven"]:
                # å¦‚æœä¸æ˜¯æµ‹è¯•é©±åŠ¨ä»»åŠ¡ï¼Œå›é€€åˆ°æ ‡å‡†æµç¨‹
                self.logger.info("ğŸ“‹ éæµ‹è¯•é©±åŠ¨ä»»åŠ¡ï¼Œä½¿ç”¨æ ‡å‡†æµç¨‹")
                return await self.base_coordinator.coordinate_task_execution(
                    task_description, context
                )
            
            # 2. éªŒè¯æµ‹è¯•å°ï¼ˆå¦‚æœæä¾›ï¼‰
            if enhanced_analysis.get("testbench_path"):
                validation = await self._validate_testbench(
                    enhanced_analysis["testbench_path"]
                )
                if not validation["valid"]:
                    return {
                        "success": False,
                        "error": f"æµ‹è¯•å°éªŒè¯å¤±è´¥: {validation['error']}",
                        "session_id": session_id
                    }
                enhanced_analysis["testbench_validation"] = validation
            
            # 3. æ‰§è¡Œæµ‹è¯•é©±åŠ¨å¾ªç¯
            result = await self._execute_tdd_loop(session_id, enhanced_analysis)
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ æµ‹è¯•é©±åŠ¨ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id,
                "fallback_suggested": True
            }
    
    async def _parse_test_driven_requirements(self, task_description: str,
                                            testbench_path: str = None,
                                            context: Dict[str, Any] = None) -> Dict[str, Any]:
        """è§£ææµ‹è¯•é©±åŠ¨éœ€æ±‚"""
        return await self.task_parser.parse_enhanced_task(
            task_description, testbench_path, context
        )
    
    async def _validate_testbench(self, testbench_path: str) -> Dict[str, Any]:
        """éªŒè¯æµ‹è¯•å°æ–‡ä»¶"""
        return await self.test_analyzer.validate_testbench_file(testbench_path)
    
    async def _execute_tdd_loop(self, session_id: str, 
                              enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæµ‹è¯•é©±åŠ¨å¼€å‘å¾ªç¯"""
        self.test_driven_sessions[session_id] = {
            "start_time": time.time(),
            "analysis": enhanced_analysis,
            "iterations": [],
            "status": "running"
        }
        
        max_iterations = self.config.max_iterations
        current_iteration = 0
        final_result = None
        
        self.logger.info(f"ğŸ”„ å¼€å§‹TDDå¾ªç¯ï¼Œæœ€å¤§è¿­ä»£æ¬¡æ•°: {max_iterations}")
        
        while current_iteration < max_iterations:
            current_iteration += 1
            iteration_start = time.time()
            
            self.logger.info(f"ğŸ”„ ç¬¬ {current_iteration}/{max_iterations} æ¬¡è¿­ä»£")
            
            # æ‰§è¡Œå•æ¬¡è¿­ä»£
            iteration_result = await self._execute_single_tdd_iteration(
                session_id, current_iteration, enhanced_analysis
            )
            
            # è®°å½•è¿­ä»£ç»“æœ
            self.test_driven_sessions[session_id]["iterations"].append({
                "iteration": current_iteration,
                "start_time": iteration_start,
                "duration": time.time() - iteration_start,
                "result": iteration_result
            })
            
            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            if iteration_result.get("all_tests_passed", False):
                self.logger.info(f"âœ… ç¬¬ {current_iteration} æ¬¡è¿­ä»£æˆåŠŸï¼")
                final_result = {
                    "success": True,
                    "session_id": session_id,
                    "total_iterations": current_iteration,
                    "final_design": iteration_result.get("design_files", []),
                    "test_results": iteration_result.get("test_results", {}),
                    "completion_reason": "tests_passed"
                }
                break
            
            # å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡è¿­ä»£ï¼Œå‡†å¤‡æ”¹è¿›å»ºè®®
            if current_iteration < max_iterations:
                improvement_analysis = await self._analyze_for_improvement(
                    iteration_result, enhanced_analysis
                )
                enhanced_analysis["improvement_suggestions"] = improvement_analysis.get("suggestions", [])
                
                # ä¿å­˜å…·ä½“çš„é”™è¯¯ä¿¡æ¯ä»¥ä¼ é€’ç»™ä¸‹æ¬¡è¿­ä»£
                test_results = iteration_result.get("test_results", {})
                if not test_results.get("all_tests_passed", False):
                    # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šåˆ†ææµ‹è¯•ç»“æœå†…å®¹
                    self.logger.info(f"ğŸ” DEBUG: æµ‹è¯•å¤±è´¥ï¼Œåˆ†æé”™è¯¯ä¿¡æ¯ä¼ é€’")
                    self.logger.info(f"ğŸ” test_results keys: {list(test_results.keys())}")
                    
                    # ä¿å­˜ç¼–è¯‘é”™è¯¯ä¿¡æ¯
                    if "compile_stderr" in test_results:
                        stderr_content = test_results["compile_stderr"]
                        enhanced_analysis["last_compilation_errors"] = stderr_content
                        self.logger.info(f"ğŸ” DEBUG: ä¿å­˜ç¼–è¯‘é”™è¯¯ä¿¡æ¯: {stderr_content[:200]}...")
                    
                    # ä¿å­˜å¤±è´¥åŸå› 
                    if "failure_reasons" in test_results:
                        failure_reasons = test_results["failure_reasons"]
                        enhanced_analysis["last_failure_reasons"] = failure_reasons
                        self.logger.info(f"ğŸ” DEBUG: ä¿å­˜å¤±è´¥åŸå› : {failure_reasons}")
                    
                    # ä¿å­˜é”™è¯¯ç±»åˆ«
                    if "error_category" in test_results:
                        error_category = test_results["error_category"]
                        enhanced_analysis["last_error_category"] = error_category
                        self.logger.info(f"ğŸ” DEBUG: ä¿å­˜é”™è¯¯ç±»åˆ«: {error_category}")
                    
                    # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥improved_analysiså†…å®¹
                    self.logger.info(f"ğŸ” DEBUG: improvement_analysis keys: {list(improvement_analysis.keys())}")
                    if "suggestions" in improvement_analysis:
                        self.logger.info(f"ğŸ” DEBUG: æ”¹è¿›å»ºè®®æ•°é‡: {len(improvement_analysis['suggestions'])}")
                        for i, suggestion in enumerate(improvement_analysis["suggestions"][:3]):
                            self.logger.info(f"ğŸ” DEBUG: å»ºè®®{i+1}: {suggestion[:100]}...")
        
        # å¦‚æœå¾ªç¯ç»“æŸä»æœªæˆåŠŸ
        if final_result is None:
            self.logger.warning(f"âš ï¸ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•° {max_iterations}")
            
            # ä»æœ€åä¸€æ¬¡è¿­ä»£ä¸­è·å–è®¾è®¡æ–‡ä»¶
            last_iteration = self.test_driven_sessions[session_id]["iterations"][-1] if self.test_driven_sessions[session_id]["iterations"] else {}
            final_design_files = last_iteration.get("result", {}).get("design_files", [])
            
            final_result = {
                "success": False,
                "session_id": session_id,
                "total_iterations": max_iterations,
                "final_design": final_design_files,
                "completion_reason": "max_iterations_reached",
                "error": "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä½†æµ‹è¯•ä»æœªå…¨éƒ¨é€šè¿‡",
                "partial_results": self.test_driven_sessions[session_id]["iterations"]
            }
        
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        self.test_driven_sessions[session_id]["status"] = "completed"
        self.test_driven_sessions[session_id]["final_result"] = final_result
        
        return final_result
    
    async def _execute_single_tdd_iteration(self, session_id: str, iteration: int,
                                          enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œå•æ¬¡TDDè¿­ä»£"""
        self.logger.info(f"ğŸ¯ æ‰§è¡Œç¬¬ {iteration} æ¬¡è¿­ä»£")
        
        try:
            # é˜¶æ®µ1: è®¾è®¡ç”Ÿæˆ/ä¿®æ”¹
            design_result = await self._execute_design_phase(
                session_id, iteration, enhanced_analysis
            )
            
            if not design_result.get("success", False):
                return {
                    "success": False,
                    "phase": "design",
                    "error": design_result.get("error", "è®¾è®¡é˜¶æ®µå¤±è´¥"),
                    "all_tests_passed": False
                }
            
            # ä»è®¾è®¡ç»“æœä¸­æå–æ–‡ä»¶å¼•ç”¨ï¼ˆå¢å¼ºç‰ˆï¼‰
            design_files = self._extract_file_references(design_result)
            
            # é˜¶æ®µ2: æµ‹è¯•æ‰§è¡Œ
            test_result = await self._execute_test_phase(
                session_id, iteration, design_result, enhanced_analysis, design_files
            )
            
            # åˆå¹¶ç»“æœ
            return {
                "success": True,
                "design_files": design_files,
                "test_results": test_result,
                "all_tests_passed": test_result.get("all_tests_passed", False),
                "iteration": iteration
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ç¬¬ {iteration} æ¬¡è¿­ä»£å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "all_tests_passed": False,
                "iteration": iteration
            }
    
    async def _execute_design_phase(self, session_id: str, iteration: int,
                                  enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œè®¾è®¡é˜¶æ®µ - ä½¿ç”¨ç°æœ‰åè°ƒå™¨åŠŸèƒ½"""
        self.logger.info(f"ğŸ¨ è®¾è®¡é˜¶æ®µ - è¿­ä»£ {iteration}")
        
        # æ„å»ºè®¾è®¡ä»»åŠ¡
        design_task = self._build_design_task(enhanced_analysis, iteration)
        
        # ğŸ”§ ä¿®å¤ï¼šåœ¨TDDåœºæ™¯ä¸­ï¼Œå¼ºåˆ¶æŒ‡å®šè¿™æ˜¯è®¾è®¡ä»»åŠ¡ï¼Œé¿å…è¢«è¯¯åˆ¤ä¸ºreviewä»»åŠ¡
        tdd_context = enhanced_analysis.get("context", {}).copy()
        tdd_context["force_task_type"] = "design"  # å¼ºåˆ¶æŒ‡å®šä¸ºè®¾è®¡ä»»åŠ¡
        tdd_context["preferred_agent_role"] = "verilog_designer"  # ä¼˜å…ˆé€‰æ‹©Verilogè®¾è®¡æ™ºèƒ½ä½“
        
        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½•å¼ºåˆ¶ä»»åŠ¡ç±»å‹
        self.logger.info(f"ğŸ”§ DEBUG: TDDè®¾è®¡é˜¶æ®µ - å¼ºåˆ¶ä»»åŠ¡ç±»å‹ä¸ºdesignï¼Œä¼˜å…ˆagent: verilog_designer")
        
        # ä½¿ç”¨ç°æœ‰åè°ƒå™¨æ‰§è¡Œè®¾è®¡ä»»åŠ¡ï¼ˆä¸ä¿®æ”¹ç°æœ‰åŠŸèƒ½ï¼‰
        result = await self.base_coordinator.coordinate_task_execution(
            design_task, tdd_context
        )
        
        return result
    
    async def _execute_test_phase(self, session_id: str, iteration: int,
                                design_result: Dict[str, Any],
                                enhanced_analysis: Dict[str, Any],
                                design_files: List[Dict[str, Any]] = None) -> Dict[str, Any]:
        """æ‰§è¡Œæµ‹è¯•é˜¶æ®µ"""
        self.logger.info(f"ğŸ§ª æµ‹è¯•é˜¶æ®µ - è¿­ä»£ {iteration}")
        
        # æ™ºèƒ½é€‰æ‹©æµ‹è¯•æ‰§è¡Œæ–¹å¼
        user_testbench_path = enhanced_analysis.get("testbench_path")
        
        # ä»å½“å‰è¿­ä»£çš„æ–‡ä»¶ä¸­æŸ¥æ‰¾ç”Ÿæˆçš„æµ‹è¯•å°
        current_iteration_testbench = None
        if design_files:
            for file_ref in design_files:
                if (isinstance(file_ref, dict) and 
                    file_ref.get("file_type") == "testbench" and 
                    file_ref.get("file_path")):
                    current_iteration_testbench = file_ref["file_path"]
                    self.logger.info(f"ğŸ¯ æ‰¾åˆ°å½“å‰è¿­ä»£æµ‹è¯•å°: {current_iteration_testbench}")
                    break
        
        # ç»Ÿä¸€çš„æ™ºèƒ½testbenché€‰æ‹©ç­–ç•¥
        testbench_strategy = self._determine_testbench_strategy(
            iteration, user_testbench_path, current_iteration_testbench
        )
        
        testbench_to_use = testbench_strategy["selected_testbench"]
        self.logger.info(f"ğŸ¯ ç¬¬{iteration}æ¬¡è¿­ä»£ï¼Œtestbenchç­–ç•¥: {testbench_strategy['strategy']}")
        self.logger.info(f"ğŸ“ ç­–ç•¥è¯´æ˜: {testbench_strategy['reason']}")
        
        if testbench_to_use:
            # ä½¿ç”¨æŒ‡å®šçš„æµ‹è¯•å°ï¼ˆç”¨æˆ·æŒ‡å®šæˆ–å½“å‰è¿­ä»£ç”Ÿæˆï¼‰
            self.logger.info(f"ğŸ§ª ä½¿ç”¨æµ‹è¯•å°æ–‡ä»¶: {testbench_to_use}")
            
            # ä¸¥æ ¼å‡†å¤‡è®¾è®¡æ–‡ä»¶åˆ—è¡¨ï¼ˆæ’é™¤æµ‹è¯•å°æ–‡ä»¶ï¼Œç¡®ä¿æ–‡ä»¶å­˜åœ¨ï¼‰
            design_only_files = []
            if design_files is None:
                design_files = design_result.get("file_references", design_result.get("design_files", []))
            
            self.logger.info(f"ğŸ” å‡†å¤‡è®¾è®¡æ–‡ä»¶ï¼Œè¾“å…¥æ–‡ä»¶æ€»æ•°: {len(design_files) if design_files else 0}")
            
            for i, file_ref in enumerate(design_files):
                if isinstance(file_ref, dict):
                    file_path = file_ref.get("file_path")
                    file_type = file_ref.get("file_type")
                    filename = Path(file_path).name if file_path else "unknown"
                    
                    self.logger.info(f"  æ–‡ä»¶{i+1}: {filename} (ç±»å‹: {file_type}, è·¯å¾„: {file_path})")
                    
                    # éªŒè¯æ˜¯è®¾è®¡æ–‡ä»¶ï¼ˆéæµ‹è¯•å°ï¼‰ä¸”æ–‡ä»¶å­˜åœ¨
                    if (file_type == "verilog" and 
                        file_path and 
                        Path(file_path).exists() and
                        not any(keyword in filename.lower() for keyword in ['_tb.v', 'testbench', '_test'])):
                        
                        design_only_files.append(file_ref)
                        self.logger.info(f"  âœ… é€‰æ‹©è®¾è®¡æ–‡ä»¶: {filename}")
                    else:
                        reason = "æœªçŸ¥åŸå› "
                        if file_type != "verilog":
                            reason = f"æ–‡ä»¶ç±»å‹ä¸æ˜¯verilog ({file_type})"
                        elif not file_path:
                            reason = "æ–‡ä»¶è·¯å¾„ä¸ºç©º"
                        elif not Path(file_path).exists():
                            reason = "æ–‡ä»¶ä¸å­˜åœ¨"
                        elif any(keyword in filename.lower() for keyword in ['_tb.v', 'testbench', '_test']):
                            reason = "æ˜¯æµ‹è¯•å°æ–‡ä»¶"
                        self.logger.info(f"  â­ï¸ è·³è¿‡æ–‡ä»¶: {filename} ({reason})")
            
            self.logger.info(f"ğŸ¯ æœ€ç»ˆé€‰æ‹©çš„è®¾è®¡æ–‡ä»¶æ•°é‡: {len(design_only_files)}")
            
            return await self.test_analyzer.run_with_user_testbench(
                design_only_files,
                testbench_to_use
            )
        else:
            # å›é€€åˆ°æ ‡å‡†æµ‹è¯•æµç¨‹ï¼ˆç”Ÿæˆæ–°çš„æµ‹è¯•å°ï¼‰
            self.logger.info("ğŸ”„ æœªæ‰¾åˆ°æµ‹è¯•å°æ–‡ä»¶ï¼Œä½¿ç”¨æ ‡å‡†æµ‹è¯•æµç¨‹ç”Ÿæˆæµ‹è¯•å°")
            test_task = self._build_test_task(design_result, enhanced_analysis)
            result = await self.base_coordinator.coordinate_task_execution(
                test_task, enhanced_analysis.get("context", {})
            )
            return result
    
    async def _analyze_for_improvement(self, iteration_result: Dict[str, Any],
                                     enhanced_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æå¹¶ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        return await self.test_analyzer.analyze_test_failures(
            iteration_result.get("test_results", {}),
            enhanced_analysis
        )
    
    def _build_design_task(self, enhanced_analysis: Dict[str, Any], iteration: int) -> str:
        """æ„å»ºè®¾è®¡ä»»åŠ¡æè¿°"""
        base_requirements = enhanced_analysis.get("design_requirements", "")
        
        task = f"è®¾è®¡ä»»åŠ¡ (è¿­ä»£ {iteration}):\n\n{base_requirements}\n\n"
        
        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½•enhanced_analysiså†…å®¹
        if iteration > 1:
            self.logger.info(f"ğŸ” DEBUG: æ„å»ºç¬¬{iteration}æ¬¡è¿­ä»£è®¾è®¡ä»»åŠ¡")
            self.logger.info(f"ğŸ” enhanced_analysis keys: {list(enhanced_analysis.keys())}")
            
            debug_keys = ["last_compilation_errors", "last_failure_reasons", "improvement_suggestions"]
            for key in debug_keys:
                if key in enhanced_analysis:
                    content = enhanced_analysis[key]
                    if isinstance(content, str):
                        self.logger.info(f"ğŸ” DEBUG: {key}: {content[:150]}...")
                    else:
                        self.logger.info(f"ğŸ” DEBUG: {key}: {content}")
                else:
                    self.logger.warning(f"ğŸ” DEBUG: ç¼ºå°‘å…³é”®å­—æ®µ: {key}")
        
        if iteration > 1:
            # æ·»åŠ å…·ä½“çš„é”™è¯¯åé¦ˆä¿¡æ¯
            last_errors = enhanced_analysis.get("last_compilation_errors", "")
            if last_errors:
                task += f"âŒ ä¸Šæ¬¡è¿­ä»£ç¼–è¯‘é”™è¯¯:\n{last_errors}\n\n"
                
                # ğŸ¯ é’ˆå¯¹å…·ä½“é”™è¯¯çš„ç‰¹æ®Šå¤„ç†
                if "rst_n" in last_errors and "not a port" in last_errors:
                    task += "ğŸš¨ **ã€è‡´å‘½é”™è¯¯ã€‘æ¥å£ä¸åŒ¹é… - å¿…é¡»ç«‹å³ä¿®å¤**:\n"
                    task += "âŒ **é”™è¯¯ç°è±¡**: æµ‹è¯•å°è¿æ¥ `.rst_n(rst_n)` ä½†æ¨¡å—å®šä¹‰çš„æ˜¯ `input rst`\n"
                    task += "âŒ **å¤±è´¥åŸå› **: ç«¯å£åç§°ä¸åŒ¹é…å¯¼è‡´ç¼–è¯‘å¤±è´¥\n"
                    task += "âœ… **å¼ºåˆ¶è¦æ±‚**: \n"
                    task += "   1. å°†æ¨¡å—å£°æ˜ä¸­çš„ `input rst` æ”¹ä¸º `input rst_n`\n"
                    task += "   2. å°†å¤ä½é€»è¾‘ä¸­çš„ `posedge rst` æ”¹ä¸º `negedge rst_n`\n"
                    task += "   3. å°†å¤ä½æ¡ä»¶ä¸­çš„ `if (rst)` æ”¹ä¸º `if (!rst_n)`\n"
                    task += "ğŸ”¥ **æ³¨æ„**: è¿™æ˜¯ç¼–è¯‘é”™è¯¯ï¼Œä¸ä¿®å¤å°±æ— æ³•é€šè¿‡æµ‹è¯•ï¼\n\n"
                elif "port" in last_errors and "not a port" in last_errors:
                    # æå–ç«¯å£å
                    import re
                    port_match = re.search(r"port\s+[`'\"]*(\w+)[`'\"]*\s+is not a port", last_errors)
                    if port_match:
                        missing_port = port_match.group(1)
                        task += f"ğŸš¨ **ç«¯å£ä¸åŒ¹é…é”™è¯¯**:\n"
                        task += f"- æµ‹è¯•å°æœŸæœ›ç«¯å£: `{missing_port}`\n"
                        task += f"- å½“å‰æ¨¡å—æ¥å£ç¼ºå°‘æ­¤ç«¯å£\n"
                        task += f"- **å¿…é¡»ä¿®å¤**: åœ¨æ¨¡å—æ¥å£ä¸­æ·»åŠ  `{missing_port}` ç«¯å£\n\n"
            
            # æ·»åŠ é”™è¯¯åˆ†æç»“æœ
            failure_reasons = enhanced_analysis.get("last_failure_reasons", [])
            if failure_reasons:
                task += "ğŸ” å¤±è´¥åŸå› åˆ†æ:\n"
                for reason in failure_reasons:
                    task += f"- {reason}\n"
                task += "\n"
            
            # æ·»åŠ æ”¹è¿›å»ºè®®
            suggestions = enhanced_analysis.get("improvement_suggestions", [])
            if suggestions:
                task += "ğŸ’¡ æ”¹è¿›å»ºè®®:\n"
                for i, suggestion in enumerate(suggestions, 1):
                    task += f"{i}. {suggestion}\n"
                task += "\n"
            
            # å¼ºè°ƒä¿®å¤è¦æ±‚
            task += "âš ï¸ **å…³é”®è¦æ±‚**: è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°é”™è¯¯åˆ†æä¿®å¤æ¥å£é—®é¢˜ã€‚\n"
            task += "âœ… **éªŒè¯æ ‡å‡†**: ç¡®ä¿ç”Ÿæˆçš„æ¨¡å—æ¥å£ä¸æµ‹è¯•å°å®ä¾‹åŒ–å®Œå…¨åŒ¹é…ã€‚\n\n"
        
        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè¾“å‡ºæœ€ç»ˆä»»åŠ¡å†…å®¹
        if iteration > 1:
            self.logger.info(f"ğŸ” DEBUG: ç¬¬{iteration}æ¬¡è¿­ä»£æœ€ç»ˆä»»åŠ¡å†…å®¹:")
            self.logger.info(f"ğŸ” Task length: {len(task)} å­—ç¬¦")
            # åˆ†æ®µè¾“å‡ºä»»åŠ¡å†…å®¹ï¼Œä¾¿äºæŸ¥çœ‹
            task_lines = task.split('\n')
            for i, line in enumerate(task_lines[:20]):  # åªæ˜¾ç¤ºå‰20è¡Œ
                self.logger.info(f"ğŸ” Task L{i+1}: {line}")
            if len(task_lines) > 20:
                self.logger.info(f"ğŸ” ... (æ€»å…± {len(task_lines)} è¡Œ)")
        
        return task
    
    def _build_test_task(self, design_result: Dict[str, Any],
                        enhanced_analysis: Dict[str, Any]) -> str:
        """æ„å»ºæµ‹è¯•ä»»åŠ¡æè¿°"""
        design_files = design_result.get("design_files", [])
        testbench_path = enhanced_analysis.get("testbench_path")
        
        task = "æµ‹è¯•éªŒè¯ä»»åŠ¡:\n\n"
        task += f"è®¾è®¡æ–‡ä»¶: {[f.get('file_path', str(f)) for f in design_files]}\n"
        
        if testbench_path:
            task += f"ä½¿ç”¨æŒ‡å®šæµ‹è¯•å°: {testbench_path}\n"
        else:
            task += "ç”Ÿæˆé€‚å½“çš„æµ‹è¯•å°å¹¶è¿›è¡ŒéªŒè¯\n"
        
        task += "\nè¯·è¿è¡Œæµ‹è¯•å¹¶æŠ¥å‘Šç»“æœã€‚"
        
        return task
    
    # ==========================================
    # ğŸ” ä¼šè¯ç®¡ç†å’ŒæŸ¥è¯¢åŠŸèƒ½
    # ==========================================
    
    def get_session_info(self, session_id: str) -> Optional[Dict[str, Any]]:
        """è·å–æµ‹è¯•é©±åŠ¨ä¼šè¯ä¿¡æ¯"""
        return self.test_driven_sessions.get(session_id)
    
    def list_active_sessions(self) -> List[str]:
        """åˆ—å‡ºæ´»è·ƒçš„æµ‹è¯•é©±åŠ¨ä¼šè¯"""
        return [sid for sid, info in self.test_driven_sessions.items() 
                if info.get("status") == "running"]
    
    def get_iteration_history(self, session_id: str) -> List[Dict[str, Any]]:
        """è·å–è¿­ä»£å†å²"""
        session = self.test_driven_sessions.get(session_id)
        return session.get("iterations", []) if session else []
    
    # ==========================================
    # ğŸ­ ä»£ç†æ–¹æ³• - ä¿æŒä¸ç°æœ‰åè°ƒå™¨çš„å®Œå…¨å…¼å®¹
    # ==========================================
    
    async def coordinate_task_execution(self, initial_task: str,
                                      context: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        ä»£ç†åŸæœ‰çš„coordinate_task_executionæ–¹æ³•
        
        ä¿æŒå®Œå…¨å‘åå…¼å®¹ï¼Œç°æœ‰ä»£ç æ— éœ€ä»»ä½•ä¿®æ”¹
        """
        return await self.base_coordinator.coordinate_task_execution(initial_task, context)
    
    def register_agent(self, agent):
        """ä»£ç†æ™ºèƒ½ä½“æ³¨å†Œ"""
        return self.base_coordinator.register_agent(agent)
    
    def get_registered_agents(self):
        """ä»£ç†è·å–å·²æ³¨å†Œæ™ºèƒ½ä½“"""
        return self.base_coordinator.get_registered_agents()
    
    # å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ æ›´å¤šä»£ç†æ–¹æ³•...
    
    def _extract_file_references(self, agent_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»æ™ºèƒ½ä½“ç»“æœä¸­æå–æ–‡ä»¶å¼•ç”¨ï¼ˆç»Ÿä¸€ç­–ç•¥ç‰ˆï¼‰"""
        file_references = []
        
        # ğŸ¯ ç­–ç•¥1ï¼šä¼˜å…ˆä»å·¥å…·è°ƒç”¨ç»“æœä¸­æå–æ–‡ä»¶å¼•ç”¨ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        if "tool_results" in agent_result:
            for tool_result in agent_result["tool_results"]:
                if isinstance(tool_result, dict) and tool_result.get("success"):
                    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ–‡ä»¶å¼•ç”¨ä¿¡æ¯
                    if "file_reference" in tool_result:
                        file_references.append(tool_result["file_reference"])
                        self.logger.info(f"âœ… ä»å·¥å…·ç»“æœæå–æ–‡ä»¶å¼•ç”¨: {tool_result['file_reference'].get('file_path', 'unknown')}")
                    elif "file_path" in tool_result and tool_result.get("file_path"):
                        # æ„å»ºå®Œæ•´çš„æ–‡ä»¶å¼•ç”¨æ ¼å¼
                        file_ref = {
                            "file_path": tool_result["file_path"],
                            "file_type": tool_result.get("file_type", "verilog"),
                            "file_id": tool_result.get("file_id"),
                            "created_by": tool_result.get("created_by"),
                            "created_at": tool_result.get("created_at"),
                            "description": tool_result.get("description", "")
                        }
                        file_references.append(file_ref)
                        self.logger.info(f"âœ… æ„å»ºæ–‡ä»¶å¼•ç”¨: {file_ref['file_path']} (ç±»å‹: {file_ref['file_type']})")
        
        # ğŸ¯ ç­–ç•¥2ï¼šä»ä¼ ç»Ÿæ ¼å¼ä¸­æå–ï¼ˆä¸­ç­‰ä¼˜å…ˆçº§ï¼‰
        legacy_formats = ["file_references", "design_files"]
        for format_key in legacy_formats:
            if format_key in agent_result and agent_result[format_key]:
                file_references.extend(agent_result[format_key])
                self.logger.info(f"âœ… ä»{format_key}æå– {len(agent_result[format_key])} ä¸ªæ–‡ä»¶å¼•ç”¨")
        
        # ğŸ¯ ç­–ç•¥3ï¼šæ™ºèƒ½ä»ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨è·å–ï¼ˆä»…åœ¨å‰ä¸¤ç§ç­–ç•¥éƒ½å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        if not file_references:
            self.logger.warning("âš ï¸ å·¥å…·ç»“æœä¸­æœªæ‰¾åˆ°æ–‡ä»¶å¼•ç”¨ï¼Œå°è¯•ä»ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨è·å–")
            file_references = self._intelligent_file_retrieval_from_manager()
        
        # ğŸ¯ ç­–ç•¥4ï¼šæ–‡ä»¶å¼•ç”¨å»é‡å’ŒéªŒè¯
        validated_references = self._validate_and_deduplicate_file_references(file_references)
        
        self.logger.info(f"ğŸ“„ æœ€ç»ˆæå–åˆ° {len(validated_references)} ä¸ªæœ‰æ•ˆæ–‡ä»¶å¼•ç”¨")
        return validated_references
    
    def _intelligent_file_retrieval_from_manager(self) -> List[Dict[str, Any]]:
        """æ™ºèƒ½ä»ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨è·å–æ–‡ä»¶ï¼ˆå¤‡ç”¨ç­–ç•¥ï¼‰"""
        file_references = []
        
        try:
            from core.file_manager import get_file_manager
            file_manager = get_file_manager()
            
            # ğŸ¯ ç²¾ç¡®ç­–ç•¥ï¼šåªè·å–æœ€è¿‘5åˆ†é’Ÿå†…åˆ›å»ºçš„æ–‡ä»¶ï¼Œé¿å…å†å²æ±¡æŸ“
            import datetime
            recent_cutoff = (datetime.datetime.now() - datetime.timedelta(minutes=5)).isoformat()
            
            # ğŸ¯ é‡ç‚¹å…³æ³¨å½“å‰TDDè¿­ä»£ç›¸å…³çš„æ™ºèƒ½ä½“
            priority_agents = ["enhanced_real_verilog_agent", "real_verilog_agent"]
            current_iteration_files = []
            
            for agent_id in priority_agents:
                try:
                    agent_files = file_manager.get_files_by_creator(agent_id)
                    # åªå–æœ€è¿‘5åˆ†é’Ÿçš„æ–‡ä»¶
                    recent_files = [f for f in agent_files if f.created_at > recent_cutoff]
                    current_iteration_files.extend(recent_files)
                    self.logger.debug(f"ä» {agent_id} è·å–åˆ° {len(recent_files)} ä¸ªæœ€è¿‘æ–‡ä»¶")
                except Exception as e:
                    self.logger.debug(f"è·å– {agent_id} æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰
            current_iteration_files.sort(key=lambda x: x.created_at, reverse=True)
            
            # ğŸ¯ ä¸¥æ ¼é€‰æ‹©ï¼šæ¯ç§ç±»å‹åªé€‰æ‹©1ä¸ªæœ€æ–°çš„ã€æ–‡ä»¶åä¸é‡å¤çš„æ–‡ä»¶
            selected_designs = {}  # module_name -> file_ref
            selected_testbenches = {}  # module_name -> file_ref
            
            for file_ref in current_iteration_files:
                filename = Path(file_ref.file_path).name
                module_name = Path(file_ref.file_path).stem
                
                # ç§»é™¤å¸¸è§çš„åç¼€æ¥è·å–æ ¸å¿ƒæ¨¡å—å
                for suffix in ['_tb', '_test', '_testbench']:
                    if module_name.endswith(suffix):
                        module_name = module_name[:-len(suffix)]
                        break
                
                # åˆ†ç±»å¤„ç†
                is_testbench = any(keyword in filename.lower() for keyword in ['_tb.v', 'testbench', '_test'])
                
                if not is_testbench and file_ref.file_type == "verilog":
                    # è®¾è®¡æ–‡ä»¶ï¼šæ¯ä¸ªæ¨¡å—åªä¿ç•™æœ€æ–°çš„
                    if module_name not in selected_designs:
                        selected_designs[module_name] = file_ref
                        self.logger.info(f"ğŸ¯ é€‰æ‹©è®¾è®¡æ–‡ä»¶: {filename} (æ¨¡å—: {module_name})")
                elif is_testbench and file_ref.file_type in ["verilog", "testbench"]:
                    # æµ‹è¯•å°æ–‡ä»¶ï¼šæ¯ä¸ªæ¨¡å—åªä¿ç•™æœ€æ–°çš„
                    if module_name not in selected_testbenches:
                        selected_testbenches[module_name] = file_ref
                        self.logger.info(f"ğŸ¯ é€‰æ‹©æµ‹è¯•å°æ–‡ä»¶: {filename} (æ¨¡å—: {module_name})")
            
            # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
            for file_ref in list(selected_designs.values()) + list(selected_testbenches.values()):
                file_references.append({
                    "file_id": file_ref.file_id,
                    "file_path": file_ref.file_path,
                    "file_type": file_ref.file_type,
                    "created_by": file_ref.created_by,
                    "created_at": file_ref.created_at,
                    "description": file_ref.description
                })
            
            self.logger.info(f"ğŸ” æ™ºèƒ½é€‰æ‹©: {len(selected_designs)} ä¸ªè®¾è®¡æ–‡ä»¶, {len(selected_testbenches)} ä¸ªæµ‹è¯•å°æ–‡ä»¶")
            
        except Exception as e:
            self.logger.error(f"âŒ ä»ä¸­å¤®æ–‡ä»¶ç®¡ç†å™¨è·å–æ–‡ä»¶å¤±è´¥: {e}")
        
        return file_references
    
    def _validate_and_deduplicate_file_references(self, file_references: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """éªŒè¯å¹¶å»é‡æ–‡ä»¶å¼•ç”¨ï¼Œæ™ºèƒ½é€‰æ‹©æœ€æ–°ç‰ˆæœ¬"""
        validated_refs = []
        seen_paths = set()
        seen_file_ids = set()
        
        # ğŸ¯ æŒ‰æ¨¡å—ååˆ†ç»„ï¼Œæ¯ä¸ªæ¨¡å—åªä¿ç•™æœ€æ–°çš„è®¾è®¡æ–‡ä»¶
        module_files = {}  # module_name -> [file_refs]
        
        for file_ref in file_references:
            if not isinstance(file_ref, dict):
                continue
                
            file_path = file_ref.get("file_path")
            file_id = file_ref.get("file_id")
            
            # è·³è¿‡æ— æ•ˆçš„æ–‡ä»¶å¼•ç”¨
            if not file_path:
                self.logger.warning("âš ï¸ è·³è¿‡æ— æ•ˆæ–‡ä»¶å¼•ç”¨ï¼ˆç¼ºå°‘file_pathï¼‰")
                continue
            
            # æ–‡ä»¶å­˜åœ¨æ€§æ£€æŸ¥
            if not Path(file_path).exists():
                self.logger.warning(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {file_path}")
                continue
            
            # æå–æ¨¡å—å
            filename = Path(file_path).name
            module_name = Path(file_path).stem
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯è®¾è®¡æ–‡ä»¶ï¼ˆéæµ‹è¯•å°ï¼‰
            is_testbench = any(keyword in filename.lower() for keyword in ['_tb.v', 'testbench', '_test'])
            
            if not is_testbench and file_ref.get("file_type") == "verilog":
                # è®¾è®¡æ–‡ä»¶ï¼šæŒ‰æ¨¡å—ååˆ†ç»„
                base_module_name = module_name.split('_')[0]  # å»é™¤ç‰ˆæœ¬åç¼€ï¼Œå¦‚ counter_8bit_2 -> counter
                
                if base_module_name not in module_files:
                    module_files[base_module_name] = []
                module_files[base_module_name].append(file_ref)
            else:
                # æµ‹è¯•å°æ–‡ä»¶å’Œå…¶ä»–æ–‡ä»¶ç›´æ¥æ·»åŠ ï¼ˆä¸éœ€è¦ç‰ˆæœ¬æ§åˆ¶ï¼‰
                if file_path not in seen_paths and (not file_id or file_id not in seen_file_ids):
                    validated_refs.append(file_ref)
                    seen_paths.add(file_path)
                    if file_id:
                        seen_file_ids.add(file_id)
                    self.logger.debug(f"âœ… éªŒè¯é€šè¿‡ï¼ˆæµ‹è¯•å°/å…¶ä»–ï¼‰: {filename}")
        
        # ğŸ¯ å¯¹æ¯ä¸ªæ¨¡å—ï¼Œåªé€‰æ‹©æœ€æ–°çš„è®¾è®¡æ–‡ä»¶
        for module_name, files in module_files.items():
            if not files:
                continue
            
            # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„
            files_sorted = sorted(files, key=lambda x: x.get("created_at", ""), reverse=True)
            latest_file = files_sorted[0]
            
            file_path = latest_file.get("file_path")
            file_id = latest_file.get("file_id")
            
            # é¿å…é‡å¤
            if file_path not in seen_paths and (not file_id or file_id not in seen_file_ids):
                validated_refs.append(latest_file)
                seen_paths.add(file_path)
                if file_id:
                    seen_file_ids.add(file_id)
                
                self.logger.info(f"ğŸ¯ é€‰æ‹©æœ€æ–°è®¾è®¡æ–‡ä»¶: {Path(file_path).name} (æ¨¡å—: {module_name})")
                
                # è®°å½•è¢«è·³è¿‡çš„æ—§ç‰ˆæœ¬
                if len(files) > 1:
                    skipped_files = [Path(f.get("file_path", "")).name for f in files_sorted[1:]]
                    self.logger.debug(f"â­ï¸ è·³è¿‡æ—§ç‰ˆæœ¬: {', '.join(skipped_files)}")
        
        return validated_refs
    
    def _determine_testbench_strategy(self, iteration: int, user_testbench_path: str, 
                                     current_iteration_testbench: str) -> Dict[str, str]:
        """ç»Ÿä¸€çš„testbenché€‰æ‹©ç­–ç•¥"""
        strategy_info = {
            "selected_testbench": None,
            "strategy": "æœªå®šä¹‰",
            "reason": "æ— å¯ç”¨æµ‹è¯•å°"
        }
        
        # æ£€æŸ¥å¯ç”¨çš„testbenché€‰é¡¹
        has_user_testbench = user_testbench_path and Path(user_testbench_path).exists()
        has_generated_testbench = current_iteration_testbench and Path(current_iteration_testbench).exists()
        
        self.logger.debug(f"testbenchå¯ç”¨æ€§: ç”¨æˆ·æä¾›={has_user_testbench}, æ™ºèƒ½ä½“ç”Ÿæˆ={has_generated_testbench}")
        
        if iteration == 1:
            # ç¬¬ä¸€æ¬¡è¿­ä»£ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æä¾›çš„ï¼Œå»ºç«‹åŸºå‡†
            if has_user_testbench:
                strategy_info.update({
                    "selected_testbench": user_testbench_path,
                    "strategy": "ç”¨æˆ·åŸºå‡†",
                    "reason": "ç¬¬1æ¬¡è¿­ä»£ä½¿ç”¨ç”¨æˆ·æä¾›çš„æµ‹è¯•å°ä½œä¸ºåŠŸèƒ½åŸºå‡†"
                })
            elif has_generated_testbench:
                strategy_info.update({
                    "selected_testbench": current_iteration_testbench,
                    "strategy": "æ™ºèƒ½ä½“ç”Ÿæˆ",
                    "reason": "ç”¨æˆ·æœªæä¾›æµ‹è¯•å°ï¼Œä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æµ‹è¯•å°"
                })
        else:
            # åç»­è¿­ä»£ï¼šğŸ¯ ä¼˜å…ˆä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æµ‹è¯•å°
            if has_generated_testbench:
                # âœ¨ æ™ºèƒ½ä½“ç”Ÿæˆäº†æµ‹è¯•å°ï¼Œä¼˜å…ˆä½¿ç”¨ï¼ˆæ¨åŠ¨TDDå¾ªç¯ï¼‰
                strategy_info.update({
                    "selected_testbench": current_iteration_testbench,
                    "strategy": "æ™ºèƒ½ä½“ä¼˜åŒ–",
                    "reason": f"ç¬¬{iteration}æ¬¡è¿­ä»£ï¼Œä¼˜å…ˆä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æœ€æ–°æµ‹è¯•å°æ¨åŠ¨TDDå¾ªç¯"
                })
            elif has_user_testbench:
                # åªæœ‰ç”¨æˆ·æµ‹è¯•å°å¯ç”¨æ—¶æ‰ä½¿ç”¨
                strategy_info.update({
                    "selected_testbench": user_testbench_path,
                    "strategy": "ç”¨æˆ·å¤‡ç”¨",
                    "reason": f"ç¬¬{iteration}æ¬¡è¿­ä»£ï¼Œæ™ºèƒ½ä½“æœªç”Ÿæˆæµ‹è¯•å°ï¼Œä½¿ç”¨ç”¨æˆ·æµ‹è¯•å°"
                })
        
        return strategy_info
    
    def _should_use_generated_testbench(self, iteration: int) -> bool:
        """å†³å®šæ˜¯å¦åº”è¯¥ä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æµ‹è¯•å°"""
        # âœ¨ ç§¯æç­–ç•¥ï¼šä»ç¬¬2æ¬¡è¿­ä»£å¼€å§‹ï¼Œä¼˜å…ˆä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæˆçš„æµ‹è¯•å°
        # è¿™ç¡®ä¿äº† TDD å¾ªç¯ä¸­æµ‹è¯•å°å¯ä»¥éšç€è®¾è®¡ä¸€èµ·è¿­ä»£æ”¹è¿›
        # ç¬¬1æ¬¡è¿­ä»£å»ºç«‹åŸºå‡†ï¼Œç¬¬2æ¬¡åŠä»¥åè¿­ä»£ä¼˜åŒ–
        return iteration >= 2


# ==========================================
# ğŸ­ å·¥å‚å‡½æ•° - ä¾¿äºé›†æˆ
# ==========================================

def create_test_driven_coordinator(base_coordinator: CentralizedCoordinator,
                                 config: TestDrivenConfig = None) -> TestDrivenCoordinator:
    """
    åˆ›å»ºæµ‹è¯•é©±åŠ¨åè°ƒå™¨çš„å·¥å‚å‡½æ•°
    
    Usage:
        # ç°æœ‰ä»£ç 
        coordinator = CentralizedCoordinator(config)
        
        # å‡çº§ä¸ºæµ‹è¯•é©±åŠ¨åŠŸèƒ½ï¼ˆå¯é€‰ï¼‰
        enhanced_coordinator = create_test_driven_coordinator(coordinator)
        
        # ç°æœ‰åŠŸèƒ½å®Œå…¨ä¸å˜
        result = await enhanced_coordinator.coordinate_task_execution(task)
        
        # æ–°å¢æµ‹è¯•é©±åŠ¨åŠŸèƒ½
        tdd_result = await enhanced_coordinator.execute_test_driven_task(task, testbench_path)
    """
    return TestDrivenCoordinator(base_coordinator, config)
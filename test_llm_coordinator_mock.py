#!/usr/bin/env python3
"""
ä½¿ç”¨æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯çš„åè°ƒå™¨æµ‹è¯•
"""

import asyncio
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config.config import FrameworkConfig, LLMConfig
from core.llm_coordinator_agent import LLMCoordinatorAgent
from agents.enhanced_real_verilog_agent import EnhancedRealVerilogAgentRefactored as EnhancedRealVerilogAgent
from agents.enhanced_real_code_reviewer import EnhancedRealCodeReviewAgent

class MockLLMClient:
    """æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯ï¼Œç”¨äºæµ‹è¯•"""
    
    def __init__(self, config):
        self.config = config
        self.logger = None
    
    async def send_prompt(self, prompt: str, system_prompt: str = None, 
                         temperature: float = None, max_tokens: int = None, 
                         json_mode: bool = False) -> str:
        """æ¨¡æ‹ŸLLMå“åº”"""
        return "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„LLMå“åº”ï¼Œç”¨äºæµ‹è¯•é‡æ„åçš„ä»£ç ã€‚"
    
    async def send_prompt_optimized(self, conversation_id: str, user_message: str,
                                  system_prompt: str = None, temperature: float = None,
                                  max_tokens: int = None, json_mode: bool = False,
                                  force_refresh_system: bool = False) -> str:
        """æ¨¡æ‹Ÿä¼˜åŒ–çš„LLMå“åº”"""
        return "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„ä¼˜åŒ–LLMå“åº”ï¼Œç”¨äºæµ‹è¯•é‡æ„åçš„ä»£ç ã€‚"

class MockEnhancedLLMClient:
    """æ¨¡æ‹Ÿå¢å¼ºLLMå®¢æˆ·ç«¯"""
    
    def __init__(self, config):
        self.config = config
        self.optimized_client = MockLLMClient(config)
    
    async def send_prompt(self, prompt: str, system_prompt: str = None, 
                         temperature: float = None, max_tokens: int = None, 
                         json_mode: bool = False) -> str:
        """æ¨¡æ‹ŸLLMå“åº”"""
        return "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„LLMå“åº”ï¼Œç”¨äºæµ‹è¯•é‡æ„åçš„ä»£ç ã€‚"
    
    async def send_prompt_optimized(self, conversation_id: str, user_message: str,
                                  system_prompt: str = None, temperature: float = None,
                                  max_tokens: int = None, json_mode: bool = False,
                                  force_refresh_system: bool = False) -> str:
        """æ¨¡æ‹Ÿä¼˜åŒ–çš„LLMå“åº”"""
        return "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„ä¼˜åŒ–LLMå“åº”ï¼Œç”¨äºæµ‹è¯•é‡æ„åçš„ä»£ç ã€‚"

async def test_coordinator_with_mock():
    """ä½¿ç”¨æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯æµ‹è¯•åè°ƒå™¨"""
    print("ğŸ§ª å¼€å§‹æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯æµ‹è¯•...")
    
    try:
        # åˆ›å»ºé…ç½®
        llm_config = LLMConfig(
            provider="mock",
            model_name="mock-model",
            api_key="mock-key",
            api_base_url="http://mock.local"
        )
        config = FrameworkConfig(llm_config=llm_config)
        
        # åˆ›å»ºåè°ƒå™¨
        coordinator = LLMCoordinatorAgent(config)
        
        # æ›¿æ¢LLMå®¢æˆ·ç«¯ä¸ºæ¨¡æ‹Ÿå®¢æˆ·ç«¯
        coordinator.llm_manager.llm_client = MockEnhancedLLMClient(config.llm)
        
        # åˆ›å»ºæ™ºèƒ½ä½“
        verilog_agent = EnhancedRealVerilogAgent(config)
        code_review_agent = EnhancedRealCodeReviewAgent(config)
        
        # æ³¨å†Œæ™ºèƒ½ä½“
        await coordinator.register_agent(verilog_agent)
        await coordinator.register_agent(code_review_agent)
        
        print("âœ… æ™ºèƒ½ä½“æ³¨å†ŒæˆåŠŸ")
        
        # æµ‹è¯•åè°ƒä»»åŠ¡
        user_request = "è¯·è®¾è®¡ä¸€ä¸ªç®€å•çš„è®¡æ•°å™¨æ¨¡å—"
        result = await coordinator.coordinate_task(
            user_request=user_request,
            max_iterations=2
        )
        
        print(f"âœ… åè°ƒä»»åŠ¡å®Œæˆ: {result}")
        
        # æµ‹è¯•LLMè°ƒç”¨
        conversation = [
            {"role": "user", "content": "è¯·è¯´'Hello, World!'"}
        ]
        
        response = await coordinator._call_llm_for_function_calling(conversation)
        print(f"âœ… Function Callingå“åº”: {response}")
        
        response_traditional = await coordinator._call_llm_traditional(conversation)
        print(f"âœ… ä¼ ç»ŸLLMå“åº”: {response_traditional}")
        
        print("âœ… æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯æµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ æ¨¡æ‹ŸLLMå®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(test_coordinator_with_mock()) 
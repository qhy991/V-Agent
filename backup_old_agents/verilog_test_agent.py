#!/usr/bin/env python3
"""
Verilogæµ‹è¯•æ™ºèƒ½ä½“

Verilog Test Agent for Testbench Generation
"""

import asyncio
import json
import logging
import time
import re
from typing import Dict, Any, List, Optional, Set
from pathlib import Path

from core.base_agent import BaseAgent, TaskMessage, FileReference
from core.enums import AgentCapability, AgentStatus
from llm_integration.enhanced_llm_client import EnhancedLLMClient


class VerilogTestAgent(BaseAgent):
    """
    Verilogæµ‹è¯•æ™ºèƒ½ä½“
    
    ä¸“é—¨è´Ÿè´£ï¼š
    1. ç”Ÿæˆå…¨é¢çš„testbenchæ–‡ä»¶
    2. è®¾è®¡æµ‹è¯•å‘é‡å’Œæµ‹è¯•åœºæ™¯
    3. éªŒè¯åŠŸèƒ½æ­£ç¡®æ€§
    4. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå’Œè¦†ç›–ç‡åˆ†æ
    """
    
    def __init__(self, llm_client: EnhancedLLMClient = None):
        super().__init__(
            agent_id="verilog_test_agent",
            role="test_engineer",
            capabilities={
                AgentCapability.TEST_GENERATION,
                AgentCapability.VERIFICATION,
                AgentCapability.COVERAGE_ANALYSIS
            }
        )
        
        self.llm_client = llm_client
        
        # æµ‹è¯•æ¨¡å¼é…ç½®
        self.test_modes = {
            "functional": "åŠŸèƒ½æµ‹è¯•",
            "corner_case": "è¾¹ç•Œæƒ…å†µæµ‹è¯•", 
            "stress": "å‹åŠ›æµ‹è¯•",
            "random": "éšæœºæµ‹è¯•"
        }
        
        # æµ‹è¯•è¦†ç›–ç‡ç›®æ ‡
        self.coverage_targets = {
            "statement": 0.95,
            "branch": 0.90,
            "condition": 0.85,
            "toggle": 0.80
        }
        
        self.logger.info("ğŸ§ª Verilogæµ‹è¯•æ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    def get_capabilities(self) -> Set[AgentCapability]:
        """è·å–æµ‹è¯•æ™ºèƒ½ä½“èƒ½åŠ›"""
        return {
            AgentCapability.TEST_GENERATION,
            AgentCapability.VERIFICATION,
            AgentCapability.COVERAGE_ANALYSIS
        }
    
    def get_specialty_description(self) -> str:
        """è·å–ä¸“ä¸šæè¿°"""
        return "ä¸“ä¸šçš„Verilogæµ‹è¯•æ™ºèƒ½ä½“ï¼Œæ“…é•¿testbenchç”Ÿæˆã€åŠŸèƒ½éªŒè¯ã€æµ‹è¯•å‘é‡è®¾è®¡å’Œè¦†ç›–ç‡åˆ†æ"
    
    async def execute_enhanced_task(self, enhanced_prompt: str,
                                  original_message: TaskMessage,
                                  file_contents: Dict[str, Dict]) -> Dict[str, Any]:
        """æ‰§è¡ŒVerilogæµ‹è¯•ä»»åŠ¡"""
        self.logger.info("ğŸ§ª å¼€å§‹æ‰§è¡ŒVerilogæµ‹è¯•ä»»åŠ¡")
        
        try:
            # 1. åˆ†æå¾…æµ‹è¯•çš„Verilogä»£ç 
            dut_analysis = await self._analyze_design_under_test(enhanced_prompt, file_contents)
            
            # 2. è®¾è®¡æµ‹è¯•ç­–ç•¥
            test_strategy = await self._design_test_strategy(dut_analysis)
            
            # 3. ç”Ÿæˆtestbenchä»£ç 
            testbench_code = await self._generate_testbench(dut_analysis, test_strategy)
            
            # 4. ç”Ÿæˆæµ‹è¯•å‘é‡
            test_vectors = await self._generate_test_vectors(dut_analysis, test_strategy)
            
            # 5. ä¿å­˜æµ‹è¯•æ–‡ä»¶
            output_files = await self._save_test_files(
                testbench_code=testbench_code,
                test_vectors=test_vectors,
                dut_analysis=dut_analysis,
                task_id=original_message.task_id
            )
            
            # 6. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
            test_report = self._generate_test_report(
                dut_analysis=dut_analysis,
                test_strategy=test_strategy,
                output_files=output_files
            )
            
            return {
                "success": True,
                "task_completed": True,
                "agent_id": self.agent_id,
                "testbench_code": testbench_code,
                "test_vectors": test_vectors,
                "dut_analysis": dut_analysis,
                "test_strategy": test_strategy,
                "test_report": test_report,
                "file_references": output_files,
                "execution_time": time.time()
            }
            
        except Exception as e:
            self.logger.error(f"âŒ Verilogæµ‹è¯•ä»»åŠ¡å¤±è´¥: {str(e)}")
            return {
                "success": False,
                "task_completed": False,
                "agent_id": self.agent_id,
                "error": str(e),
                "execution_time": time.time()
            }
    
    async def _analyze_design_under_test(self, task_description: str, 
                                       file_contents: Dict[str, Dict]) -> Dict[str, Any]:
        """åˆ†æå¾…æµ‹è¯•è®¾è®¡"""
        # æŸ¥æ‰¾Verilogæºç æ–‡ä»¶
        verilog_content = None
        verilog_file = None
        
        for file_path, content_info in file_contents.items():
            if content_info.get("type") == "verilog" or file_path.endswith(".v"):
                verilog_content = content_info.get("content", "")
                verilog_file = file_path
                break
        
        if not verilog_content:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°Verilogæ–‡ä»¶ï¼Œå°è¯•ä»ä»»åŠ¡æè¿°ä¸­æå–
            return self._simple_dut_analysis(task_description)
        
        if not self.llm_client:
            return self._parse_verilog_manually(verilog_content, verilog_file)
        
        # ä½¿ç”¨LLMåˆ†æVerilogä»£ç 
        analysis_prompt = f"""
è¯·åˆ†æä»¥ä¸‹Verilogæ¨¡å—ï¼Œæå–æµ‹è¯•æ‰€éœ€çš„å…³é”®ä¿¡æ¯ï¼š

æ–‡ä»¶: {verilog_file}
Verilogä»£ç :
{verilog_content}

è¯·åˆ†æå¹¶æå–ï¼š
1. æ¨¡å—åç§°å’ŒåŠŸèƒ½æè¿°
2. è¾“å…¥ç«¯å£ï¼ˆåç§°ã€ä½å®½ã€ç±»å‹ï¼‰
3. è¾“å‡ºç«¯å£ï¼ˆåç§°ã€ä½å®½ã€ç±»å‹ï¼‰
4. å‚æ•°å®šä¹‰
5. ä¸»è¦åŠŸèƒ½å’Œæ“ä½œ
6. æ—¶é’Ÿå’Œå¤ä½ä¿¡å·
7. æµ‹è¯•å…³é”®ç‚¹å’Œè¾¹ç•Œæ¡ä»¶
8. é¢„æœŸçš„æµ‹è¯•åœºæ™¯

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚
"""
        
        try:
            response = await self.llm_client.send_prompt(
                prompt=analysis_prompt,
                temperature=0.2,
                max_tokens=2000,
                json_mode=True
            )
            
            analysis = json.loads(response)
            analysis["source_file"] = verilog_file
            analysis["source_code"] = verilog_content
            
            self.logger.info(f"ğŸ“‹ DUTåˆ†æå®Œæˆ: {analysis.get('module_name', 'Unknown')}")
            return analysis
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ LLM DUTåˆ†æå¤±è´¥ï¼Œä½¿ç”¨æ‰‹åŠ¨è§£æ: {str(e)}")
            return self._parse_verilog_manually(verilog_content, verilog_file)
    
    def _parse_verilog_manually(self, verilog_content: str, 
                              verilog_file: str) -> Dict[str, Any]:
        """æ‰‹åŠ¨è§£æVerilogä»£ç """
        analysis = {
            "source_file": verilog_file,
            "source_code": verilog_content,
            "module_name": "unknown",
            "inputs": [],
            "outputs": [],
            "parameters": [],
            "has_clock": False,
            "has_reset": False
        }
        
        try:
            # æŸ¥æ‰¾moduleå£°æ˜
            module_match = re.search(r'module\s+(\w+)', verilog_content)
            if module_match:
                analysis["module_name"] = module_match.group(1)
            
            # æŸ¥æ‰¾è¾“å…¥ç«¯å£
            input_matches = re.findall(r'input\s+.*?(\w+)', verilog_content, re.MULTILINE)
            analysis["inputs"] = input_matches
            
            # æŸ¥æ‰¾è¾“å‡ºç«¯å£
            output_matches = re.findall(r'output\s+.*?(\w+)', verilog_content, re.MULTILINE)
            analysis["outputs"] = output_matches
            
            # æ£€æŸ¥æ—¶é’Ÿå’Œå¤ä½ä¿¡å·
            analysis["has_clock"] = "clk" in verilog_content.lower()
            analysis["has_reset"] = any(reset in verilog_content.lower() 
                                     for reset in ["rst", "reset", "rst_n"])
            
            self.logger.info(f"ğŸ” æ‰‹åŠ¨è§£æå®Œæˆ: {analysis['module_name']}")
            
        except Exception as e:
            self.logger.error(f"âŒ æ‰‹åŠ¨è§£æå¤±è´¥: {str(e)}")
        
        return analysis
    
    def _simple_dut_analysis(self, task_description: str) -> Dict[str, Any]:
        """ç®€å•çš„DUTåˆ†æï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        desc_lower = task_description.lower()
        
        return {
            "module_name": "dut",
            "description": task_description,
            "inputs": ["clk", "rst_n", "data_in"],
            "outputs": ["data_out"],
            "has_clock": "clk" in desc_lower or "clock" in desc_lower,
            "has_reset": "rst" in desc_lower or "reset" in desc_lower,
            "test_scenarios": ["basic_functionality", "reset_test", "edge_cases"]
        }
    
    async def _design_test_strategy(self, dut_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """è®¾è®¡æµ‹è¯•ç­–ç•¥"""
        module_name = dut_analysis.get("module_name", "dut")
        has_clock = dut_analysis.get("has_clock", False)
        has_reset = dut_analysis.get("has_reset", False)
        
        # åŸºæœ¬æµ‹è¯•ç­–ç•¥
        strategy = {
            "test_modes": [],
            "test_scenarios": [],
            "stimulus_types": [],
            "coverage_goals": self.coverage_targets.copy(),
            "simulation_time": "1000ns"
        }
        
        # æ ¹æ®è®¾è®¡ç‰¹ç‚¹é€‰æ‹©æµ‹è¯•æ¨¡å¼
        strategy["test_modes"].append("functional")
        
        if has_reset:
            strategy["test_scenarios"].append("reset_test")
        
        if has_clock:
            strategy["test_scenarios"].append("clock_edge_test")
            strategy["stimulus_types"].append("sequential")
        else:
            strategy["stimulus_types"].append("combinational")
        
        # æ·»åŠ é€šç”¨æµ‹è¯•åœºæ™¯
        strategy["test_scenarios"].extend([
            "basic_functionality",
            "boundary_conditions",
            "corner_cases"
        ])
        
        strategy["test_modes"].extend(["corner_case", "random"])
        
        self.logger.info(f"ğŸ“‹ æµ‹è¯•ç­–ç•¥è®¾è®¡å®Œæˆ: {len(strategy['test_scenarios'])} ä¸ªåœºæ™¯")
        return strategy
    
    async def _generate_testbench(self, dut_analysis: Dict[str, Any], 
                                test_strategy: Dict[str, Any]) -> str:
        """ç”Ÿæˆtestbenchä»£ç """
        if not self.llm_client:
            return self._generate_template_testbench(dut_analysis, test_strategy)
        
        testbench_prompt = f"""
åŸºäºä»¥ä¸‹DUTåˆ†æå’Œæµ‹è¯•ç­–ç•¥ç”Ÿæˆå®Œæ•´çš„SystemVerilog testbenchï¼š

DUTä¿¡æ¯:
{json.dumps(dut_analysis, indent=2, ensure_ascii=False)}

æµ‹è¯•ç­–ç•¥:
{json.dumps(test_strategy, indent=2, ensure_ascii=False)}

è¯·ç”ŸæˆåŒ…å«ä»¥ä¸‹ç‰¹æ€§çš„testbenchï¼š
1. å®Œæ•´çš„moduleå®šä¹‰å’Œä¿¡å·å£°æ˜
2. æ—¶é’Ÿå’Œå¤ä½ç”Ÿæˆé€»è¾‘
3. DUTå®ä¾‹åŒ–
4. æµ‹è¯•æ¿€åŠ±ç”Ÿæˆ
5. å“åº”æ£€æŸ¥å’Œæ–­è¨€
6. æµ‹è¯•åœºæ™¯è¦†ç›–
7. é€‚å½“çš„æ˜¾ç¤ºå’Œç›‘æ§è¯­å¥

è¯·åªè¿”å›SystemVerilogä»£ç ï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚
"""
        
        try:
            testbench_code = await self.llm_client.send_prompt(
                prompt=testbench_prompt,
                temperature=0.3,
                max_tokens=4000
            )
            
            self.logger.info(f"âœ… Testbenchç”Ÿæˆå®Œæˆ ({len(testbench_code)} å­—ç¬¦)")
            return testbench_code.strip()
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ LLM testbenchç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ¿: {str(e)}")
            return self._generate_template_testbench(dut_analysis, test_strategy)
    
    def _generate_template_testbench(self, dut_analysis: Dict[str, Any], 
                                   test_strategy: Dict[str, Any]) -> str:
        """åŸºäºæ¨¡æ¿ç”Ÿæˆtestbenchï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        module_name = dut_analysis.get("module_name", "dut")
        has_clock = dut_analysis.get("has_clock", False)
        has_reset = dut_analysis.get("has_reset", False)
        
        # åŸºæœ¬testbenchæ¨¡æ¿
        testbench = f"""
// Testbench for {module_name}
// Generated by VerilogTestAgent

`timescale 1ns/1ps

module tb_{module_name};

    // Parameters
    parameter CLK_PERIOD = 10; // 100MHz clock
    parameter SIM_TIME = 1000;
    
    // Signals
"""
        
        # æ·»åŠ ä¿¡å·å£°æ˜
        if has_clock:
            testbench += "    reg clk;\n"
        if has_reset:
            testbench += "    reg rst_n;\n"
        
        # æ·»åŠ è¾“å…¥è¾“å‡ºä¿¡å·
        inputs = dut_analysis.get("inputs", [])
        outputs = dut_analysis.get("outputs", [])
        
        for inp in inputs:
            if inp not in ["clk", "rst_n"]:
                testbench += f"    reg {inp};\n"
        
        for out in outputs:
            testbench += f"    wire {out};\n"
        
        testbench += f"""
    // DUT instantiation
    {module_name} dut (
"""
        
        # ç«¯å£è¿æ¥
        all_ports = inputs + outputs
        for i, port in enumerate(all_ports):
            comma = "," if i < len(all_ports) - 1 else ""
            testbench += f"        .{port}({port}){comma}\n"
        
        testbench += "    );\n\n"
        
        # æ—¶é’Ÿç”Ÿæˆ
        if has_clock:
            testbench += """    // Clock generation
    initial begin
        clk = 0;
        forever #(CLK_PERIOD/2) clk = ~clk;
    end
    
"""
        
        # æµ‹è¯•åºåˆ—
        testbench += """    // Test sequence
    initial begin
        $display("=== Test Start ===");
        
"""
        
        # å¤ä½åºåˆ—
        if has_reset:
            testbench += """        // Reset sequence
        rst_n = 0;
        #(CLK_PERIOD * 2);
        rst_n = 1;
        #(CLK_PERIOD);
        
"""
        
        # åŸºæœ¬æµ‹è¯•
        testbench += """        // Basic functionality test
        $display("Starting basic functionality test...");
        
        // Add test vectors here
        
        // Wait and finish
        #SIM_TIME;
        $display("=== Test Complete ===");
        $finish;
    end
    
    // Monitor signals
    initial begin
        $monitor("Time=%0t: ", $time);
    end
    
endmodule
"""
        
        return testbench.strip()
    
    async def _generate_test_vectors(self, dut_analysis: Dict[str, Any], 
                                   test_strategy: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆæµ‹è¯•å‘é‡"""
        test_vectors = []
        
        # åŸºæœ¬åŠŸèƒ½æµ‹è¯•å‘é‡
        basic_vectors = {
            "name": "basic_functionality",
            "description": "åŸºæœ¬åŠŸèƒ½æµ‹è¯•",
            "vectors": [
                {"inputs": {"data_in": "8'h00"}, "expected": {"data_out": "8'h00"}},
                {"inputs": {"data_in": "8'hFF"}, "expected": {"data_out": "8'hFF"}},
                {"inputs": {"data_in": "8'h55"}, "expected": {"data_out": "8'h55"}},
                {"inputs": {"data_in": "8'hAA"}, "expected": {"data_out": "8'hAA"}}
            ]
        }
        test_vectors.append(basic_vectors)
        
        # è¾¹ç•Œæ¡ä»¶æµ‹è¯•
        boundary_vectors = {
            "name": "boundary_conditions", 
            "description": "è¾¹ç•Œæ¡ä»¶æµ‹è¯•",
            "vectors": [
                {"inputs": {"data_in": "8'h00"}, "expected": {"data_out": "8'h00"}},
                {"inputs": {"data_in": "8'hFF"}, "expected": {"data_out": "8'hFF"}},
                {"inputs": {"data_in": "8'h7F"}, "expected": {"data_out": "8'h7F"}},
                {"inputs": {"data_in": "8'h80"}, "expected": {"data_out": "8'h80"}}
            ]
        }
        test_vectors.append(boundary_vectors)
        
        # éšæœºæµ‹è¯•å‘é‡
        random_vectors = {
            "name": "random_test",
            "description": "éšæœºæµ‹è¯•",
            "vectors": []
        }
        
        # ç”Ÿæˆéšæœºæµ‹è¯•å‘é‡
        import random
        for i in range(10):
            random_val = random.randint(0, 255)
            random_vectors["vectors"].append({
                "inputs": {"data_in": f"8'h{random_val:02X}"},
                "expected": {"data_out": f"8'h{random_val:02X}"}
            })
        
        test_vectors.append(random_vectors)
        
        self.logger.info(f"ğŸ¯ æµ‹è¯•å‘é‡ç”Ÿæˆå®Œæˆ: {len(test_vectors)} ä¸ªæµ‹è¯•é›†")
        return test_vectors
    
    async def _save_test_files(self, testbench_code: str, 
                             test_vectors: List[Dict[str, Any]],
                             dut_analysis: Dict[str, Any],
                             task_id: str) -> List[FileReference]:
        """ä¿å­˜æµ‹è¯•æ–‡ä»¶"""
        output_files = []
        module_name = dut_analysis.get("module_name", "dut")
        
        try:
            # 1. ä¿å­˜testbenchæ–‡ä»¶
            tb_path = f"output/{task_id}/tb_{module_name}.sv"
            tb_ref = await self.save_result_to_file(
                content=testbench_code,
                file_path=tb_path,
                file_type="testbench"
            )
            output_files.append(tb_ref)
            
            # 2. ä¿å­˜æµ‹è¯•å‘é‡æ–‡ä»¶
            vectors_content = json.dumps(test_vectors, indent=2, ensure_ascii=False)
            vectors_path = f"output/{task_id}/test_vectors.json"
            vectors_ref = await self.save_result_to_file(
                content=vectors_content,
                file_path=vectors_path,
                file_type="test_data"
            )
            output_files.append(vectors_ref)
            
            # 3. ä¿å­˜ä»¿çœŸè„šæœ¬
            sim_script = self._generate_simulation_script(module_name, task_id)
            script_path = f"output/{task_id}/run_sim.sh"
            script_ref = await self.save_result_to_file(
                content=sim_script,
                file_path=script_path,
                file_type="script"
            )
            output_files.append(script_ref)
            
            # 4. ä¿å­˜æµ‹è¯•æ–‡æ¡£
            doc_content = f"""# {module_name.upper()} æµ‹è¯•æ–‡æ¡£

## æµ‹è¯•æ¦‚è¦
æœ¬æ–‡æ¡£æè¿°äº†{module_name}æ¨¡å—çš„æµ‹è¯•ç­–ç•¥å’Œæµ‹è¯•ç»“æœã€‚

## æµ‹è¯•æ–‡ä»¶
- `tb_{module_name}.sv`: ä¸»è¦testbenchæ–‡ä»¶
- `test_vectors.json`: æµ‹è¯•å‘é‡æ•°æ®
- `run_sim.sh`: ä»¿çœŸè¿è¡Œè„šæœ¬

## æµ‹è¯•åœºæ™¯
{chr(10).join(f"- {tv['name']}: {tv['description']}" for tv in test_vectors)}

## è¿è¡Œæ–¹æ³•
```bash
chmod +x run_sim.sh
./run_sim.sh
```

## ç”Ÿæˆä¿¡æ¯
- ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}
- ç”Ÿæˆæ™ºèƒ½ä½“: {self.agent_id}
"""
            
            doc_path = f"output/{task_id}/TEST_README.md"
            doc_ref = await self.save_result_to_file(
                content=doc_content,
                file_path=doc_path,
                file_type="documentation"
            )
            output_files.append(doc_ref)
            
            self.logger.info(f"ğŸ’¾ æµ‹è¯•æ–‡ä»¶ä¿å­˜å®Œæˆ: {len(output_files)} ä¸ªæ–‡ä»¶")
            return output_files
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜æµ‹è¯•æ–‡ä»¶å¤±è´¥: {str(e)}")
            return output_files
    
    def _generate_simulation_script(self, module_name: str, task_id: str) -> str:
        """ç”Ÿæˆä»¿çœŸè„šæœ¬"""
        script = f"""#!/bin/bash
# Simulation script for {module_name}
# Generated by VerilogTestAgent

echo "Starting simulation for {module_name}..."

# Create work directory
if [ ! -d "work" ]; then
    mkdir work
fi

# Compile with ModelSim/QuestaSim
vlog -work work {module_name}.v
vlog -work work tb_{module_name}.sv

# Run simulation
vsim -work work -c -do "run -all; quit" tb_{module_name}

echo "Simulation completed!"
echo "Check modelsim.log for results"

# Alternative with Icarus Verilog
# iverilog -o tb_{module_name} {module_name}.v tb_{module_name}.sv
# vvp tb_{module_name}

# Alternative with Verilator
# verilator --cc --exe --build tb_{module_name}.sv {module_name}.v
# ./obj_dir/Vtb_{module_name}
"""
        return script.strip()
    
    def _generate_test_report(self, dut_analysis: Dict[str, Any],
                            test_strategy: Dict[str, Any],
                            output_files: List[FileReference]) -> str:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        module_name = dut_analysis.get("module_name", "Unknown")
        
        report = f"""
ğŸ§ª VERILOGæµ‹è¯•æŠ¥å‘Š
==================

ğŸ“‹ æµ‹è¯•æ¦‚è¦:
- è¢«æµ‹æ¨¡å—: {module_name}
- æµ‹è¯•æ¨¡å¼: {', '.join(test_strategy.get('test_modes', []))}
- æµ‹è¯•åœºæ™¯: {len(test_strategy.get('test_scenarios', []))} ä¸ª

ğŸ¯ æµ‹è¯•ç­–ç•¥:
- åŠŸèƒ½è¦†ç›–ç‡ç›®æ ‡: {test_strategy.get('coverage_goals', {}).get('statement', 0.95)*100:.0f}%
- åˆ†æ”¯è¦†ç›–ç‡ç›®æ ‡: {test_strategy.get('coverage_goals', {}).get('branch', 0.90)*100:.0f}%
- ä»¿çœŸæ—¶é—´: {test_strategy.get('simulation_time', 'N/A')}

ğŸ“ ç”Ÿæˆæ–‡ä»¶: {len(output_files)} ä¸ª
{chr(10).join(f"- {ref.file_path} ({ref.file_type})" for ref in output_files)}

ğŸ” DUTåˆ†æç»“æœ:
- è¾“å…¥ç«¯å£: {len(dut_analysis.get('inputs', []))} ä¸ª
- è¾“å‡ºç«¯å£: {len(dut_analysis.get('outputs', []))} ä¸ª
- æ—¶é’Ÿä¿¡å·: {'âœ…' if dut_analysis.get('has_clock', False) else 'âŒ'}
- å¤ä½ä¿¡å·: {'âœ…' if dut_analysis.get('has_reset', False) else 'âŒ'}

ğŸ“‹ æµ‹è¯•åœºæ™¯:
{chr(10).join(f"- {scenario}" for scenario in test_strategy.get('test_scenarios', []))}
"""
        return report.strip()
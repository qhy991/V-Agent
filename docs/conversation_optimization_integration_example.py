#!/usr/bin/env python3
"""
å¯¹è¯æ˜¾ç¤ºä¼˜åŒ–é›†æˆç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•åœ¨ç°æœ‰ä»£ç ä¸­é›†æˆå¯¹è¯æ˜¾ç¤ºä¼˜åŒ–åŠŸèƒ½
"""

import asyncio
from core.conversation_display_optimizer import conversation_optimizer, optimize_agent_output
from core.conversation_config import get_conversation_config


class OptimizedAgentExample:
    """é›†æˆäº†å¯¹è¯æ˜¾ç¤ºä¼˜åŒ–çš„æ™ºèƒ½ä½“ç¤ºä¾‹"""
    
    def __init__(self, agent_id: str = "example_agent"):
        self.agent_id = agent_id
        self.conversation_config = get_conversation_config()
        self.iteration_count = 0
    
    async def process_with_optimized_display(self, user_request: str) -> str:
        """ä½¿ç”¨ä¼˜åŒ–æ˜¾ç¤ºçš„å¤„ç†æ–¹æ³•"""
        self.iteration_count += 1
        
        # æ¨¡æ‹ŸAIå“åº”ï¼ˆè¿™é‡Œä¼šæ˜¯å®é™…çš„LLMè°ƒç”¨ï¼‰
        ai_response = f"è¿™æ˜¯é’ˆå¯¹'{user_request}'çš„AIå“åº”ã€‚" * 20  # æ¨¡æ‹Ÿé•¿å“åº”
        
        # åº”ç”¨æ˜¾ç¤ºä¼˜åŒ–
        if self.conversation_config.should_optimize_display():
            # ä½¿ç”¨ä¼˜åŒ–æ˜¾ç¤º
            optimized_display = optimize_agent_output(
                agent_id=self.agent_id,
                user_request=user_request,
                ai_response=ai_response,
                iteration_count=self.iteration_count
            )
            print(optimized_display)
        else:
            # ä½¿ç”¨åŸå§‹æ˜¾ç¤ºï¼ˆä¼šå¾ˆé•¿ï¼‰
            print(f"\nåŸå§‹å“åº”ï¼ˆç¬¬{self.iteration_count}è½®ï¼‰:")
            print(f"ç”¨æˆ·: {user_request}")
            print(f"AI: {ai_response}")
            print("-" * 100)
        
        return ai_response
    
    def demonstrate_history_optimization(self, conversation_history: list) -> list:
        """æ¼”ç¤ºå¯¹è¯å†å²ä¼˜åŒ–"""
        print(f"\nğŸ“Š å¯¹è¯å†å²ä¼˜åŒ–æ¼”ç¤º:")
        print(f"åŸå§‹å†å²é•¿åº¦: {len(conversation_history)} æ¡æ¶ˆæ¯")
        
        # åº”ç”¨å†å²ä¼˜åŒ–
        optimized_history = conversation_optimizer.optimize_conversation_history(
            conversation_history=conversation_history,
            keep_last_n_turns=self.conversation_config.max_history_turns
        )
        
        print(f"ä¼˜åŒ–åå†å²é•¿åº¦: {len(optimized_history)} æ¡æ¶ˆæ¯")
        
        # åˆ›å»ºå¯¹è¯æ‘˜è¦
        summary = conversation_optimizer.create_conversation_summary(conversation_history)
        print(f"\nå¯¹è¯æ‘˜è¦:\n{summary}")
        
        return optimized_history


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ å¯¹è¯æ˜¾ç¤ºä¼˜åŒ–é›†æˆæ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºä¼˜åŒ–æ™ºèƒ½ä½“å®ä¾‹
    agent = OptimizedAgentExample("demo_agent")
    
    # æ¼”ç¤º1: ä¼˜åŒ–æ˜¾ç¤º
    print("\nğŸ“‹ æ¼”ç¤º1: å¯¹è¯æ˜¾ç¤ºä¼˜åŒ–")
    await agent.process_with_optimized_display("è®¾è®¡ä¸€ä¸ªè®¡æ•°å™¨æ¨¡å—")
    await agent.process_with_optimized_display("æ·»åŠ æµ‹è¯•å°")
    await agent.process_with_optimized_display("ä¿®å¤ç¼–è¯‘é”™è¯¯")
    
    # æ¼”ç¤º2: å¯¹è¯å†å²ä¼˜åŒ–
    print("\nğŸ“‹ æ¼”ç¤º2: å¯¹è¯å†å²ä¼˜åŒ–")
    sample_history = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªVerilogè®¾è®¡åŠ©æ‰‹"},
        {"role": "user", "content": "è®¾è®¡ALU"},
        {"role": "assistant", "content": "æˆ‘å°†ä¸ºæ‚¨è®¾è®¡ä¸€ä¸ªALUæ¨¡å—..."},
        {"role": "user", "content": "æ·»åŠ åŠ æ³•åŠŸèƒ½"},
        {"role": "assistant", "content": "æˆ‘å°†æ·»åŠ åŠ æ³•åŠŸèƒ½..."},
        {"role": "user", "content": "æ·»åŠ å‡æ³•åŠŸèƒ½"},
        {"role": "assistant", "content": "æˆ‘å°†æ·»åŠ å‡æ³•åŠŸèƒ½..."},
        {"role": "user", "content": "ç”Ÿæˆæµ‹è¯•å°"},
        {"role": "assistant", "content": "æˆ‘å°†ç”Ÿæˆæµ‹è¯•å°..."},
        {"role": "user", "content": "ä¿®å¤é”™è¯¯"},
        {"role": "assistant", "content": "æˆ‘å°†ä¿®å¤é”™è¯¯..."}
    ]
    
    agent.demonstrate_history_optimization(sample_history)
    
    # æ¼”ç¤º3: é…ç½®æ§åˆ¶
    print("\nğŸ“‹ æ¼”ç¤º3: é…ç½®æ§åˆ¶")
    config = get_conversation_config()
    print(f"å½“å‰é…ç½®:")
    print(f"- æ˜¾ç¤ºä¼˜åŒ–: {config.enable_display_optimization}")
    print(f"- æœ€å¤§æ˜¾ç¤ºè½®æ•°: {config.max_display_rounds}")
    print(f"- ç´§å‡‘æ¨¡å¼: {config.enable_compact_mode}")
    print(f"- æœ€å¤§å†å²è½®æ•°: {config.max_history_turns}")
    print(f"- ä¸ºOllamaä¼˜åŒ–: {config.optimize_for_ollama}")


class IntegrationGuide:
    """é›†æˆæŒ‡å—ç±»"""
    
    @staticmethod
    def show_integration_steps():
        """æ˜¾ç¤ºé›†æˆæ­¥éª¤"""
        print("\nğŸ”§ å¯¹è¯æ˜¾ç¤ºä¼˜åŒ–é›†æˆæŒ‡å—")
        print("=" * 60)
        
        steps = [
            "1. å¯¼å…¥å¿…è¦æ¨¡å—:",
            "   from core.conversation_display_optimizer import optimize_agent_output",
            "   from core.conversation_config import get_conversation_config",
            "",
            "2. åœ¨æ™ºèƒ½ä½“ç±»ä¸­æ·»åŠ é…ç½®:",
            "   self.conversation_config = get_conversation_config()",
            "",
            "3. åœ¨è¾“å‡ºå“åº”æ—¶åº”ç”¨ä¼˜åŒ–:",
            "   if self.conversation_config.should_optimize_display():",
            "       optimized_display = optimize_agent_output(",
            "           agent_id=self.agent_id,",
            "           user_request=user_request,",
            "           ai_response=ai_response,",
            "           iteration_count=iteration_count",
            "       )",
            "       print(optimized_display)",
            "",
            "4. å¯¹è¯å†å²ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰:",
            "   from core.conversation_display_optimizer import conversation_optimizer",
            "   optimized_history = conversation_optimizer.optimize_conversation_history(",
            "       conversation_history=full_history,",
            "       keep_last_n_turns=3",
            "   )",
            "",
            "5. ç¯å¢ƒå˜é‡æ§åˆ¶ï¼ˆå¯é€‰ï¼‰:",
            "   export CONVERSATION_DISPLAY_OPTIMIZATION=true",
            "   export CONVERSATION_MAX_DISPLAY_ROUNDS=1",
            "   export CONVERSATION_COMPACT_MODE=true",
            "   export CONVERSATION_MAX_RESPONSE_LENGTH=500"
        ]
        
        for step in steps:
            print(step)
    
    @staticmethod 
    def show_specific_fixes():
        """æ˜¾ç¤ºé’ˆå¯¹ç‰¹å®šé—®é¢˜çš„ä¿®å¤æ–¹æ¡ˆ"""
        print("\nğŸ¯ é’ˆå¯¹æ‰§è¡Œç»“æœé—®é¢˜çš„å…·ä½“ä¿®å¤")
        print("=" * 60)
        
        fixes = [
            "é—®é¢˜: æ¯æ¬¡è¿­ä»£éƒ½æ˜¾ç¤ºå®Œæ•´å¯¹è¯å†å²ï¼Œå¯¼è‡´è¾“å‡ºè¶Šæ¥è¶Šé•¿",
            "",
            "è§£å†³æ–¹æ¡ˆ1 - åœ¨test_llm_coordinator_enhanced.pyä¸­åº”ç”¨:",
            "```python",
            "# åœ¨æ˜¾ç¤ºç»“æœæ—¶ä½¿ç”¨ä¼˜åŒ–",
            "from core.conversation_display_optimizer import optimize_agent_output",
            "",
            "# æ›¿æ¢åŸæ¥çš„é•¿è¾“å‡º",
            "optimized_output = optimize_agent_output(",
            "    agent_id='coordinator',",
            "    user_request=requirements,",
            "    ai_response=result.get('coordination_result', ''),",
            "    iteration_count=analysis.get('total_iterations', 1)",
            ")",
            "print(optimized_output)",
            "```",
            "",
            "è§£å†³æ–¹æ¡ˆ2 - åœ¨enhanced_base_agent.pyä¸­é›†æˆ:",
            "```python",
            "# åœ¨process_with_function_callingæ–¹æ³•çš„æœ€å",
            "if hasattr(self, 'conversation_config') and self.conversation_config.should_optimize_display():",
            "    return optimize_agent_output(",
            "        agent_id=self.agent_id,",
            "        user_request=user_request,",
            "        ai_response=final_response,",
            "        iteration_count=iteration_count",
            "    )",
            "```",
            "",
            "è§£å†³æ–¹æ¡ˆ3 - ç¯å¢ƒå˜é‡æ§åˆ¶ï¼ˆç«‹å³ç”Ÿæ•ˆï¼‰:",
            "```bash",
            "export CONVERSATION_DISPLAY_OPTIMIZATION=true",
            "export CONVERSATION_MAX_RESPONSE_LENGTH=200",
            "export CONVERSATION_COMPACT_MODE=true",
            "```"
        ]
        
        for fix in fixes:
            print(fix)


if __name__ == "__main__":
    # æ˜¾ç¤ºé›†æˆæŒ‡å—
    IntegrationGuide.show_integration_steps()
    IntegrationGuide.show_specific_fixes()
    
    print("\n" + "=" * 60)
    
    # è¿è¡Œæ¼”ç¤º
    asyncio.run(main())